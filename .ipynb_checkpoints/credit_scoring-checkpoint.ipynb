{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAmA1Tr1ybJK"
   },
   "source": [
    "# **<center>Credit Scoring - A basic introduction</center>**\n",
    "\n",
    "\n",
    "## <center> Using Deep Learning </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tiUNZK3r53F"
   },
   "source": [
    "---\n",
    "**Presentation of the Coursework:**\n",
    "\n",
    "In this notebook, an interpretable Neural Network to handle the same classification problem is introduced. \n",
    "\n",
    "\n",
    "The notebook is structured into three sections:\n",
    "\n",
    "* In Section 1, we undertake data preprocessing, which involves scaling the numerical features and applying Label Encoding to the categorical features.\n",
    "* In Section 2, we develop and train a model, as depicted in the following diagram:\n",
    "<center><img width=\"1000\" src = \"https://drive.google.com/uc?export=view&id=1Aj7nc0QSS5hweGx_xPUbYH-5L6_2HRgz\"></center>\n",
    "* In Section 3, we adapt the model presented in Section 2 to address a sequential problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81kUcaVEcLV9"
   },
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq5p0Tdc5zGG"
   },
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x_oge2jy5MC1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # for dataframes\n",
    "import matplotlib.pyplot as plt # as usual for plots\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, Dense, Concatenate, Embedding, LayerNormalization, Dropout\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXeXv79FWk_W"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "The data is stored in the folder \"data\". Load the dataframe and shuffle the rows, then display 5 random rows in the dataframe.\n",
    "</font>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DIjN41OnZGSF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>65000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>E</td>\n",
       "      <td>15000</td>\n",
       "      <td>16.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>72000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>D</td>\n",
       "      <td>25000</td>\n",
       "      <td>15.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>28800</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>A</td>\n",
       "      <td>5000</td>\n",
       "      <td>7.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>90000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>14.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>D</td>\n",
       "      <td>10000</td>\n",
       "      <td>15.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>61000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>A</td>\n",
       "      <td>4500</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0          24          65000                  RENT                8.0   \n",
       "1          27          72000                  RENT                3.0   \n",
       "2          21          28800              MORTGAGE                0.0   \n",
       "3          30          90000                  RENT               14.0   \n",
       "4          30          61000              MORTGAGE                4.0   \n",
       "\n",
       "         loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
       "0            VENTURE          E      15000          16.32            1   \n",
       "1  DEBTCONSOLIDATION          D      25000          15.95            1   \n",
       "2  DEBTCONSOLIDATION          A       5000           7.49            0   \n",
       "3           PERSONAL          D      10000          15.62            0   \n",
       "4           PERSONAL          A       4500           6.54            0   \n",
       "\n",
       "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "0                 0.23                         Y                           4  \n",
       "1                 0.35                         Y                           6  \n",
       "2                 0.17                         N                           3  \n",
       "3                 0.11                         Y                           6  \n",
       "4                 0.07                         N                           6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import data\n",
    "df = pd.read_csv('credit_dataset.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "d5dqKPecZHZ8"
   },
   "outputs": [],
   "source": [
    "## Shuffle the rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "OCOVEDWtZHoC",
    "outputId": "8c721c11-68d4-44a3-e583-fe08ee09acec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>23</td>\n",
       "      <td>55000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>A</td>\n",
       "      <td>3000</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18101</th>\n",
       "      <td>31</td>\n",
       "      <td>135000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>12.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>15000</td>\n",
       "      <td>13.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21331</th>\n",
       "      <td>27</td>\n",
       "      <td>51996</td>\n",
       "      <td>OWN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>D</td>\n",
       "      <td>9600</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24324</th>\n",
       "      <td>42</td>\n",
       "      <td>64464</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>13.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>E</td>\n",
       "      <td>30000</td>\n",
       "      <td>19.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10180</th>\n",
       "      <td>29</td>\n",
       "      <td>47340</td>\n",
       "      <td>RENT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>B</td>\n",
       "      <td>2000</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "1600           23          55000                  RENT                2.0   \n",
       "18101          31         135000              MORTGAGE               12.0   \n",
       "21331          27          51996                   OWN                8.0   \n",
       "24324          42          64464              MORTGAGE               13.0   \n",
       "10180          29          47340                  RENT                5.0   \n",
       "\n",
       "             loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
       "1600           EDUCATION          A       3000           6.99            0   \n",
       "18101            MEDICAL          C      15000          13.85            0   \n",
       "21331          EDUCATION          D       9600          14.09            0   \n",
       "24324            MEDICAL          E      30000          19.03            1   \n",
       "10180  DEBTCONSOLIDATION          B       2000           9.99            0   \n",
       "\n",
       "       loan_percent_income cb_person_default_on_file  \\\n",
       "1600                  0.05                         N   \n",
       "18101                 0.11                         N   \n",
       "21331                 0.18                         N   \n",
       "24324                 0.40                         N   \n",
       "10180                 0.04                         N   \n",
       "\n",
       "       cb_person_cred_hist_length  \n",
       "1600                            2  \n",
       "18101                          10  \n",
       "21331                          10  \n",
       "24324                          14  \n",
       "10180                           6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sample 5 random rows\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gPqz3TJVvqj"
   },
   "source": [
    "In this dataset, each entry represents a person who takes a credit by a bank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wAu3-W5W7fN"
   },
   "source": [
    "The target is: `loan_status`. It takes two possible values:\n",
    "\n",
    "\n",
    "* 1 in case of default.\n",
    "* 0 otherwise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JviraydcXGx2"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "the below cells show that it is a binary classification problem and that the dataset is highly imbalanced.\n",
    "</font>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AeweMdjXW7DF",
    "outputId": "f396c544-059d-406f-d775-17de962e4384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show it's a Binary Classification Problem\n",
    "df['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "xxRF_SU2WkC8",
    "outputId": "9557f35f-8525-4c9c-d0db-85c4ad1449f8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"loan_status\"].hist(figsize=(10, 6))\n",
    "plt.title(\"Target Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>From the above histogram, it can clearly be seen that the the dataset is highly imbalanced. There are way more non-defaulters than defaulters. To be more precise, the below line of code will count exactly the occurences of 1s (default) and 0s (otherwise). \n",
    "\n",
    "It can be found that there are **25473 non-defaulters** against **7108 defaulters**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25473\n",
       "1     7108\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5Bsa6SAjCmn"
   },
   "source": [
    "### Adding a categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5Q6q3SVZvQg"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "We now describe the way we created the categorical variable `category_income`.\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "We create a new categorical variable `category_income` using by segmenting the `person_income` in 4 categories `D`, `C`, `B` and `A` where `D` is the lowest income and `A` is the highest. \n",
    "\n",
    "Namely:\n",
    "  * If `person_income` is in [0, 39000], then `category_income = 'D'`.\n",
    "  * If `person_income` is in [39000, 55000], then `category_income = 'C'`.\n",
    "  * If `person_income` is in [55000, 79000], then `category_income = 'B'`.\n",
    "  * If `person_income` is in [79000, +$\\infty$], then `category_income = 'A'`.\n",
    "    \n",
    "Note that these categories have been defined given the training set in a previous study. Here, we can take the shortcut of using directly these category splits. Feel free to reach out to me srr21@ic.ac.uk for further explanation of the full process.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tDw2ugxMgDd9"
   },
   "outputs": [],
   "source": [
    "# Age intervals\n",
    "intervals = (0, 39000, 55000, 79000, 6000000)\n",
    "# Categories\n",
    "categories = [\"D\", \"C\", \"B\", \"A\"]\n",
    "# Create the new feature\n",
    "df[\"category_income\"] = pd.cut(df.person_income, intervals, labels=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>category_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>26400</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>B</td>\n",
       "      <td>3600</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>42564</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>B</td>\n",
       "      <td>15000</td>\n",
       "      <td>10.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>120000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>D</td>\n",
       "      <td>8000</td>\n",
       "      <td>14.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>55600</td>\n",
       "      <td>OWN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>4200</td>\n",
       "      <td>10.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>N</td>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>53000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>A</td>\n",
       "      <td>10000</td>\n",
       "      <td>7.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0          34          26400              MORTGAGE                0.0   \n",
       "1          30          42564                  RENT                3.0   \n",
       "2          23         120000                  RENT                4.0   \n",
       "3          27          55600                   OWN                2.0   \n",
       "4          21          53000                  RENT                5.0   \n",
       "\n",
       "         loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
       "0  DEBTCONSOLIDATION          B       3600           9.88            0   \n",
       "1            MEDICAL          B      15000          10.75            1   \n",
       "2          EDUCATION          D       8000          14.61            0   \n",
       "3          EDUCATION          B       4200          10.37            0   \n",
       "4          EDUCATION          A      10000           7.51            0   \n",
       "\n",
       "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \\\n",
       "0                 0.14                         N                           5   \n",
       "1                 0.35                         N                           6   \n",
       "2                 0.07                         Y                           4   \n",
       "3                 0.08                         N                           9   \n",
       "4                 0.19                         N                           4   \n",
       "\n",
       "  category_income  \n",
       "0               D  \n",
       "1               C  \n",
       "2               A  \n",
       "3               B  \n",
       "4               C  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPTIONAL CELL: to get a quick overview of the whole df with the new column\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3HaTKxKhPre"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Here we print the number of categories associated with the categorical variable `loan_grade` and print the different categories.\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categorical variable loan_grade contains 7 categories\n",
      "The different categories of the categorical variable loan_grade are: ['B' 'D' 'A' 'C' 'E' 'F' 'G']\n"
     ]
    }
   ],
   "source": [
    "print(f\"The categorical variable loan_grade contains {df['loan_grade'].nunique()} categories\")\n",
    "print(f\"The different categories of the categorical variable loan_grade are: {df['loan_grade'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4Bixb49gqw-"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "We now create a list called `catvars` containing the 5 categorical variables, and a list called `cardinalities` containing the number of categories associated with each categorical variable in `catvars`.\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>From the below informative table about the dataframe. We cann see that the datatype corresponding to caterogical variables are `object` and `category`. Hence to create a list, `catvar`, of categorical variables names, we need to make sure to incle both `object` and `category`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32581 entries, 0 to 32580\n",
      "Data columns (total 13 columns):\n",
      " #   Column                      Non-Null Count  Dtype   \n",
      "---  ------                      --------------  -----   \n",
      " 0   person_age                  32581 non-null  int64   \n",
      " 1   person_income               32581 non-null  int64   \n",
      " 2   person_home_ownership       32581 non-null  object  \n",
      " 3   person_emp_length           32581 non-null  float64 \n",
      " 4   loan_intent                 32581 non-null  object  \n",
      " 5   loan_grade                  32581 non-null  object  \n",
      " 6   loan_amnt                   32581 non-null  int64   \n",
      " 7   loan_int_rate               32581 non-null  float64 \n",
      " 8   loan_status                 32581 non-null  int64   \n",
      " 9   loan_percent_income         32581 non-null  float64 \n",
      " 10  cb_person_default_on_file   32581 non-null  object  \n",
      " 11  cb_person_cred_hist_length  32581 non-null  int64   \n",
      " 12  category_income             32581 non-null  category\n",
      "dtypes: category(1), float64(3), int64(5), object(4)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list categories contains the following elements: ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file', 'category_income']\n",
      "The list cardinalities contains the following elements: [4, 6, 7, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "catvars = list(df.select_dtypes(include = ['object', 'category']).columns)\n",
    "cardinalities = [len(df[column].unique()) for column in catvars]\n",
    "\n",
    "print(f\"The list categories contains the following elements: {catvars}\")\n",
    "print(f\"The list cardinalities contains the following elements: {cardinalities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U81wWA1a6L2"
   },
   "source": [
    "The following table shows the different categories for each categorical variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0XM1aE0VCYW"
   },
   "source": [
    "| Categorical Variable      | Categories                                                                                        |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| person_home_ownership     | ['MORTGAGE', 'RENT', 'OWN', 'OTHER']                                                              |\n",
    "| loan_intent               | ['DEBTCONSOLIDATION',   'PERSONAL',   'VENTURE',   'EDUCATION',   'MEDICAL',   'HOMEIMPROVEMENT'] |\n",
    "| loan_grade                | ['A', 'C', 'B', 'E', 'D', 'G', 'F']                                                               |\n",
    "| cb_person_default_on_file | ['N', 'Y']                                                                                        |\n",
    "| category_income           | ['B', 'D', 'C', 'A']                                                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YR9fhmXvjlR2"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let's create a list called `numvars` containing the 7 numerical variables. Let's then describe their distributions.\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numerical variables are: ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\n"
     ]
    }
   ],
   "source": [
    "numvars = list(df.select_dtypes(exclude = ['object', 'category']).columns)\n",
    "numvars.remove(\"loan_status\")\n",
    "\n",
    "print(f\"The numerical variables are: {numvars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpTOIRG3j77k",
    "outputId": "a1fedea3-5ead-43ea-93b4-ecc97cddf7ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32581.000000</td>\n",
       "      <td>3.258100e+04</td>\n",
       "      <td>32581.000000</td>\n",
       "      <td>32581.000000</td>\n",
       "      <td>32581.000000</td>\n",
       "      <td>32581.000000</td>\n",
       "      <td>32581.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.734600</td>\n",
       "      <td>6.607485e+04</td>\n",
       "      <td>4.767994</td>\n",
       "      <td>9589.371106</td>\n",
       "      <td>11.009620</td>\n",
       "      <td>0.170203</td>\n",
       "      <td>5.804211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.348078</td>\n",
       "      <td>6.198312e+04</td>\n",
       "      <td>4.087372</td>\n",
       "      <td>6322.086646</td>\n",
       "      <td>3.081611</td>\n",
       "      <td>0.106782</td>\n",
       "      <td>4.055001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.850000e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>8.490000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.500000e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>10.990000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.920000e+04</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12200.000000</td>\n",
       "      <td>13.110000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>6.000000e+06</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>23.220000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person_age  person_income  person_emp_length     loan_amnt  \\\n",
       "count  32581.000000   3.258100e+04       32581.000000  32581.000000   \n",
       "mean      27.734600   6.607485e+04           4.767994   9589.371106   \n",
       "std        6.348078   6.198312e+04           4.087372   6322.086646   \n",
       "min       20.000000   4.000000e+03           0.000000    500.000000   \n",
       "25%       23.000000   3.850000e+04           2.000000   5000.000000   \n",
       "50%       26.000000   5.500000e+04           4.000000   8000.000000   \n",
       "75%       30.000000   7.920000e+04           7.000000  12200.000000   \n",
       "max      144.000000   6.000000e+06         123.000000  35000.000000   \n",
       "\n",
       "       loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \n",
       "count   32581.000000         32581.000000                32581.000000  \n",
       "mean       11.009620             0.170203                    5.804211  \n",
       "std         3.081611             0.106782                    4.055001  \n",
       "min         5.420000             0.000000                    2.000000  \n",
       "25%         8.490000             0.090000                    3.000000  \n",
       "50%        10.990000             0.150000                    4.000000  \n",
       "75%        13.110000             0.230000                    8.000000  \n",
       "max        23.220000             0.830000                   30.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description of the numerical variables distribution\n",
    "df[numvars].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1flTS8wbirS-"
   },
   "source": [
    "### Preprocessing numerical and categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnjaLPADmQK9"
   },
   "source": [
    "We'll begin by dividing the dataset into a training set and a test set. The training set will contain 70% of the data and will be used to train our model. The remaining 30% will form the test set and will be used to evaluate the performance of the model.\n",
    "\n",
    "When dealing with categorical variables, it's important to remember that machine learning models are mathematical models and work with numbers. Therefore, these categories must be transformed into numbers before we can use them to fit and validate a model.\n",
    "\n",
    "Consider a simple example where we have a categorical variable with three unique values: 'A', 'B', and 'C'.\n",
    "\n",
    "Label Encoding would involve assigning each unique category value a unique integer. We could assign 'A' to '0', 'B' to '1', and 'C' to '2'. After encoding, our data will look like this:\n",
    "\n",
    "| categorical_variable | Index  |\n",
    "|-------|-------|\n",
    "| A     | 0   |\n",
    "| B     | 1   |\n",
    "| C     | 2   |\n",
    "\n",
    "This way, we have transformed our categorical data into numerical data, which makes it compatible for a machine learning algorithm.\n",
    "\n",
    "In addition to this, machine learning algorithms perform better when input numerical variables fall within a similar scale. Therefore, we'll scale (normalize) our numerical variables so they all have a similar range of values. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "145kreYTrd0G"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let's describe two methods to scale the numerical variables. \n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "As seen in the figure below, there are two ways of scaling numerical features.\n",
    "\n",
    "1. **Min-Max Scaling (Normalization):**\n",
    "   This method scales the data to a specific range, typically [0, 1]. The formula for min-max scaling is:\n",
    "   ```\n",
    "   X_normalized = (X - X.min()) / (X.max() - X.min())\n",
    "   ```\n",
    "   Here, `X` represents the original numerical variable. Subtracting the minimum value (`X.min()`) ensures that the minimum value is transformed to 0, and dividing by the range (`X.max() - X.min()`) scales the values to fit within the [0, 1] range. This scaling preserves the relative relationships between the data points.\n",
    "   \n",
    "\n",
    "2. **Standardization (Z-score Scaling):**\n",
    "   This method scales the data to have a mean of 0 and a standard deviation of 1. The formula for standardization is:\n",
    "   ```\n",
    "   X_standardized = (X - X.mean()) / X.std()\n",
    "   ```\n",
    "   Here, `X` represents the original numerical variable. Subtracting the mean (`X.mean()`) centers the data around 0, and dividing by the standard deviation (`X.std()`) scales the data to have a standard deviation of 1. Standardization helps in cases where the distribution of the data is not necessarily Gaussian and can handle outliers more robustly.\n",
    "\n",
    "Both methods have their advantages and are used depending on the specific requirements of the problem and the characteristics of the data. Min-max scaling is useful when you want to preserve the original range of the data, while standardization is useful when you want to bring the data to a common scale and handle outliers effectively.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img width=\"500\" src = \"https://drive.google.com/uc?export=view&id=1UiUAyNligNF9TQkavRdatKR-4WI3pxqz\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peDyoqN7reXP"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let's split the dataset into training and test sets. \n",
    "Furthermore, we process all the categorical variables using Label Encoding. \n",
    "Also, we scale the numerical variables using our preferred method.\n",
    "Finally, we extract the training and test targets.\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>category_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RENT</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENT</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>D</td>\n",
       "      <td>Y</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OWN</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RENT</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  person_home_ownership        loan_intent loan_grade  \\\n",
       "0              MORTGAGE  DEBTCONSOLIDATION          B   \n",
       "1                  RENT            MEDICAL          B   \n",
       "2                  RENT          EDUCATION          D   \n",
       "3                   OWN          EDUCATION          B   \n",
       "4                  RENT          EDUCATION          A   \n",
       "\n",
       "  cb_person_default_on_file category_income  \n",
       "0                         N               D  \n",
       "1                         N               C  \n",
       "2                         Y               A  \n",
       "3                         N               B  \n",
       "4                         N               C  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPTIONAL CELL: run this cell to have an insight on the categorical variables before label encoding\n",
    "df[catvars].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='blue'>Processing all the categorical variables using Label Encoding.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: only run this code once to avoid errors.\n",
    "\n",
    "# Create an instance of OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit and transform the ordinal encoder on the categorical variables of the DataFrame\n",
    "df[catvars] = ordinal_encoder.fit_transform(df[catvars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>person_home_ownership</th>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OWN</td>\n",
       "      <td>RENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_intent</th>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>HOMEIMPROVEMENT</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_grade</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_income</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0          1                2  \\\n",
       "person_home_ownership               MORTGAGE      OTHER              OWN   \n",
       "loan_intent                DEBTCONSOLIDATION  EDUCATION  HOMEIMPROVEMENT   \n",
       "loan_grade                                 A          B                C   \n",
       "cb_person_default_on_file                  N          Y              NaN   \n",
       "category_income                            A          B                C   \n",
       "\n",
       "                                 3         4        5    6  \n",
       "person_home_ownership         RENT       NaN      NaN  NaN  \n",
       "loan_intent                MEDICAL  PERSONAL  VENTURE  NaN  \n",
       "loan_grade                       D         E        F    G  \n",
       "cb_person_default_on_file      NaN       NaN      NaN  NaN  \n",
       "category_income                  D       NaN      NaN  NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPTIONAL CELL: Create and print a label mapping to understand the encoded values\n",
    "# Create a dictionary to map the encoded values to their original labels\n",
    "label_mapping = {}\n",
    "for i, column in enumerate(catvars):\n",
    "    label_mapping[column] = dict(enumerate(ordinal_encoder.categories_[i]))\n",
    "\n",
    "# Convert the label mapping dictionary into a DataFrame\n",
    "label_mapping_df = pd.DataFrame.from_dict(label_mapping, orient='index')\n",
    "\n",
    "\n",
    "# Print the label mapping DataFrame\n",
    "print(\"Label Mapping DataFrame:\")\n",
    "label_mapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>category_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_home_ownership  loan_intent  loan_grade  cb_person_default_on_file  \\\n",
       "0                    0.0          0.0         1.0                        0.0   \n",
       "1                    3.0          3.0         1.0                        0.0   \n",
       "2                    3.0          1.0         3.0                        1.0   \n",
       "3                    2.0          1.0         1.0                        0.0   \n",
       "4                    3.0          1.0         0.0                        0.0   \n",
       "\n",
       "   category_income  \n",
       "0              3.0  \n",
       "1              2.0  \n",
       "2              0.0  \n",
       "3              1.0  \n",
       "4              2.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPTIONAL CELL: run this cell to have an insight on the categorical variables after label encoding\n",
    "df[catvars].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Dataset splitting.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold\n",
    "threshold = 0.7*len(df)\n",
    "\n",
    "# Splitting the dataset into train/test\n",
    "X_train = df.loc[:threshold].reset_index(drop=True)\n",
    "X_test = df.loc[threshold:].reset_index(drop=True)\n",
    "\n",
    "# Extracting the targets and features from the train/test datasets\n",
    "## For train dataset\n",
    "y_train = X_train['loan_status']\n",
    "X_train_features = X_train.drop('loan_status',axis=1)\n",
    "## For test dataset\n",
    "y_test = X_test['loan_status']\n",
    "X_test_features = X_test.drop('loan_status',axis=1)\n",
    "\n",
    "# Extract numvars from the rest of the features for train and test\n",
    "## For train\n",
    "X_num_train = X_train_features[numvars]\n",
    "X_cat_train = X_train_features[X_train_features.columns[~X_train_features.columns.isin(numvars)]]\n",
    "## For test\n",
    "X_num_test = X_test_features[numvars]\n",
    "X_cat_test = X_test_features[X_test_features.columns[~X_test_features.columns.isin(numvars)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='blue'>Scale the numerical variables using your preferred method.</font>\n",
    "<font color='blue'>Preferred method: Standard Scaler.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate StandardScaler model\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Fit and Transform the training numerical variables using StandardScaler\n",
    "X_num_train_std = pd.DataFrame(standard_scaler.fit_transform(X_num_train))\n",
    "\n",
    "# Transform the testing numerical variables using StandardScaler\n",
    "X_num_test_std = pd.DataFrame(standard_scaler.transform(X_num_test)) \n",
    "\n",
    "# Concatenate the processed data into two final dataframes: one for train and one for test.\n",
    "## Therefore, the new X_train is\n",
    "X_train = pd.concat([X_num_train_std, X_cat_train], axis=1)\n",
    "## Therefore, the new X_test is\n",
    "X_test = pd.concat([X_num_test_std, X_cat_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Programmatic nomenclature - formatting purposes only. Feel free to ignore</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name             | Shape           \n",
      "-----------------|-------\n",
      "X_num_train      | (N_T, D_n)\n",
      "X_cat_train      | (N_T, D_c)\n",
      "X_train          | (N_T, D)\n",
      "X_num_test       | (N_t, D_n)\n",
      "X_cat_test       | (N_t, D_c)\n",
      "X_test           | (N_t, D)\n",
      "y_train          | (N_T,)\n",
      "y_test           | (N_t,)\n",
      "\n",
      "Notation         | Value           \n",
      "-----------------|-------\n",
      "N_T              | 22807\n",
      "N_t              | 9774\n",
      "D_n              | 7\n",
      "D_c              | 5\n",
      "D                | 12\n"
     ]
    }
   ],
   "source": [
    "def recognizeNotation(s):\n",
    "    if s == X_train.shape[0]: return \"N_T\"\n",
    "    elif s == X_test.shape[0]: return \"N_t\"\n",
    "    elif s == len(numvars): return 'D_n'\n",
    "    elif s == len(catvars): return 'D_c'\n",
    "    elif s == X_test.shape[1]: return 'D'\n",
    "    elif s == embedding_dim: return'D_e'\n",
    "    else: return 'ERROR CHECK DATA'\n",
    "\n",
    "def generalTensorShape(s):\n",
    "    if len(s) == 1: return f'({recognizeNotation(s[0])},)'\n",
    "    elif len(s) == 2: return f'({recognizeNotation(s[0])}, {recognizeNotation(s[1])})'\n",
    "    elif len(s) == 3: return f'({recognizeNotation(s[0])}, {recognizeNotation(s[1])}, {recognizeNotation(s[2])})'\n",
    "    \n",
    "def printTable(titles, columns):\n",
    "    print(f\"{titles[0]:16} | {titles[1]:16}\")\n",
    "    print(\"-----------------|-------\")\n",
    "    for col1, col2 in columns:\n",
    "        print(f\"{col1:16} | {col2}\")\n",
    "# Define the tensor names and their shapes\n",
    "titlesTensorTable= ['Name', 'Shape']\n",
    "tensors = [\n",
    "    (\"X_num_train\", generalTensorShape(X_num_train.shape)),\n",
    "    (\"X_cat_train\", generalTensorShape(X_cat_train.shape)),\n",
    "    (\"X_train\", generalTensorShape(X_train.shape)),\n",
    "    (\"X_num_test\", generalTensorShape(X_num_test.shape)),\n",
    "    (\"X_cat_test\", generalTensorShape(X_cat_test.shape)),\n",
    "    (\"X_test\", generalTensorShape(X_test.shape)),\n",
    "    (\"y_train\", generalTensorShape(y_train.shape)),\n",
    "    (\"y_test\", generalTensorShape(y_test.shape))\n",
    "]\n",
    "\n",
    "titlesNotationTable= ['Notation', 'Value']\n",
    "notations = [\n",
    "    ('N_T', X_train.shape[0]),\n",
    "    ('N_t', X_test.shape[0]),\n",
    "    ('D_n', len(numvars)),\n",
    "    ('D_c', len(catvars)),\n",
    "    ('D', X_test.shape[1])\n",
    "]\n",
    "    \n",
    "printTable(titlesTensorTable, tensors)\n",
    "print('')\n",
    "printTable(titlesNotationTable, notations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLrioDXtz0q9"
   },
   "source": [
    "The following table summarizes the tensors you should create:\n",
    "\n",
    "| Description of the Tensor                                                                                                       | Name        | Shape        |\n",
    "|---------------------------------------------------------------------------------------------------------------------------------|-------------|--------------|\n",
    "| The tensor containing all the numerical features associated with the training dataset                                           | X_num_train | $(N_T, D_n)$ |\n",
    "| The tensor containing all the label encoded categorical features associated with the training dataset                           | X_cat_train | $(N_T, D_c)$ |\n",
    "| The tensor containing all the features (numerical and label encoded categorical features) associated with the training dataset  | X_train     | $(N_T, D)$   |\n",
    "| The tensor containing all the numerical features associated with the test dataset                                               | X_num_test  | $(N_t, D_n)$ |\n",
    "| The tensor containing all the label encoded categorical features associated with the test dataset                               | X_cat_test  | $(N_t, D_c)$ |\n",
    "| The tensor containing all the features (numerical and label encoded categorical features) associated with the test dataset      | X_test      | $(N_t, D)$   |\n",
    "| The training target tensor                                                                                                      | y_train     | $(N_T,)$   |\n",
    "| The test target tensor                                                                                                          | y_test      | $(N_t,)$   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mt6cgjbeW5eQ"
   },
   "source": [
    "where:\n",
    "\n",
    "|                  | Notation |\n",
    "|--------------------------------|----------|\n",
    "| Number of Training Data        | $N_T$    |\n",
    "| Number of Test Data            | $N_t$    |\n",
    "| Number of numerical features   | $D_n$    |\n",
    "| Number of categorical features | $D_c$    |\n",
    "| Number of all features         | $D$       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Z9whjHWS1Zk"
   },
   "source": [
    "# The Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd0J0i2xwit0"
   },
   "source": [
    "## Processing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eU3BnDwXXop"
   },
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uwCEGw18bk0"
   },
   "source": [
    "We denote $x_i \\in \\mathbb{R}^D$ the D-dimensional vector representing all the processed features:\n",
    "\n",
    "* The first $D_n$ dimensions are the numerical variables. \n",
    "* The last $D_c$ dimensions are the label encoded categorical variables. \n",
    "\n",
    "\n",
    "<center><img width=\"400\" src = \"https://drive.google.com/uc?export=view&id=1haI7b3oi60irjOv7W9iES99aUN1gPOMJ\"></center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McL-K8AYAh57"
   },
   "source": [
    "Therefore, the first $D_n$ indices $d \\in \\{1, \\dots, D_n\\}$ are associated with the numerical variables $x_i^d$. \n",
    "\n",
    "Each categorical variable $x_i^{d'}$ of index $d'$ (where $d' \\in \\{D_n +1, \\dots, D_n + D_c \\}$) has $n_{d'}$ possible categories, as summarized in the following table:\n",
    "\n",
    "| Categorical Variables      | Cardinalities                                                                                        |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| person_home_ownership     | 4                                                              |\n",
    "| loan_intent               | 6 |\n",
    "| loan_grade                | 7                                                             |\n",
    "| cb_person_default_on_file | 2                                                                                    |\n",
    "| category_income           | 4                                                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pD7g96wTS7DT"
   },
   "source": [
    "#### Encoding the numerical and the categorical variables into $D_e$-dimensional vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6H91f7TjqKsJ"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "What is the primary limitation of Label Encoding? How can this issue be circumvented?\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "The primary limitation of label encoding is the potential misleading **relative order or hierarchy among the categories**. In the specific case of our study, we do not want to encode any order of the labels. Label encoding introduces an arbitrary and implicit ordering of the categorical values. This implicit ordering can mislead machine learning algorithms into assuming a meaningful numerical relationship between the encoded values.\n",
    "    \n",
    "This issue can be circumvented using one-hot encoding instead of label encoding. \n",
    "        \n",
    "One-hot encoding is a categorical variable encoding technique that consists of first label-encoding some given categorical variables followed by the process of representing each unique category as a binary vector, where each vector indicates the presence or absence of that category in a data point, avoiding the implicit ordinal relationship introduced by Label Encoding. By using One Hot Encoding, we may overcome the limitations associated with Label Encoding, such as the misinterpretation of numerical labels, the inappropriate assumption of ordering and **removing any order relationship between the categories**. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIOUMZbZACP3"
   },
   "source": [
    "Let $D_e$ be the size of the embedding space. We would like to encode each feature (numerical or categorical) into a $D_e$-dimensional vector. To that end, we will use: \n",
    "\n",
    "* **Dense Layers** for numerical features. \n",
    "\n",
    "  Therefore, the numerical feature $x_i^d$ (for $d \\in \\{1, \\dots, D_n\\}$) will be mapped into a $D_e$-dimensional vector $\\xi_i^d \\in \\mathbb{R}^{D_e}$.\n",
    "\n",
    "\n",
    "* **Embedding Layers** for categorical features. \n",
    "\n",
    "  The idea is to represent each category as a vector in a continuous vector space, rather than using one-hot encoding or Label Encoding. This has the advantage of capturing more complex relationships between categories, which can be especially important when dealing with categorical variables that have many categories. Therefore, the categorical feature $x_i^{d'}$ (for $d' \\in \\{D_n + 1, \\dots, D_n + D_c\\}$) will be mapped into a $D_e$-dimensional vector $\\xi_i^{d'} \\in \\mathbb{R}^{D_e}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qK2VtRwxBnM1"
   },
   "source": [
    "#### Example: Exploring one of the categorical variables `loan_grade`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oY3difyn_2Vn"
   },
   "source": [
    "\n",
    "Suppose $d'$ is the index of the categorical variable `load_grade`, which has $n_{d'} = 7$ possible values, encoded into $\\{0, 1, \\dots, 6\\}$ using Label Encoding.\n",
    "\n",
    "Suppose we create an embedding layer (with the corresponding embedding_matrix $\\mathcal{E}_{d'}$) to process the categorical variable `load_grade`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlN3SbOEPgR6"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let's explain why the embedding matrix $\\mathcal{E}_{d'}$ associated with the categorical variable `loan_grade` is of shape $(n_{d'}, D_e$)\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The embedding matrix $\\mathcal{E}_{d'}$ associated with the categorical variable `loan_grade` is of shape $(n_{d'}, D_e$) because it represents the mapping of each category in the `loan_grade` variable to a $D_{e}$-dimensional vector. These dense vectors are stored in the embedding matrix. The rows of the embedding matrix correspond to the unique categorical values, and the columns represent the elements of the dense vectors.For example there are $n_{d'}$ unique values for the `loan_grade` variable, and each value is represented by a dense vector of length D. Each row in the matrix represents the embedding vector for a specific categorical value.</font>\n",
    "    \n",
    "<font color='blue'>In the case of categorical variables such as `loan_grade`, the goal is to represent each category as a vector in a continuous vector space. This representation allows capturing complex relationships between categories that may not be easily captured by one-hot encoding or label encoding.</font>\n",
    "\n",
    "<font color='blue'>The embedding matrix $\\mathcal{E}_{d'}$' is essentially a lookup table that maps each category index to its corresponding $D_{e}$-dimensional vector representation. The matrix has a shape of $(n_{d'}, D_e$), where $n_{d'}$ is the number of categories in the `loan_grade` variable, and $D_{e}$ is the size of the embedding space.</font>\n",
    "\n",
    "<font color='blue'>By using an embedding layer, the neural network learns to map each category index to a vector representation in a way that best captures the relationships between the categories based on the given data. The embedding layer essentially acts as a nonlinear projection from the index space to the continuous vector space, enabling the model to learn meaningful representations for the categorical variable.</font>\n",
    "    \n",
    "<font color='blue'>These embedding vectors are learned during the training process and are updated via backpropagation, just like any other weights in the network\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVFPeL10YDWF"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Therefore, let's investigate the embedding vector associated with the category 2 of `loan_grade`?\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "The embedding vector associated with the category 2 of the `loan_grade` variable would be a $D_{e}$-dimensional vector from the embedding matrix $\\mathcal{E}_{d'}$.\n",
    "\n",
    "Since `loan_grade` has been label encoded, the category 2 corresponds to the index 2. In the embedding matrix $\\mathcal{E}_{d'}$, the row at index 2 represents the embedding vector associated with category 2.\n",
    "\n",
    "To access the embedding vector for category 2, one can simply retrieve the row at index 2 from the embedding matrix $\\mathcal{E}_{d'}$. The values in that row would represent the $D_{e}$-dimensional vector representation for category 2.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ew1h6pDTtES"
   },
   "source": [
    "#### Introducing the `InputTransformation` Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m2yikIiT5MS"
   },
   "source": [
    "The following custom TensorFlow layer, named `InputTransformation`, is designed to process numerical and categorical features as described previously.\n",
    "\n",
    "This layer takes as input the numerical tensor `X_num_train` $\\in \\mathbb{R}^{N_T \\times D_n}$ and the categorical tensor `X_cat_train` $\\in \\mathbb{R}^{N_T \\times D_c}$ and transforms them into a more representative space (embedded space) which can be further processed by downstream layers.\n",
    "\n",
    "\n",
    "The `InputTransformation` class has several key attributes: \n",
    "\n",
    "| Attribute  | Notation      | Description                                                              |\n",
    "|-----------------|---------------|--------------------------------------------------------------------------|\n",
    "| embedding_dim   |$D_e$ | Dimension of the space to which the input features will be mapped.             |                                                  \n",
    "| num_numerical   | $D_n$           | Number of numerical features                                             |\n",
    "| num_categorical | $D_c$           | Number of categorical features                                           |\n",
    "| cardinalities   | cardinalities | List that contains the number of unique values (categories) for each categorical variable. |\n",
    "\n",
    "\n",
    "\n",
    "In the `call` method, the class processes the numerical and categorical features separately. \n",
    "\n",
    "* For each numerical feature, it applies a **Dense layer** (a linear operation with learnable weights and biases), which projects the numerical feature into the embedding space. \n",
    "  \n",
    "  Therefore, the numerical tensor  $\\begin{bmatrix}\n",
    "x_i^1 \\\\\n",
    "\\vdots\\\\\n",
    "x_i^{D_n}\\\\\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{D_n}$ is mapped into the list of tensors $\\left[\\xi_i^1 \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^d \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n} \\in \\mathbb{R}^{D_e} \\right]$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* For each categorical feature, it applies an **Embedding layer**, which assigns each category an embedding vector in the embedding space.\n",
    "\n",
    "  Therefore, the categorical tensor  $\\begin{bmatrix}\n",
    "x_i^{D_n+1} \\\\\n",
    "\\vdots\\\\\n",
    "x_i^{D_n + D_c}\\\\\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{D_c}$ is mapped into the list of tensors $\\left[\\xi_i^{D_n +1} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{d'} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n + D_c} \\in \\mathbb{R}^{D_e} \\right]$\n",
    "\n",
    "* The following graph summarizes these transformations: \n",
    "\n",
    "<center><img width=\"700\" src = \"https://drive.google.com/uc?export=view&id=1XGcCfnBVTvOR64kKWWQLMyOyg1CUfdTy\"></center>\n",
    "\n",
    "\n",
    "* Finally, it stacks all the embedded numerical features $\\left[\\xi_i^1 \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^d \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n} \\in \\mathbb{R}^{D_e} \\right]$ and the embeded categorical features $\\left[\\xi_i^{D_n +1} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{d'} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n + D_c} \\in \\mathbb{R}^{D_e} \\right]$ along the last axis, resulting in the tensor $\\left[\\xi_i^1 \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^d \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n} \\in \\mathbb{R}^{D_e}, \\xi_i^{D_n +1} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{d'} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n + D_c} \\in \\mathbb{R}^{D_e} \\right] \\in \\mathbb{R}^{D_e \\times (D_n + D_c)}$ as shown in the following graph: \n",
    "\n",
    "<center><img width=\"700\" src = \"https://drive.google.com/uc?export=view&id=1L-VOZBERHSgGLcc44pcYoCnbl7SIKkwa\"></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2Y9REiU6SXMD"
   },
   "outputs": [],
   "source": [
    "class InputTransformation(tf.keras.layers.Layer):\n",
    "  def __init__(self, embedding_dim, num_numerical, num_categorical, cardinalities, **kwargs):\n",
    "    super(InputTransformation, self).__init__(**kwargs)\n",
    "    # Define the Hyperparameters\n",
    "    self.embedding_dim = embedding_dim\n",
    "    self.num_numerical = num_numerical\n",
    "    self.num_categorical = num_categorical\n",
    "    self.cardinalities = cardinalities\n",
    "\n",
    "    # List of projections\n",
    "    self.list_projection_layers = [Dense(self.embedding_dim) for _ in range(self.num_numerical)]\n",
    "    # List of embedding layers\n",
    "    self.list_embedding_layers = [Embedding(input_dim=cardinality, output_dim=self.embedding_dim)\n",
    "                            for cardinality in self.cardinalities]\n",
    "\n",
    "  def call(self, x_num, x_cat):\n",
    "    \"\"\"\n",
    "    x_num (batch_size, num_numerical)\n",
    "    x_cat (batch_size, num_categorical)\n",
    "    \"\"\"\n",
    "    list_numerical_features = [] # list of num_numerical tensors[(batch_size, embedding_dim),...,(batch_size, embedding_dim)]\n",
    "    # Apply the projections on each feature x_num[:, i:i+1]\n",
    "    for i, projection in enumerate(self.list_projection_layers):\n",
    "      list_numerical_features.append(projection(x_num[:, i:i+1]))\n",
    "    list_categorical_features = [] # list of num_categorical tensors[(batch_size, embedding_dim),...,(batch_size, embedding_dim)]\n",
    "    # Apply the Embedding layers on each categorical feature x_cat[:, i:i+1]\n",
    "    for i, embedding_layer in enumerate(self.list_embedding_layers):\n",
    "      list_categorical_features.append(embedding_layer(x_cat[:, i]))\n",
    "    # stack all the embedding vectors (batch_size, embedding_dim, num_numerical + num_categorical)\n",
    "    stack_features = tf.stack(list_numerical_features + list_categorical_features, axis=-1)\n",
    "    return stack_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KN5lJlJ_pl_p"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let's apply the layer on `X_num_train` and `X_cat_train` as follows by filling the following code with the appropriate values.\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TfaoQvoxt4zH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22807, 64, 12)\n",
      "(N_T, D_e, D)\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the InputTransformation\n",
    "embedding_dim=64\n",
    "input_transformation = InputTransformation(\n",
    "  embedding_dim = embedding_dim, # HYPERPARAMETER: MIGHT CONSIDER GRID SEARCH FOR VALUES SUCH AS [8, 16, 32]\n",
    "  num_numerical = len(numvars), \n",
    "  num_categorical = len(catvars), \n",
    "  cardinalities = cardinalities\n",
    ") \n",
    "# Apply it on the tensors X_num_train and X_cat_train as follows:\n",
    "stack_features = input_transformation(np.array(X_num_train), np.array(X_cat_train))\n",
    "\n",
    "# Print the shape of stack_features\n",
    "print(stack_features.shape)\n",
    "print(generalTensorShape(stack_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBJ4r6awuCau"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let's explain the shape of `stack_features`\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The shape of `stack_features` is `(22807, 16, 12)` which corresponds to `(N_T, D_e, D)` where `N_T` is the number of training data, `D_e` is the embedding vector dimension, and `D` is the total number of features.</font>\n",
    "    \n",
    "<font color='blue'>This dimension for the stack_features tensor makes sense because, as discussed earlier in this notebook, the numerical tensor of length `D_n` is mapped into a list of tensors of length `D_e`. Same for the categorical tensor of length `D_n` which is mapped into a list of tensors of length `D_e`. </font>\n",
    "    \n",
    "<font color='blue'>After that, the two embeddings are concatenated, hence the dimension `D` which is just the sum of `D_c` and `D_n`.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTRuyw7LQaxE"
   },
   "source": [
    "## The Gated Residual Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZXQDBv1wtFW"
   },
   "source": [
    "#### The Gated Linear Unit Layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_089PsGovdJ0"
   },
   "source": [
    "The following custom `GatedLinearUnits` (GLU) layer is a special kind of layer introduced in the paper [Language Modeling with Gated Convolutional Networks](https://arxiv.org/pdf/1612.08083.pdf). In general, the purpose of gating mechanisms is to control the flow of information in a neural network, and the Gated Linear Units follow this principle.\n",
    "\n",
    "Here's how this custom TensorFlow layer works:\n",
    "\n",
    "* The `GatedLinearUnits` class has the following attribute: \n",
    "\n",
    "| Attribute  | Notation      | Description                                                              |\n",
    "|-----------------|---------------|--------------------------------------------------------------------------|\n",
    "| output_dim   | d_o             |   Dimension of the output vector                                               |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* **Initialization**: When the layer is instantiated, it takes an `output_dim` parameter, which defines the dimensionality of the output space of the layer. \n",
    "\n",
    "* Two dense (fully connected) layers are also initialized: `dense_filter` and `dense_vector`. The `dense_filter` layer uses a **sigmoid** activation function, which will output values between 0 and 1, while `dense_vector` has no activation function specified, meaning it will use a linear activation function by default.\n",
    "\n",
    "* In the `call` method, the input $\\eta \\in \\mathbb{R}^{d_i}$ is processed by both `dense_filter` and `dense_vector`. \n",
    "\n",
    "  * The input vector $\\eta \\in \\mathbb{R}^{d_i}$ is processed by the `dense_filter` layer to get $\\sigma \\left( W_f^T \\eta + b_f \\right) \\in \\mathbb{R}^{d_o}$.\n",
    "  \n",
    "  * The input vector $\\eta \\in \\mathbb{R}^{d_i}$ is also processed by the `dense_vector` layer to get $W^T \\eta + b\\in \\mathbb{R}^{d_o}\n",
    "$.\n",
    "  * The output is the Hadamard product between both output vectors: $\\sigma \\left( W_f^T \\eta + b_f \\right) \\circ \\left(W^T \\eta + b\\right) \\in \\mathbb{R}^{d_o} $.\n",
    "\n",
    "* The `GatedLinearUnit` layer is represented in the following graph: \n",
    "\n",
    "<center><img width=\"900\" src = \"https://drive.google.com/uc?export=view&id=11h7MJpm8t9z7IT03QWbUgAiE53CVzJzd\"></center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7rxVLND11p3b"
   },
   "outputs": [],
   "source": [
    "class GatedLinearUnits(tf.keras.layers.Layer):\n",
    "  def __init__(self, output_dim, **kwargs):\n",
    "    super(GatedLinearUnits, self).__init__(**kwargs)\n",
    "    self.output_dim = output_dim\n",
    "    self.dense_filter = Dense(output_dim, activation='sigmoid')\n",
    "    self.dense_vector = Dense(output_dim)\n",
    "  def call(self, x):\n",
    "    filter = self.dense_filter(x)\n",
    "    vector = self.dense_vector(x)\n",
    "    output = tf.multiply(filter, vector)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yX6GVjwm1zZ2"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let's understand the intuition behind this gating mechanism.\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "The intuition behind gating mechanisms is to control the flow of information within neural networks by performing three actions: erase information, write new information, and/or read parts of the information and output the vector that is processing data up to a specific time. Controlling the flow of information with gates is also done by modifying data on some dimensions and not necessarily all dimensions. \n",
    "\n",
    "The sigmoid activation function helps filter the information.To be specific, it is used on a vector that is going to transform some dimensions into values close to 0 and 1, then when two vectors are multiplied elementwise to each other, some dimensions are filtered out.Through this gating mechanism, the network will be able to capture the most relevant features and to mitigate noise features. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4EP2F0M1RkS"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "What is the total number of parameters of the `GatedLinearUnit` layer as a function of $d_i$ and $d_o$ ?\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "The `GatedLinearUnit` layer consists of two dense layers: `dense_filter` and `dense_vector`. \n",
    "\n",
    "The number of parameters in a dense layer is determined by the dimensions of its input and output. In this case, the input dimension is $d_{i}$ and the output dimension is $d_{o}$.\n",
    "\n",
    "The `dense_filter` layer has an input dimension of $d_{i}$ and an output dimension of $d_{o}$, which means it has $d_{i}*d_{o}$ weights and $d_{o}$ biases. Therefore, the number of parameters in `dense_filter` is $d_{i} * d_{o} + d_{o}$.\n",
    "\n",
    "Similarly, the `dense_vector` layer also has an input dimension of $d_{i}$ and an output dimension of $d_{o}$, resulting in $d_{i}*d_{o}$ weights and $d_{o}$ biases. Thus, the number of parameters in `dense_vector` is $d_{i}*d_{o} + d_{o}$.\n",
    "\n",
    "The total number of parameters in the GatedLinearUnit layer is the sum of the parameters in both dense layers:\n",
    "\n",
    "Total parameters = Parameters in `dense_filter` + Parameters in `dense_vector`<br/>\n",
    "               = $d_{i}*d_{o} + d_{o} + d_{i}*d_{o} + d_{o}$<br/>\n",
    "               = $2 * (d_{i}*d_{o} + d_{o})$<br/>\n",
    "               = $2 * d_{o}(d_{i} + 1)$<br/>\n",
    "\n",
    "Therefore, the total number of parameters in the `GatedLinearUnit` layer is $2 * d_{o}(d_{i} + 1)$.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hElmknMx1gyM"
   },
   "source": [
    "#### The Gated Residual Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ueu2RZCW7Jzn"
   },
   "source": [
    "The following custom`GatedResidualNetwork` layer is a layer that implements a Gated Residual Network architecture, which is a type of feed-forward neural network that includes gating mechanisms and residual connections. This can be helpful in controlling the flow of information through the network and mitigating problems such as vanishing gradients.\n",
    "\n",
    "\n",
    "\n",
    "* The input tensor $\\xi$ is first passed through the two Dense layers and then through the Dropout layer. The first Dense layer applies an Exponential Linear Unit (ELU) activation function, and the second Dense layer has no activation function specified, meaning it will use a linear activation function by default. The Dropout layer randomly sets a fraction (10% in this case) of the input units to 0 at each update during training, which helps prevent overfitting.\n",
    "\n",
    "* The output from the Dropout layer is passed through the `GatedLinearUnits` (GLU) layer described previously. This layer applies a gating mechanism that can help control the flow of information through the network.\n",
    "\n",
    "* Then, the output from the GLU layer is added to the input tensor. This forms a residual connection, which can help alleviate the vanishing gradient problem and improve the ability of the network to learn complex patterns.\n",
    "\n",
    "* Finally, the `LayerNormalization` layer is applied, which normalizes the output across the features (i.e., the last dimension) rather than across the batch. This can make the model more stable and faster to train.\n",
    "\n",
    "* The following graph summarizes the different steps of processing an input vector $\\xi \\in \\mathbb{R}^{d_i}$ into an output vector $\\tilde{\\xi} \\in \\mathbb{R}^{d_o}$ using the `GatedResidualNetwork`. \n",
    "\n",
    "<center><img width=\"500\" src = \"https://drive.google.com/uc?export=view&id=1Kf0zZgyDvzBxFDqLc0nzOPXwzT4TGABb\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KdJH2dOKSXME"
   },
   "outputs": [],
   "source": [
    "class GatedResidualNetwork(tf.keras.layers.Layer):\n",
    "  def __init__(self, hidden_dim, output_dim, **kwargs):\n",
    "    super(GatedResidualNetwork, self).__init__(**kwargs)\n",
    "    self.hidden_dim=hidden_dim\n",
    "    self.output_dim=output_dim\n",
    "    # Define the layers\n",
    "    self.projection = Dense(output_dim)\n",
    "    self.dense_1 = Dense(hidden_dim, activation=\"elu\")\n",
    "    self.dense_2 = Dense(hidden_dim)\n",
    "    self.dropout = Dropout(rate=0.1)\n",
    "    self.glu = GatedLinearUnits(output_dim)\n",
    "    self.layer_norm = LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    \"\"\"\n",
    "    x (batch_size, input_dim) -> output (batch_size, output_dim)\n",
    "    \"\"\"\n",
    "    input_dim = x.shape[-1]\n",
    "    z = self.dense_1(x) # (batch_size, hidden_dim)\n",
    "    z = self.dense_2(z) # (batch_size, hidden_dim)\n",
    "    z = self.dropout(z) # (batch_size, hidden_dim)\n",
    "    z = self.glu(z) # (batch_size, output_dim)\n",
    "    if input_dim != self.output_dim:\n",
    "      x = self.projection(x)\n",
    "    output = self.layer_norm(x + z) # (batch_size, output_dim)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoyNde0dLpZF"
   },
   "source": [
    "#### Getting the final output vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8aF3cvO9hhQ"
   },
   "source": [
    "We would like to apply a Gated Residual Network (GRN) to each of the embedded features $\\left[\\xi_i^1, \\dots, \\xi_i^d , \\dots, \\xi_i^{D_n} , \\xi_i^{D_n +1}, \\dots, \\xi_i^{d'}, \\dots, \\xi_i^{D_n + D_c} \\right] \\in \\mathbb{R}^{D_e \\times (D_n + D_c)}$ in order to get the following sequence of $D_o$-Dimensional vectors: $\\left[\\tilde{\\xi}_i^1, \\dots, \\tilde{\\xi}_i^d, \\dots, \\tilde{\\xi}_i^{D_n}, \\tilde{\\xi}_i^{D_n +1}, \\dots, \\tilde{\\xi}_i^{d'}, \\dots, \\tilde{\\xi}_i^{D_n + D_c} \\right] \\in \\mathbb{R}^{D_o \\times (D_n + D_c)}$ as shown in the following graph: \n",
    "\n",
    "<center><img width=\"700\" src = \"https://drive.google.com/uc?export=view&id=15lm1HCVFM3365iMWsIVA-X0JZ9qm3puL\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJiAC30JLxAV"
   },
   "source": [
    "Let $\\xi_i$ be the concatenation of all the vectors $\\left[\\xi_i^1, \\dots, \n",
    "\\xi_i^d , \\dots, \\xi_i^{D_n} , \\xi_i^{D_n +1}, \\dots, \\xi_i^{d'}, \\dots, \\xi_i^{D_n + D_c} \\right]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2aI-JIVJ4ca"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "What is the dimensionality of $\\xi_i$ ? \n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "<center><img width=\"700\" src = \"https://drive.google.com/uc?export=view&id=1L3hLN_9ljvKBo-NhYNlsRFtz-Jvl7B-P\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "$\\xi_i$ is a vector of size $D*D_e$ where $D = D_n + D_c$\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9OljENkMmlY"
   },
   "source": [
    "We want to apply a `GatedResidualNetwork` and a `Softmax` activation function on the vector $\\xi_i$ in order to get the vector $\\alpha_i$ of size $D_n + D_c$ as shown in the following figure:\n",
    "\n",
    "<center><img width=\"700\" src = \"https://drive.google.com/uc?export=view&id=1K3Ryx_M0lc9w8LUQdH6T7tuoJLStwVh3\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFCaLK1NNoPr"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let $\\psi_i$ be the output vector of the `GatedResidualNetwork` applied on $\\xi_i$. How can we get $\\alpha_i$ from $\\psi_i$ ?\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "To obtain $\\alpha_i$ from the output vector $\\psi_i$ of the `GatedResidualNetwork` applied on $\\xi_i$, we need to apply a `softmax` function to the elements of $\\psi_i$. \n",
    "\n",
    "Therefore,\n",
    "\n",
    "$\\alpha_i = softmax(\\psi_i)$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFfileR4OIk0"
   },
   "source": [
    "The final vector is $\\tilde{\\xi}_i = \\sum\\limits_{d=1}^{D_n + D_c} \\alpha_i^d \\tilde{\\xi}_i^{d}$ as shown in the following figure: \n",
    "\n",
    "<center><img width=\"1000\" src = \"https://drive.google.com/uc?export=view&id=1vYuM7IHblWHGXgblVzLRvOqHF24q923p\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Z_-BOMpO6ok"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "What is the interpretation of $\\alpha_i^d$ for all $d \\in \\{1, \\dots, D_n + D_c \\}$ ?\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "$\\alpha_i^d$ can be interpreted as the importance weight assigned to the -th embedded feature in the input vector $\\xi_i$.\n",
    "    \n",
    "Since the `GatedResidualNetwork` applies a `softmax` activation function to the output vector $\\psi_i$, the resulting $\\alpha_i^d$ values represent a probability distribution over the -th embedded features. \n",
    "    \n",
    "In the contex of our study on credit scoring, $\\alpha_i^d$ indicates the importance of each feature in determining the creditworthiness of an individual. Higher $\\alpha_i^d$ values suggest that a particular feature has a greater impact on the credit score prediction, indicating its significance in assessing creditworthiness.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GZJZCh6SXME"
   },
   "source": [
    "## The Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbhe1XJvRF6D"
   },
   "source": [
    "#### Coding the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlz1rcYAQ664"
   },
   "source": [
    "The following graph summarizes the whole Forward Propagation. \n",
    "\n",
    "The whole process is coded in the `FinalModel` model below. \n",
    "\n",
    "It takes as input the tensors $\\begin{bmatrix}\n",
    "x_i^1 \\\\\n",
    "\\vdots\\\\\n",
    "x_i^{D_n}\\\\\n",
    "\\end{bmatrix}$ and $\\begin{bmatrix}\n",
    "x_i^{D_n+1} \\\\\n",
    "\\vdots\\\\\n",
    "x_i^{D_n + D_c}\\\\\n",
    "\\end{bmatrix}$ and outputs the prediction tensor $\\tilde{\\xi}_i \\in \\mathbb{R}^{D_o}$ to which we apply a Dense layer to get a final prediction $\\in [0, 1]$ as it's a binary classification problem and the alpha coeffecitions  $\\alpha_i \\in \\mathbb{R}^{D_n + D_c}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMM08EmGSXME"
   },
   "source": [
    "<center><img width=\"1000\" src = \"https://drive.google.com/uc?export=view&id=1vYuM7IHblWHGXgblVzLRvOqHF24q923p\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eswmvY2HUg2z"
   },
   "outputs": [],
   "source": [
    "class VariableSelectionNetwork(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_features, hidden_dim, output_dim, **kwargs):\n",
    "        super(VariableSelectionNetwork, self).__init__(**kwargs)\n",
    "        self.num_features = num_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        # Layers\n",
    "        self.list_grns = [GatedResidualNetwork(hidden_dim=hidden_dim,\n",
    "                                               output_dim=output_dim) for _ in range(num_features)]\n",
    "        self.flatten_grn = GatedResidualNetwork(hidden_dim=hidden_dim,\n",
    "                                                output_dim=num_features)\n",
    "\n",
    "    def call(self, stack_features):\n",
    "        \"\"\"\n",
    "        stack_features (batch_size, embedding_dim, num_features) -> outputs (batch_size, output_dim), feature_weights (batch_size, num_features)\n",
    "        \"\"\"\n",
    "        # Apply the gated residual network to each feature vector\n",
    "        list_features = []\n",
    "        for i, grn in enumerate(self.list_grns):\n",
    "            feature = grn(stack_features[:, :, i])\n",
    "            list_features.append(feature)\n",
    "        # [(batch_size, output_dim), ..., (batch_size, output_dim)] of size num_features -> (batch_size, output_dim, num_features)\n",
    "        stacked_features = tf.stack(list_features, axis=-1)  # (batch_size, output_dim, num_features)\n",
    "        # Reshape stacked_features (batch_size, output_dim, num_features) -> (batch_size, output_dim*num_features)\n",
    "        batch_size = tf.shape(stacked_features)[0]\n",
    "        stack_features_reshaped = tf.reshape(stacked_features, shape=(batch_size, stacked_features.shape[1] * stacked_features.shape[2]))\n",
    "        # Apply GRN (batch_size, output_dim*num_features) -> (batch_size, num_features)\n",
    "        stack_features_reshaped = self.flatten_grn(stack_features_reshaped)\n",
    "        # Apply Softmax (batch_size, num_features) -> (batch_size, num_features)\n",
    "        weights = tf.nn.softmax(stack_features_reshaped, axis=-1)\n",
    "        # Reshape weigths(batch_size, num_features) -> (batch_size, 1, num_features)\n",
    "        weights_reshaped = weights[:, tf.newaxis, :]\n",
    "        # Multiply weights and stacked_features (batch_size, output_dim, num_features), (batch_size, 1, num_features) -> (batch_size, output_dim, num_features)\n",
    "        output = tf.multiply(stacked_features, weights_reshaped)\n",
    "        # Sum over the num_features axis (batch_size, output_dim, num_features) -> (batch_size, output_dim)\n",
    "        output = tf.reduce_sum(output, axis=-1)\n",
    "        return output, weights\n",
    "\n",
    "class FinalModel(tf.keras.models.Model):\n",
    "    def __init__(self, embedding_dim, num_numerical, num_categorical, cardinalities, hidden_dim, output_dim, **kwargs):\n",
    "        super(FinalModel, self).__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_numerical = num_numerical\n",
    "        self.num_categorical = num_categorical\n",
    "        self.cardinalities = cardinalities\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        # Layers\n",
    "        self.input_transformation = InputTransformation(embedding_dim=embedding_dim,\n",
    "                                                        num_numerical=num_numerical,\n",
    "                                                        num_categorical=num_categorical,\n",
    "                                                        cardinalities=cardinalities)\n",
    "        self.vsn = VariableSelectionNetwork(num_features=num_numerical + num_categorical,\n",
    "                                            hidden_dim=hidden_dim,\n",
    "                                            output_dim=output_dim)\n",
    "        self.dense = Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_num, x_cat = inputs\n",
    "        stack_features = self.input_transformation(x_num, x_cat)\n",
    "        output, alpha = self.vsn(stack_features)\n",
    "        output = self.dense(output)\n",
    "        return tf.squeeze(output), alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SS1aGmdlRL8t"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let's create a summary of the entire `FinalModel` by specifying the following elements: The different layers used, with a brief description of each layer and how the shape of the data changes after each layer transformation.\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>1. The input_transformation layer(the embedding layer): this layer transform the input data which includes both numerical and categorical features using hot encoding to prepare the data for further processing.The output shape is x_num and x_cat after transformation.</font>\n",
    "\n",
    "<font color='blue'>2. The VariableSelectionNetwork layer: this layer uses GNR to each feature vector and selects relevant features. This layer produces two outputs. The shape of 'output' is (batch_size,output_dim).The shape of 'weights' is (batch_size,num_features).</font>\n",
    "\n",
    "<font color='blue'>3. The Denser layer: this layer carries out a linear transformation by a sigmoid activation function to transform the selected features' outputs, the shape of this layer's outputs is (batch_size,1).</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpRI3XiRXtVG"
   },
   "source": [
    "#### The Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZUlXn6NX8lk"
   },
   "source": [
    "Let us apply the `FinalModel` on `(X_num_train, X_cat_train)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJYwOLDZYkVV"
   },
   "source": [
    "The following table summarizes the different hyperparameters of the `FinalModel`:\n",
    "\n",
    "| Attribute | Description |\n",
    "|-----------|-------------|\n",
    "| `embedding_dim` | The dimension of the embedding space for both numerical and categorical variables. |\n",
    "| `num_numerical` | The number of numerical features  |\n",
    "| `num_categorical` | The number of categorical features |\n",
    "| `cardinalities` | A list of integers specifying the number of distinct categories for each categorical feature. |\n",
    "| `hidden_dim` | The dimensionality of the hidden layers in the Gated Residual Networks (GRN) |\n",
    "| `output_dim` | The dimensionality of the output space of the GRNs |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoHr7DEYZNGQ"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let's complete the following code to create an instance of `FinalModel` and apply it to `(X_num_train, X_cat_train)`\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>The obvious way is to around with `hidden_dim` and `output_dim` until obtaining satisfactory results with the model.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZnNjkL12SXMF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (22807,)\n",
      "Alpha shape: (22807, 12)\n"
     ]
    }
   ],
   "source": [
    "## Create an instance of the model\n",
    "fm = FinalModel(embedding_dim= embedding_dim,\n",
    "                num_numerical= len(numvars),\n",
    "                num_categorical= len(catvars),\n",
    "                cardinalities=cardinalities,\n",
    "                hidden_dim=100,\n",
    "                output_dim=50)\n",
    "\n",
    "# Apply the model to the tensors x_num, x_cat\n",
    "output, alpha = fm((np.array(X_num_train), np.array(X_cat_train)))\n",
    "\n",
    "# Print the shape of the output tensor \n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "# Print the shape of the alpha tensor \n",
    "print(\"Alpha shape:\", alpha.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Y0kiBPFZ0l2"
   },
   "source": [
    "---\n",
    "<br><font color='green'>\n",
    "Let's explain why $\\frac{1}{N_T} \\sum\\limits_{i=1}^{N_T} \\sum\\limits_{d=1}^{D_n+D_c} \\alpha_i^d = 1$ and make sure your `alpha` tensor verifies the aforementioned equation.\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "The equation sums up all the weights assigned to each feature and computes their average. Since the weights are normalized using softmax, their sum across each sample in the batch will be 1. Therefore, when averaged over all samples, the resulting value will also be 1.\n",
    "    \n",
    "    \n",
    "To verify this, the following code computes the equation. As seen below, the result of the equation is 1, which confirms the statement.\n",
    "   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(N_T, D)\n",
      "Result of the equation:  1.0\n"
     ]
    }
   ],
   "source": [
    "N_T = alpha.shape[0]\n",
    "D = alpha.shape[1]\n",
    "print(generalTensorShape(alpha.shape))\n",
    "\n",
    "result = tf.reduce_sum(alpha).numpy()/N_T\n",
    "print(\"Result of the equation: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmNIAQZZbstb"
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xtl5FGVck7s"
   },
   "source": [
    "#### Preparing the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShApwZV6ydcy"
   },
   "source": [
    "The code is provided to you, no need to change it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "SGAb0YMLcyFn"
   },
   "outputs": [],
   "source": [
    "## Create the training dataset\n",
    "def create_dataset(X_num, X_cat, y, batch_size=32):\n",
    "    X_num = tf.data.Dataset.from_tensor_slices(X_num.astype('float32'))\n",
    "    X_cat = tf.data.Dataset.from_tensor_slices(X_cat.astype('int32'))\n",
    "    y = tf.data.Dataset.from_tensor_slices(y.astype('float32'))\n",
    "    dataset = tf.data.Dataset.zip(((X_num, X_cat), y)).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "## Training Process\n",
    "@tf.function\n",
    "def grad_fn(model, inputs, targets, loss_fn):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = model(inputs)  \n",
    "        loss_value = loss_fn(targets, predictions)\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    return loss_value, grads, predictions\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "## Train the model\n",
    "\n",
    "def train_model(model, num_epochs, train_dataset, test_dataset, optimizer, loss, grad_fn):\n",
    "    mean_train_loss = []\n",
    "    mean_train_auc = []\n",
    "    mean_train_f1 = []\n",
    "    mean_train_recall = []\n",
    "    mean_train_precision = []\n",
    "\n",
    "    mean_test_loss = []\n",
    "    mean_test_auc = []\n",
    "    mean_test_f1 = []\n",
    "    mean_test_recall = []\n",
    "    mean_test_precision = []\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        train_loss_tmp = []\n",
    "        train_auc_tmp = []\n",
    "        train_f1_tmp = []\n",
    "        train_recall_tmp = []\n",
    "        train_precision_tmp = []\n",
    "\n",
    "        print(f\"Epoch - {e}\")\n",
    "        for inputs, outputs in train_dataset:\n",
    "            g_loss, grads, y_pred = grad_fn(model, inputs, outputs, loss)\n",
    "\n",
    "            # Update metrics\n",
    "            auc = AUC()\n",
    "            precision = Precision()\n",
    "            recall = Recall()\n",
    "\n",
    "            auc.update_state(outputs, y_pred)\n",
    "            precision.update_state(outputs, y_pred)\n",
    "            recall.update_state(outputs, y_pred)\n",
    "\n",
    "            auc_result = auc.result().numpy()\n",
    "            precision_result = precision.result().numpy()\n",
    "            recall_result = recall.result().numpy()\n",
    "            f1_result = f1_score(precision_result, recall_result)\n",
    "\n",
    "            train_loss_tmp.append(g_loss)\n",
    "            train_auc_tmp.append(auc_result)\n",
    "            train_f1_tmp.append(f1_result)\n",
    "            train_recall_tmp.append(recall_result)\n",
    "            train_precision_tmp.append(precision_result)\n",
    "\n",
    "            print(f\"Train Loss - {g_loss};\\t Train AUC - {auc_result};\\t Train F1 Score - {f1_result};\\t Train Recall - {recall_result};\\t Train Precision - {precision_result}\")\n",
    "\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        mean_train_loss.append(np.mean(train_loss_tmp))\n",
    "        mean_train_auc.append(np.mean(train_auc_tmp))\n",
    "        mean_train_f1.append(np.mean(train_f1_tmp))\n",
    "        mean_train_recall.append(np.mean(train_recall_tmp))\n",
    "        mean_train_precision.append(np.mean(train_precision_tmp))\n",
    "\n",
    "        # Evaluate on test data\n",
    "        test_loss_tmp = []\n",
    "        test_auc_tmp = []\n",
    "        test_f1_tmp = []\n",
    "        test_recall_tmp = []\n",
    "        test_precision_tmp = []\n",
    "\n",
    "        for inputs, outputs in test_dataset:\n",
    "            y_pred, _ = model(inputs)\n",
    "            test_loss_value = loss(outputs, y_pred)\n",
    "\n",
    "            # Update metrics\n",
    "            auc = AUC()\n",
    "            precision = Precision()\n",
    "            recall = Recall()\n",
    "\n",
    "            auc.update_state(outputs, y_pred)\n",
    "            precision.update_state(outputs, y_pred)\n",
    "            recall.update_state(outputs, y_pred)\n",
    "\n",
    "            auc_result = auc.result().numpy()\n",
    "            precision_result = precision.result().numpy()\n",
    "            recall_result = recall.result().numpy()\n",
    "            f1_result = f1_score(precision_result, recall_result)\n",
    "\n",
    "            test_loss_tmp.append(test_loss_value)\n",
    "            test_auc_tmp.append(auc_result)\n",
    "            test_f1_tmp.append(f1_result)\n",
    "            test_recall_tmp.append(recall_result)\n",
    "            test_precision_tmp.append(precision_result)\n",
    "\n",
    "            print(f\"Test Loss - {test_loss_value};\\t Test AUC - {auc_result};\\t Test F1 Score - {f1_result};\\t Test Recall - {recall_result};\\t Test Precision - {precision_result}\")\n",
    "\n",
    "        mean_test_loss.append(np.mean(test_loss_tmp))\n",
    "        mean_test_auc.append(np.mean(test_auc_tmp))\n",
    "        mean_test_f1.append(np.mean(test_f1_tmp))\n",
    "        mean_test_recall.append(np.mean(test_recall_tmp))\n",
    "        mean_test_precision.append(np.mean(test_precision_tmp))\n",
    "\n",
    "    return mean_train_loss, mean_train_auc, mean_train_f1, mean_train_recall, mean_train_precision, mean_test_loss, mean_test_auc, mean_test_f1, mean_test_recall, mean_test_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdwSUfSnbupF"
   },
   "source": [
    "#### Preparing the Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcRh2hd3cG8G"
   },
   "source": [
    "---\n",
    "\n",
    "<br><font color='green'>\n",
    "Hyperparameters selection\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ld2S51KPZz1t"
   },
   "outputs": [],
   "source": [
    "num_numerical = len(numvars)\n",
    "num_categorical = len(catvars)\n",
    "cardinalities = cardinalities\n",
    "embedding_dim = embedding_dim\n",
    "hidden_dim = 70\n",
    "output_dim= 30\n",
    "epochs = 30\n",
    "batch_size = 600\n",
    "num_epochs = int(np.ceil(N_T / batch_size))\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBC7I9qey07Y"
   },
   "source": [
    "#### Create and instance `fm` of the `FinalModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "m75g5HpKeTZK"
   },
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "fm = FinalModel(embedding_dim=embedding_dim,\n",
    "                num_numerical=num_numerical,\n",
    "                num_categorical=num_categorical,\n",
    "                cardinalities=cardinalities,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim)\n",
    "\n",
    "# Defining the Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "# Defining the Loss function\n",
    "loss = tf.keras.losses.binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name             | Shape           \n",
      "-----------------|-------\n",
      "X_num_train      | (N_T, D_n)\n",
      "X_cat_train      | (N_T, D_c)\n",
      "X_train          | (N_T, D)\n",
      "X_num_test       | (N_t, D_n)\n",
      "X_cat_test       | (N_t, D_c)\n",
      "X_test           | (N_t, D)\n",
      "y_train          | (N_T,)\n",
      "y_test           | (N_t,)\n",
      "\n",
      "Notation         | Value           \n",
      "-----------------|-------\n",
      "N_T              | 22807\n",
      "N_t              | 9774\n",
      "D_n              | 7\n",
      "D_c              | 5\n",
      "D                | 12\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL CELL - formatting\n",
    "# Define the tensor names and their shapes\n",
    "titlesTensorTable= ['Name', 'Shape']\n",
    "tensors = [\n",
    "    (\"X_num_train\", generalTensorShape(X_num_train.shape)),\n",
    "    (\"X_cat_train\", generalTensorShape(X_cat_train.shape)),\n",
    "    (\"X_train\", generalTensorShape(X_train.shape)),\n",
    "    (\"X_num_test\", generalTensorShape(X_num_test.shape)),\n",
    "    (\"X_cat_test\", generalTensorShape(X_cat_test.shape)),\n",
    "    (\"X_test\", generalTensorShape(X_test.shape)),\n",
    "    (\"y_train\", generalTensorShape(y_train.shape)),\n",
    "    (\"y_test\", generalTensorShape(y_test.shape))\n",
    "]\n",
    "\n",
    "    \n",
    "printTable(titlesTensorTable, tensors)\n",
    "print('')\n",
    "printTable(titlesNotationTable, notations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAsTz33afUCo"
   },
   "source": [
    "Make sure the following tensors in this table are well defined and run the next cell to create `train_dataset`and `test_dataset`\n",
    "\n",
    "| Description of the Tensor                                                                                                       | Name        | Shape        |\n",
    "|---------------------------------------------------------------------------------------------------------------------------------|-------------|--------------|\n",
    "| The tensor containing all the numerical features associated with the training dataset                                           | X_num_train | $(N_T, D_n)$ |\n",
    "| The tensor containing all the label encoded categorical features associated with the training dataset                           | X_cat_train | $(N_T, D_c)$ |\n",
    "| The tensor containing all the features (numerical and label encoded categorical features) associated with the training dataset  | X_train     | $(N_T, D)$   |\n",
    "| The tensor containing all the numerical features associated with the test dataset                                               | X_num_test  | $(N_t, D_n)$ |\n",
    "| The tensor containing all the label encoded categorical features associated with the test dataset                               | X_cat_test  | $(N_t, D_c)$ |\n",
    "| The tensor containing all the features (numerical and label encoded categorical features) associated with the test dataset      | X_test      | $(N_t, D)$   |\n",
    "| The training target tensor                                                                                                      | y_train     | $(N_T,)$   |\n",
    "| The test target tensor                                                                                                          | y_test      | $(N_t,)$   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "xUuB3ggWcnDX"
   },
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(X_num_train, X_cat_train, y_train, batch_size=batch_size)\n",
    "test_dataset = create_dataset(X_num_test, X_cat_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q66X-qjCf7bO"
   },
   "source": [
    "#### The Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "id": "ToyLdl-IcUNT",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0\n",
      "Train Loss - 1.307241439819336;\t Train AUC - 0.42027488350868225;\t Train F1 Score - 0.3914209197536759;\t Train Recall - 1.0;\t Train Precision - 0.2433333396911621\n",
      "Train Loss - 0.6645025610923767;\t Train AUC - 0.646491289138794;\t Train F1 Score - 0.4142011863986645;\t Train Recall - 0.5645161271095276;\t Train Precision - 0.32710281014442444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-53d5bd3d0ff2>:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss - 0.509691059589386;\t Train AUC - 0.7610752582550049;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Train Loss - 0.5268133282661438;\t Train AUC - 0.8285597562789917;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Train Loss - 0.5252386331558228;\t Train AUC - 0.8591928482055664;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Train Loss - 0.5733336210250854;\t Train AUC - 0.8260940313339233;\t Train F1 Score - 0.012195121454532616;\t Train Recall - 0.0061349691823124886;\t Train Precision - 1.0\n",
      "Train Loss - 0.4885140061378479;\t Train AUC - 0.7738686203956604;\t Train F1 Score - 0.30409357554223326;\t Train Recall - 0.1843971610069275;\t Train Precision - 0.8666666746139526\n",
      "Train Loss - 0.4155932068824768;\t Train AUC - 0.8267416954040527;\t Train F1 Score - 0.4924622968569711;\t Train Recall - 0.3798449635505676;\t Train Precision - 0.699999988079071\n",
      "Train Loss - 0.40747880935668945;\t Train AUC - 0.85099858045578;\t Train F1 Score - 0.5497630561565229;\t Train Recall - 0.442748099565506;\t Train Precision - 0.7250000238418579\n",
      "Train Loss - 0.447003573179245;\t Train AUC - 0.8074795007705688;\t Train F1 Score - 0.44230768987815533;\t Train Recall - 0.35384616255760193;\t Train Precision - 0.5897436141967773\n",
      "Train Loss - 0.44874125719070435;\t Train AUC - 0.7973583936691284;\t Train F1 Score - 0.4935064760364951;\t Train Recall - 0.41911765933036804;\t Train Precision - 0.6000000238418579\n",
      "Train Loss - 0.453683078289032;\t Train AUC - 0.7954515218734741;\t Train F1 Score - 0.4134615476478878;\t Train Recall - 0.3359375;\t Train Precision - 0.5375000238418579\n",
      "Train Loss - 0.4162810146808624;\t Train AUC - 0.8084402084350586;\t Train F1 Score - 0.4897959148654809;\t Train Recall - 0.39344263076782227;\t Train Precision - 0.6486486196517944\n",
      "Train Loss - 0.4066738486289978;\t Train AUC - 0.8562532067298889;\t Train F1 Score - 0.5242718233647212;\t Train Recall - 0.3970588147640228;\t Train Precision - 0.7714285850524902\n",
      "Train Loss - 0.4089485704898834;\t Train AUC - 0.8260968923568726;\t Train F1 Score - 0.4252873589290488;\t Train Recall - 0.29600000381469727;\t Train Precision - 0.7551020383834839\n",
      "Train Loss - 0.40628719329833984;\t Train AUC - 0.7805929183959961;\t Train F1 Score - 0.379746842204789;\t Train Recall - 0.2542372941970825;\t Train Precision - 0.75\n",
      "Train Loss - 0.3844797611236572;\t Train AUC - 0.8230087161064148;\t Train F1 Score - 0.4074073908815326;\t Train Recall - 0.2844827473163605;\t Train Precision - 0.717391312122345\n",
      "Train Loss - 0.3655058443546295;\t Train AUC - 0.8747656345367432;\t Train F1 Score - 0.46327684540202524;\t Train Recall - 0.3253968358039856;\t Train Precision - 0.8039215803146362\n",
      "Train Loss - 0.39752259850502014;\t Train AUC - 0.8482439517974854;\t Train F1 Score - 0.5410627917612867;\t Train Recall - 0.39716312289237976;\t Train Precision - 0.8484848737716675\n",
      "Train Loss - 0.3710501492023468;\t Train AUC - 0.8614801168441772;\t Train F1 Score - 0.4431818410877367;\t Train Recall - 0.3145161271095276;\t Train Precision - 0.75\n",
      "Train Loss - 0.41259822249412537;\t Train AUC - 0.8420310020446777;\t Train F1 Score - 0.5370370261524441;\t Train Recall - 0.4000000059604645;\t Train Precision - 0.8169013857841492\n",
      "Train Loss - 0.3553108870983124;\t Train AUC - 0.8720194101333618;\t Train F1 Score - 0.5151515591092131;\t Train Recall - 0.3893129825592041;\t Train Precision - 0.7611940503120422\n",
      "Train Loss - 0.4047348201274872;\t Train AUC - 0.8251140713691711;\t Train F1 Score - 0.44334972059917843;\t Train Recall - 0.33088234066963196;\t Train Precision - 0.6716417670249939\n",
      "Train Loss - 0.35512009263038635;\t Train AUC - 0.8524391651153564;\t Train F1 Score - 0.568421004859807;\t Train Recall - 0.44999998807907104;\t Train Precision - 0.7714285850524902\n",
      "Train Loss - 0.3748722970485687;\t Train AUC - 0.866032600402832;\t Train F1 Score - 0.6399999981850386;\t Train Recall - 0.5517241358757019;\t Train Precision - 0.761904776096344\n",
      "Train Loss - 0.3655339777469635;\t Train AUC - 0.8562006950378418;\t Train F1 Score - 0.6584362184069287;\t Train Recall - 0.5925925970077515;\t Train Precision - 0.7407407164573669\n",
      "Train Loss - 0.36630794405937195;\t Train AUC - 0.8631187677383423;\t Train F1 Score - 0.6359832613019005;\t Train Recall - 0.5507246255874634;\t Train Precision - 0.7524752616882324\n",
      "Train Loss - 0.32736659049987793;\t Train AUC - 0.8663822412490845;\t Train F1 Score - 0.6153846227127339;\t Train Recall - 0.5454545617103577;\t Train Precision - 0.7058823704719543\n",
      "Train Loss - 0.36283379793167114;\t Train AUC - 0.8644997477531433;\t Train F1 Score - 0.5760000033037398;\t Train Recall - 0.5496183037757874;\t Train Precision - 0.605042040348053\n",
      "Train Loss - 0.3802468180656433;\t Train AUC - 0.8748801946640015;\t Train F1 Score - 0.6397058427486755;\t Train Recall - 0.5370370149612427;\t Train Precision - 0.7909091114997864\n",
      "Train Loss - 0.3358583450317383;\t Train AUC - 0.8844049572944641;\t Train F1 Score - 0.6283186016098072;\t Train Recall - 0.5378788113594055;\t Train Precision - 0.7553191781044006\n",
      "Train Loss - 0.3732304275035858;\t Train AUC - 0.828326940536499;\t Train F1 Score - 0.5306122210696114;\t Train Recall - 0.42975205183029175;\t Train Precision - 0.6933333277702332\n",
      "Train Loss - 0.3663245737552643;\t Train AUC - 0.8175433874130249;\t Train F1 Score - 0.5820106271927089;\t Train Recall - 0.4545454680919647;\t Train Precision - 0.8088235259056091\n",
      "Train Loss - 0.3554394543170929;\t Train AUC - 0.8604469895362854;\t Train F1 Score - 0.5208332940550625;\t Train Recall - 0.38167938590049744;\t Train Precision - 0.8196721076965332\n",
      "Train Loss - 0.33528319001197815;\t Train AUC - 0.8669524192810059;\t Train F1 Score - 0.5666666636608957;\t Train Recall - 0.41129031777381897;\t Train Precision - 0.9107142686843872\n",
      "Train Loss - 0.3315195143222809;\t Train AUC - 0.8835068941116333;\t Train F1 Score - 0.5888325033129473;\t Train Recall - 0.43609023094177246;\t Train Precision - 0.90625\n",
      "Train Loss - 0.3663851022720337;\t Train AUC - 0.8688265085220337;\t Train F1 Score - 0.536585349704994;\t Train Recall - 0.38732394576072693;\t Train Precision - 0.8730158805847168\n",
      "Train Loss - 0.3564276099205017;\t Train AUC - 0.8547240495681763;\t Train F1 Score - 0.6197183471655793;\t Train Recall - 0.48175182938575745;\t Train Precision - 0.8684210777282715\n",
      "Train Loss - 0.2277146875858307;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.31738826632499695;\t Test AUC - 0.8791229724884033;\t Test F1 Score - 0.5698324308528302;\t Test Recall - 0.43220338225364685;\t Test Precision - 0.8360655903816223\n",
      "Test Loss - 0.35990652441978455;\t Test AUC - 0.8520622253417969;\t Test F1 Score - 0.5189189233290387;\t Test Recall - 0.3692307770252228;\t Test Precision - 0.8727272748947144\n",
      "Test Loss - 0.335058331489563;\t Test AUC - 0.877295196056366;\t Test F1 Score - 0.5393258584351694;\t Test Recall - 0.3779527544975281;\t Test Precision - 0.9411764740943909\n",
      "Test Loss - 0.32394400238990784;\t Test AUC - 0.8800816535949707;\t Test F1 Score - 0.5937499830156182;\t Test Recall - 0.4523809552192688;\t Test Precision - 0.8636363744735718\n",
      "Test Loss - 0.33540070056915283;\t Test AUC - 0.8715173006057739;\t Test F1 Score - 0.5494505733206232;\t Test Recall - 0.3968254029750824;\t Test Precision - 0.8928571343421936\n",
      "Test Loss - 0.3153337240219116;\t Test AUC - 0.8664627075195312;\t Test F1 Score - 0.5421687282682783;\t Test Recall - 0.3947368562221527;\t Test Precision - 0.8653846383094788\n",
      "Test Loss - 0.3337995111942291;\t Test AUC - 0.8413900136947632;\t Test F1 Score - 0.5862069261592593;\t Test Recall - 0.4396551847457886;\t Test Precision - 0.8793103694915771\n",
      "Test Loss - 0.33983051776885986;\t Test AUC - 0.8470444679260254;\t Test F1 Score - 0.5465116442959737;\t Test Recall - 0.39830508828163147;\t Test Precision - 0.8703703880310059\n",
      "Test Loss - 0.34104999899864197;\t Test AUC - 0.8796172738075256;\t Test F1 Score - 0.5940593968349785;\t Test Recall - 0.43795621395111084;\t Test Precision - 0.9230769276618958\n",
      "Test Loss - 0.331412136554718;\t Test AUC - 0.8659729361534119;\t Test F1 Score - 0.5745856865280761;\t Test Recall - 0.42276424169540405;\t Test Precision - 0.8965517282485962\n",
      "Test Loss - 0.39023756980895996;\t Test AUC - 0.8458631038665771;\t Test F1 Score - 0.5242718113852899;\t Test Recall - 0.3776223659515381;\t Test Precision - 0.8571428656578064\n",
      "Test Loss - 0.3325034976005554;\t Test AUC - 0.8864917159080505;\t Test F1 Score - 0.6183575290105303;\t Test Recall - 0.46043166518211365;\t Test Precision - 0.9411764740943909\n",
      "Test Loss - 0.38248834013938904;\t Test AUC - 0.8412778973579407;\t Test F1 Score - 0.530612254636968;\t Test Recall - 0.38235294818878174;\t Test Precision - 0.8666666746139526\n",
      "Test Loss - 0.33060768246650696;\t Test AUC - 0.8634674549102783;\t Test F1 Score - 0.5714285779578387;\t Test Recall - 0.42276424169540405;\t Test Precision - 0.8813559412956238\n",
      "Test Loss - 0.37139660120010376;\t Test AUC - 0.8507547378540039;\t Test F1 Score - 0.560000014167173;\t Test Recall - 0.39716312289237976;\t Test Precision - 0.9491525292396545\n",
      "Test Loss - 0.3549501597881317;\t Test AUC - 0.8519617319107056;\t Test F1 Score - 0.4550898370328935;\t Test Recall - 0.31147539615631104;\t Test Precision - 0.8444444537162781\n",
      "Test Loss - 0.37037554383277893;\t Test AUC - 0.869498610496521;\t Test F1 Score - 0.576271192193956;\t Test Recall - 0.4047619104385376;\t Test Precision - 1.0\n",
      "Epoch - 1\n",
      "Train Loss - 0.33686888217926025;\t Train AUC - 0.9041548371315002;\t Train F1 Score - 0.5687203861347776;\t Train Recall - 0.4109589159488678;\t Train Precision - 0.9230769276618958\n",
      "Train Loss - 0.3479486107826233;\t Train AUC - 0.8461981415748596;\t Train F1 Score - 0.5586592046826314;\t Train Recall - 0.4032258093357086;\t Train Precision - 0.9090909361839294\n",
      "Train Loss - 0.3540118336677551;\t Train AUC - 0.8592672348022461;\t Train F1 Score - 0.5743589711847624;\t Train Recall - 0.4148148000240326;\t Train Precision - 0.9333333373069763\n",
      "Train Loss - 0.34776726365089417;\t Train AUC - 0.8690507411956787;\t Train F1 Score - 0.5624999884159572;\t Train Recall - 0.4153846204280853;\t Train Precision - 0.8709677457809448\n",
      "Train Loss - 0.3273448348045349;\t Train AUC - 0.8887189030647278;\t Train F1 Score - 0.5684210615269618;\t Train Recall - 0.40909090638160706;\t Train Precision - 0.931034505367279\n",
      "Train Loss - 0.3830718398094177;\t Train AUC - 0.8780516982078552;\t Train F1 Score - 0.5853658836403648;\t Train Recall - 0.44171780347824097;\t Train Precision - 0.8674699068069458\n",
      "Train Loss - 0.3939283788204193;\t Train AUC - 0.8319195508956909;\t Train F1 Score - 0.5196078488984792;\t Train Recall - 0.3758865296840668;\t Train Precision - 0.841269850730896\n",
      "Train Loss - 0.31316956877708435;\t Train AUC - 0.8861238956451416;\t Train F1 Score - 0.7009346182569809;\t Train Recall - 0.5813953280448914;\t Train Precision - 0.8823529481887817\n",
      "Train Loss - 0.29838114976882935;\t Train AUC - 0.9194485545158386;\t Train F1 Score - 0.6909091030000967;\t Train Recall - 0.580152690410614;\t Train Precision - 0.8539325594902039\n",
      "Train Loss - 0.3269677758216858;\t Train AUC - 0.8849673271179199;\t Train F1 Score - 0.6846846865879167;\t Train Recall - 0.5846154093742371;\t Train Precision - 0.8260869383811951\n",
      "Train Loss - 0.34604009985923767;\t Train AUC - 0.8724169731140137;\t Train F1 Score - 0.6890756099586328;\t Train Recall - 0.6029411554336548;\t Train Precision - 0.8039215803146362\n",
      "Train Loss - 0.3518121540546417;\t Train AUC - 0.8597390651702881;\t Train F1 Score - 0.5945945522625486;\t Train Recall - 0.515625;\t Train Precision - 0.7021276354789734\n",
      "Train Loss - 0.3047005832195282;\t Train AUC - 0.8936141133308411;\t Train F1 Score - 0.6787329968883603;\t Train Recall - 0.6147540807723999;\t Train Precision - 0.7575757503509521\n",
      "Train Loss - 0.3260168731212616;\t Train AUC - 0.8838741779327393;\t Train F1 Score - 0.6752136649293857;\t Train Recall - 0.5808823704719543;\t Train Precision - 0.8061224222183228\n",
      "Train Loss - 0.3062104284763336;\t Train AUC - 0.8874105215072632;\t Train F1 Score - 0.6944444700206824;\t Train Recall - 0.6000000238418579;\t Train Precision - 0.8241758346557617\n",
      "Train Loss - 0.3557792007923126;\t Train AUC - 0.8164339661598206;\t Train F1 Score - 0.5999999820548328;\t Train Recall - 0.4576271176338196;\t Train Precision - 0.8709677457809448\n",
      "Train Loss - 0.30039897561073303;\t Train AUC - 0.8848674893379211;\t Train F1 Score - 0.66666663935155;\t Train Recall - 0.517241358757019;\t Train Precision - 0.9375\n",
      "Train Loss - 0.27207791805267334;\t Train AUC - 0.9153522849082947;\t Train F1 Score - 0.696078396479474;\t Train Recall - 0.5634920597076416;\t Train Precision - 0.9102563858032227\n",
      "Train Loss - 0.342528373003006;\t Train AUC - 0.8729971051216125;\t Train F1 Score - 0.6457398787482557;\t Train Recall - 0.5106382966041565;\t Train Precision - 0.8780487775802612\n",
      "Train Loss - 0.29616886377334595;\t Train AUC - 0.8970249891281128;\t Train F1 Score - 0.7035175527454637;\t Train Recall - 0.5645161271095276;\t Train Precision - 0.9333333373069763\n",
      "Train Loss - 0.3462831676006317;\t Train AUC - 0.8782492876052856;\t Train F1 Score - 0.6810344969052936;\t Train Recall - 0.5448275804519653;\t Train Precision - 0.9080459475517273\n",
      "Train Loss - 0.2908976078033447;\t Train AUC - 0.9072575569152832;\t Train F1 Score - 0.6883720888048852;\t Train Recall - 0.5648854970932007;\t Train Precision - 0.8809523582458496\n",
      "Train Loss - 0.3399178683757782;\t Train AUC - 0.8714027404785156;\t Train F1 Score - 0.6638655166548313;\t Train Recall - 0.5808823704719543;\t Train Precision - 0.7745097875595093\n",
      "Train Loss - 0.2716921865940094;\t Train AUC - 0.9080381393432617;\t Train F1 Score - 0.7407407760620117;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.8333333134651184\n",
      "Train Loss - 0.3278314471244812;\t Train AUC - 0.8788480758666992;\t Train F1 Score - 0.7426471234551939;\t Train Recall - 0.6965517401695251;\t Train Precision - 0.7952755689620972\n",
      "Train Loss - 0.29810890555381775;\t Train AUC - 0.8909120559692383;\t Train F1 Score - 0.7567568247534793;\t Train Recall - 0.7259259223937988;\t Train Precision - 0.7903226017951965\n",
      "Train Loss - 0.3074271082878113;\t Train AUC - 0.893602192401886;\t Train F1 Score - 0.7199999639689127;\t Train Recall - 0.6521739363670349;\t Train Precision - 0.8035714030265808\n",
      "Train Loss - 0.28749293088912964;\t Train AUC - 0.884397029876709;\t Train F1 Score - 0.7005076131481222;\t Train Recall - 0.6272727251052856;\t Train Precision - 0.7931034564971924\n",
      "Train Loss - 0.29482436180114746;\t Train AUC - 0.9005680680274963;\t Train F1 Score - 0.7490347223084172;\t Train Recall - 0.7404580116271973;\t Train Precision - 0.7578125\n",
      "Train Loss - 0.3186218738555908;\t Train AUC - 0.9048072099685669;\t Train F1 Score - 0.7455196381821269;\t Train Recall - 0.6419752836227417;\t Train Precision - 0.8888888955116272\n",
      "Train Loss - 0.2894672155380249;\t Train AUC - 0.9035385847091675;\t Train F1 Score - 0.7090908826814669;\t Train Recall - 0.5909090638160706;\t Train Precision - 0.8863636255264282\n",
      "Train Loss - 0.30375298857688904;\t Train AUC - 0.8757570385932922;\t Train F1 Score - 0.7029703260667143;\t Train Recall - 0.586776852607727;\t Train Precision - 0.8765432238578796\n",
      "Train Loss - 0.3115294277667999;\t Train AUC - 0.8601425290107727;\t Train F1 Score - 0.6938775626160214;\t Train Recall - 0.5619834661483765;\t Train Precision - 0.9066666960716248\n",
      "Train Loss - 0.2857109606266022;\t Train AUC - 0.9075993895530701;\t Train F1 Score - 0.7047619433220237;\t Train Recall - 0.5648854970932007;\t Train Precision - 0.9367088675498962\n",
      "Train Loss - 0.29077479243278503;\t Train AUC - 0.8908156156539917;\t Train F1 Score - 0.7368421052631579;\t Train Recall - 0.6209677457809448;\t Train Precision - 0.9058823585510254\n",
      "Train Loss - 0.2926221489906311;\t Train AUC - 0.900122344493866;\t Train F1 Score - 0.7096774142125215;\t Train Recall - 0.5789473652839661;\t Train Precision - 0.9166666865348816\n",
      "Train Loss - 0.30336371064186096;\t Train AUC - 0.8930822610855103;\t Train F1 Score - 0.716666629158865;\t Train Recall - 0.6056337952613831;\t Train Precision - 0.8775510191917419\n",
      "Train Loss - 0.30242928862571716;\t Train AUC - 0.8801374435424805;\t Train F1 Score - 0.7723577458716386;\t Train Recall - 0.6934306621551514;\t Train Precision - 0.8715596199035645\n",
      "Train Loss - 0.20746289193630219;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.27745676040649414;\t Test AUC - 0.8964062333106995;\t Test F1 Score - 0.7298578473811144;\t Test Recall - 0.6525423526763916;\t Test Precision - 0.8279569745063782\n",
      "Test Loss - 0.32810938358306885;\t Test AUC - 0.8586743474006653;\t Test F1 Score - 0.6637930668333508;\t Test Recall - 0.5923076868057251;\t Test Precision - 0.7549019455909729\n",
      "Test Loss - 0.27717775106430054;\t Test AUC - 0.9035475254058838;\t Test F1 Score - 0.7339449360099403;\t Test Recall - 0.6299212574958801;\t Test Precision - 0.8791208863258362\n",
      "Test Loss - 0.27260085940361023;\t Test AUC - 0.9035311937332153;\t Test F1 Score - 0.7387387815554521;\t Test Recall - 0.6507936716079712;\t Test Precision - 0.8541666865348816\n",
      "Test Loss - 0.28317660093307495;\t Test AUC - 0.8955780267715454;\t Test F1 Score - 0.7383177409339615;\t Test Recall - 0.6269841194152832;\t Test Precision - 0.8977272510528564\n",
      "Test Loss - 0.26378732919692993;\t Test AUC - 0.8943036794662476;\t Test F1 Score - 0.7389162361994148;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.8426966071128845\n",
      "Test Loss - 0.3055892586708069;\t Test AUC - 0.846599817276001;\t Test F1 Score - 0.6903553486244025;\t Test Recall - 0.5862069129943848;\t Test Precision - 0.8395061492919922\n",
      "Test Loss - 0.29357069730758667;\t Test AUC - 0.8741296529769897;\t Test F1 Score - 0.6836734421055323;\t Test Recall - 0.5677965879440308;\t Test Precision - 0.8589743375778198\n",
      "Test Loss - 0.29765641689300537;\t Test AUC - 0.8847881555557251;\t Test F1 Score - 0.7404255109282829;\t Test Recall - 0.6350364685058594;\t Test Precision - 0.8877550959587097\n",
      "Test Loss - 0.3056153357028961;\t Test AUC - 0.8675751090049744;\t Test F1 Score - 0.6981132797442471;\t Test Recall - 0.6016260385513306;\t Test Precision - 0.8314606547355652\n",
      "Test Loss - 0.328561931848526;\t Test AUC - 0.8693593144416809;\t Test F1 Score - 0.7107437822180884;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.868686854839325\n",
      "Test Loss - 0.2881413698196411;\t Test AUC - 0.902331531047821;\t Test F1 Score - 0.7264957494946112;\t Test Recall - 0.6115108132362366;\t Test Precision - 0.8947368264198303\n",
      "Test Loss - 0.31193724274635315;\t Test AUC - 0.8783912658691406;\t Test F1 Score - 0.7142857484063312;\t Test Recall - 0.5882353186607361;\t Test Precision - 0.9090909361839294\n",
      "Test Loss - 0.3112545311450958;\t Test AUC - 0.8644219636917114;\t Test F1 Score - 0.6889951962659505;\t Test Recall - 0.5853658318519592;\t Test Precision - 0.8372092843055725\n",
      "Test Loss - 0.3040176331996918;\t Test AUC - 0.8857908248901367;\t Test F1 Score - 0.732510316774279;\t Test Recall - 0.631205677986145;\t Test Precision - 0.8725489974021912\n",
      "Test Loss - 0.29990750551223755;\t Test AUC - 0.8762689232826233;\t Test F1 Score - 0.6930692474587696;\t Test Recall - 0.5737704634666443;\t Test Precision - 0.875\n",
      "Test Loss - 0.3401915729045868;\t Test AUC - 0.8745490312576294;\t Test F1 Score - 0.6769230818786948;\t Test Recall - 0.523809552192688;\t Test Precision - 0.95652174949646\n",
      "Epoch - 2\n",
      "Train Loss - 0.262277215719223;\t Train AUC - 0.9271393418312073;\t Train F1 Score - 0.7803030154264459;\t Train Recall - 0.7054794430732727;\t Train Precision - 0.8728813529014587\n",
      "Train Loss - 0.30686384439468384;\t Train AUC - 0.8708999752998352;\t Train F1 Score - 0.6600000697887308;\t Train Recall - 0.5322580933570862;\t Train Precision - 0.8684210777282715\n",
      "Train Loss - 0.31369322538375854;\t Train AUC - 0.872512936592102;\t Train F1 Score - 0.7314814836034823;\t Train Recall - 0.585185170173645;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.28673991560935974;\t Train AUC - 0.9031914472579956;\t Train F1 Score - 0.6732672989852047;\t Train Recall - 0.5230769515037537;\t Train Precision - 0.9444444179534912\n",
      "Train Loss - 0.3028877079486847;\t Train AUC - 0.896715521812439;\t Train F1 Score - 0.6540284072876444;\t Train Recall - 0.5227272510528564;\t Train Precision - 0.8734177350997925\n",
      "Train Loss - 0.3210478723049164;\t Train AUC - 0.9027389883995056;\t Train F1 Score - 0.7185184597137962;\t Train Recall - 0.5950919985771179;\t Train Precision - 0.9065420627593994\n",
      "Train Loss - 0.36241474747657776;\t Train AUC - 0.8495032787322998;\t Train F1 Score - 0.6329113751683291;\t Train Recall - 0.5319148898124695;\t Train Precision - 0.78125\n",
      "Train Loss - 0.27527162432670593;\t Train AUC - 0.9055942296981812;\t Train F1 Score - 0.761133576343407;\t Train Recall - 0.7286821603775024;\t Train Precision - 0.7966101765632629\n",
      "Train Loss - 0.25053298473358154;\t Train AUC - 0.9325754046440125;\t Train F1 Score - 0.7698744535589542;\t Train Recall - 0.7022900581359863;\t Train Precision - 0.8518518805503845\n",
      "Train Loss - 0.2857922315597534;\t Train AUC - 0.9023404121398926;\t Train F1 Score - 0.7634854375816668;\t Train Recall - 0.7076923251152039;\t Train Precision - 0.8288288116455078\n",
      "Train Loss - 0.28292977809906006;\t Train AUC - 0.8961396813392639;\t Train F1 Score - 0.77732796625599;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.8648648858070374\n",
      "Train Loss - 0.30516865849494934;\t Train AUC - 0.8794772624969482;\t Train F1 Score - 0.6877828144139266;\t Train Recall - 0.59375;\t Train Precision - 0.8172042965888977\n",
      "Train Loss - 0.2516218423843384;\t Train AUC - 0.9081641435623169;\t Train F1 Score - 0.747663571123099;\t Train Recall - 0.6557376980781555;\t Train Precision - 0.8695651888847351\n",
      "Train Loss - 0.28491899371147156;\t Train AUC - 0.9010522365570068;\t Train F1 Score - 0.7500000195150023;\t Train Recall - 0.6617646813392639;\t Train Precision - 0.8653846383094788\n",
      "Train Loss - 0.2591356337070465;\t Train AUC - 0.9081599712371826;\t Train F1 Score - 0.7677725161126622;\t Train Recall - 0.6480000019073486;\t Train Precision - 0.9418604373931885\n",
      "Train Loss - 0.3274760842323303;\t Train AUC - 0.8308601379394531;\t Train F1 Score - 0.6594594614909093;\t Train Recall - 0.5169491767883301;\t Train Precision - 0.9104477763175964\n",
      "Train Loss - 0.25603097677230835;\t Train AUC - 0.8989829421043396;\t Train F1 Score - 0.7512690721950485;\t Train Recall - 0.6379310488700867;\t Train Precision - 0.9135802388191223\n",
      "Train Loss - 0.2479926347732544;\t Train AUC - 0.9232469201087952;\t Train F1 Score - 0.7383177409339615;\t Train Recall - 0.6269841194152832;\t Train Precision - 0.8977272510528564\n",
      "Train Loss - 0.30620691180229187;\t Train AUC - 0.8860535621643066;\t Train F1 Score - 0.7355372220021348;\t Train Recall - 0.631205677986145;\t Train Precision - 0.8811880946159363\n",
      "Train Loss - 0.26007547974586487;\t Train AUC - 0.9110022783279419;\t Train F1 Score - 0.7488986926663075;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.8252426981925964\n",
      "Train Loss - 0.30497685074806213;\t Train AUC - 0.8832285404205322;\t Train F1 Score - 0.7419354914225054;\t Train Recall - 0.634482741355896;\t Train Precision - 0.893203854560852\n",
      "Train Loss - 0.2556972801685333;\t Train AUC - 0.9161770343780518;\t Train F1 Score - 0.758620647031184;\t Train Recall - 0.6717557311058044;\t Train Precision - 0.8712871074676514\n",
      "Train Loss - 0.3045410215854645;\t Train AUC - 0.8853083848953247;\t Train F1 Score - 0.7086613560406836;\t Train Recall - 0.6617646813392639;\t Train Precision - 0.7627118825912476\n",
      "Train Loss - 0.24523183703422546;\t Train AUC - 0.9167014360427856;\t Train F1 Score - 0.7570093443443972;\t Train Recall - 0.675000011920929;\t Train Precision - 0.8617021441459656\n",
      "Train Loss - 0.2918526232242584;\t Train AUC - 0.8930806517601013;\t Train F1 Score - 0.7686274602300581;\t Train Recall - 0.6758620738983154;\t Train Precision - 0.8909090757369995\n",
      "Train Loss - 0.25482654571533203;\t Train AUC - 0.908825159072876;\t Train F1 Score - 0.7863247572278441;\t Train Recall - 0.6814814805984497;\t Train Precision - 0.9292929172515869\n",
      "Train Loss - 0.269755482673645;\t Train AUC - 0.9114749431610107;\t Train F1 Score - 0.7543859370931956;\t Train Recall - 0.6231883764266968;\t Train Precision - 0.9555555582046509\n",
      "Train Loss - 0.2635376751422882;\t Train AUC - 0.8888311386108398;\t Train F1 Score - 0.7173913390890344;\t Train Recall - 0.6000000238418579;\t Train Precision - 0.8918918967247009\n",
      "Train Loss - 0.2658078968524933;\t Train AUC - 0.907623827457428;\t Train F1 Score - 0.7598253660867301;\t Train Recall - 0.6641221642494202;\t Train Precision - 0.8877550959587097\n",
      "Train Loss - 0.29286372661590576;\t Train AUC - 0.9150952696800232;\t Train F1 Score - 0.7573529082818578;\t Train Recall - 0.6358024477958679;\t Train Precision - 0.9363636374473572\n",
      "Train Loss - 0.2642730474472046;\t Train AUC - 0.9062662124633789;\t Train F1 Score - 0.7657657657657657;\t Train Recall - 0.6439393758773804;\t Train Precision - 0.9444444179534912\n",
      "Train Loss - 0.2795984148979187;\t Train AUC - 0.8818820118904114;\t Train F1 Score - 0.7014218139512184;\t Train Recall - 0.6115702390670776;\t Train Precision - 0.8222222328186035\n",
      "Train Loss - 0.28209036588668823;\t Train AUC - 0.8749547004699707;\t Train F1 Score - 0.7184466550408477;\t Train Recall - 0.6115702390670776;\t Train Precision - 0.8705882430076599\n",
      "Train Loss - 0.25249624252319336;\t Train AUC - 0.9105861186981201;\t Train F1 Score - 0.784140983546463;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9270833134651184\n",
      "Train Loss - 0.26471269130706787;\t Train AUC - 0.8959999084472656;\t Train F1 Score - 0.7706422310727951;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.8936170339584351\n",
      "Train Loss - 0.27088436484336853;\t Train AUC - 0.9028916358947754;\t Train F1 Score - 0.7598253281781427;\t Train Recall - 0.6541353464126587;\t Train Precision - 0.90625\n",
      "Train Loss - 0.29973194003105164;\t Train AUC - 0.8826572895050049;\t Train F1 Score - 0.7457626910866054;\t Train Recall - 0.6197183132171631;\t Train Precision - 0.936170220375061\n",
      "Train Loss - 0.2766806185245514;\t Train AUC - 0.8922372460365295;\t Train F1 Score - 0.7815126294656232;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.9207921028137207\n",
      "Train Loss - 0.09825865179300308;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2609293758869171;\t Test AUC - 0.8947798013687134;\t Test F1 Score - 0.763819077305559;\t Test Recall - 0.6440678238868713;\t Test Precision - 0.9382715821266174\n",
      "Test Loss - 0.316261351108551;\t Test AUC - 0.851252019405365;\t Test F1 Score - 0.7047619549091485;\t Test Recall - 0.5692307949066162;\t Test Precision - 0.925000011920929\n",
      "Test Loss - 0.2636079788208008;\t Test AUC - 0.9072015285491943;\t Test F1 Score - 0.7523809220835409;\t Test Recall - 0.6220472455024719;\t Test Precision - 0.9518072009086609\n",
      "Test Loss - 0.2724970579147339;\t Test AUC - 0.8958374857902527;\t Test F1 Score - 0.7254901915131828;\t Test Recall - 0.5873016119003296;\t Test Precision - 0.9487179517745972\n",
      "Test Loss - 0.27565550804138184;\t Test AUC - 0.8966244459152222;\t Test F1 Score - 0.7171717024075827;\t Test Recall - 0.5634920597076416;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.24384109675884247;\t Test AUC - 0.9037433862686157;\t Test F1 Score - 0.7486630687764925;\t Test Recall - 0.6140350699424744;\t Test Precision - 0.9589040875434875\n",
      "Test Loss - 0.29292017221450806;\t Test AUC - 0.8588184118270874;\t Test F1 Score - 0.69273748016135;\t Test Recall - 0.5344827771186829;\t Test Precision - 0.9841269850730896\n",
      "Test Loss - 0.28865838050842285;\t Test AUC - 0.8779186010360718;\t Test F1 Score - 0.6666666397489155;\t Test Recall - 0.508474588394165;\t Test Precision - 0.9677419066429138\n",
      "Test Loss - 0.3038989305496216;\t Test AUC - 0.874186098575592;\t Test F1 Score - 0.7247706915309876;\t Test Recall - 0.5766423344612122;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.2946351170539856;\t Test AUC - 0.8659814596176147;\t Test F1 Score - 0.7046632168926413;\t Test Recall - 0.5528455376625061;\t Test Precision - 0.9714285731315613\n",
      "Test Loss - 0.3138059377670288;\t Test AUC - 0.8816085457801819;\t Test F1 Score - 0.7058823937775779;\t Test Recall - 0.5454545617103577;\t Test Precision - 1.0\n",
      "Test Loss - 0.29719480872154236;\t Test AUC - 0.9040402770042419;\t Test F1 Score - 0.7155962801296412;\t Test Recall - 0.5611510872840881;\t Test Precision - 0.9873417615890503\n",
      "Test Loss - 0.3089628219604492;\t Test AUC - 0.8850468993186951;\t Test F1 Score - 0.6919431590148741;\t Test Recall - 0.5367646813392639;\t Test Precision - 0.9733333587646484\n",
      "Test Loss - 0.2928893268108368;\t Test AUC - 0.873123049736023;\t Test F1 Score - 0.6943005913402389;\t Test Recall - 0.5447154641151428;\t Test Precision - 0.9571428298950195\n",
      "Test Loss - 0.30056241154670715;\t Test AUC - 0.8934702277183533;\t Test F1 Score - 0.6940639150710427;\t Test Recall - 0.5390070676803589;\t Test Precision - 0.9743589758872986\n",
      "Test Loss - 0.2933075428009033;\t Test AUC - 0.8785924911499023;\t Test F1 Score - 0.6984127021324994;\t Test Recall - 0.5409836173057556;\t Test Precision - 0.9850746393203735\n",
      "Test Loss - 0.36140039563179016;\t Test AUC - 0.8721139430999756;\t Test F1 Score - 0.576271192193956;\t Test Recall - 0.4047619104385376;\t Test Precision - 1.0\n",
      "Epoch - 3\n",
      "Train Loss - 0.26021671295166016;\t Train AUC - 0.9276144504547119;\t Train F1 Score - 0.7563025021629916;\t Train Recall - 0.6164383292198181;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.3075003921985626;\t Train AUC - 0.8784646987915039;\t Train F1 Score - 0.6043956011013862;\t Train Recall - 0.44354838132858276;\t Train Precision - 0.9482758641242981\n",
      "Train Loss - 0.30062049627304077;\t Train AUC - 0.8815451860427856;\t Train F1 Score - 0.7014217783019108;\t Train Recall - 0.5481481552124023;\t Train Precision - 0.9736841917037964\n",
      "Train Loss - 0.278158962726593;\t Train AUC - 0.8992389440536499;\t Train F1 Score - 0.7211538446637299;\t Train Recall - 0.5769230723381042;\t Train Precision - 0.9615384340286255\n",
      "Train Loss - 0.2874038517475128;\t Train AUC - 0.8896173238754272;\t Train F1 Score - 0.7214612536968764;\t Train Recall - 0.5984848737716675;\t Train Precision - 0.9080459475517273\n",
      "Train Loss - 0.297210693359375;\t Train AUC - 0.9092108607292175;\t Train F1 Score - 0.7588652444225106;\t Train Recall - 0.6564416885375977;\t Train Precision - 0.8991596698760986\n",
      "Train Loss - 0.3439788818359375;\t Train AUC - 0.852562665939331;\t Train F1 Score - 0.6497889892422004;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.8020833134651184\n",
      "Train Loss - 0.2538410723209381;\t Train AUC - 0.9070342779159546;\t Train F1 Score - 0.7863247446558028;\t Train Recall - 0.713178277015686;\t Train Precision - 0.8761904835700989\n",
      "Train Loss - 0.2372995764017105;\t Train AUC - 0.9343576431274414;\t Train F1 Score - 0.7911111329398683;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9468085169792175\n",
      "Train Loss - 0.2767791748046875;\t Train AUC - 0.9011538624763489;\t Train F1 Score - 0.7477477770254183;\t Train Recall - 0.6384615302085876;\t Train Precision - 0.9021739363670349\n",
      "Train Loss - 0.27160364389419556;\t Train AUC - 0.8980175256729126;\t Train F1 Score - 0.776371298510674;\t Train Recall - 0.6764705777168274;\t Train Precision - 0.9108911156654358\n",
      "Train Loss - 0.30313751101493835;\t Train AUC - 0.886536717414856;\t Train F1 Score - 0.6698113336081537;\t Train Recall - 0.5546875;\t Train Precision - 0.8452380895614624\n",
      "Train Loss - 0.24135446548461914;\t Train AUC - 0.9087386131286621;\t Train F1 Score - 0.7547169476402701;\t Train Recall - 0.6557376980781555;\t Train Precision - 0.8888888955116272\n",
      "Train Loss - 0.26793473958969116;\t Train AUC - 0.9057587385177612;\t Train F1 Score - 0.7594936145248506;\t Train Recall - 0.6617646813392639;\t Train Precision - 0.8910890817642212\n",
      "Train Loss - 0.25059133768081665;\t Train AUC - 0.9071158170700073;\t Train F1 Score - 0.7720930159152924;\t Train Recall - 0.6639999747276306;\t Train Precision - 0.9222221970558167\n",
      "Train Loss - 0.3126280903816223;\t Train AUC - 0.8362754583358765;\t Train F1 Score - 0.7021277034744015;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.9428571462631226\n",
      "Train Loss - 0.24607788026332855;\t Train AUC - 0.9000872373580933;\t Train F1 Score - 0.755102047042686;\t Train Recall - 0.6379310488700867;\t Train Precision - 0.925000011920929\n",
      "Train Loss - 0.23628170788288116;\t Train AUC - 0.9266793727874756;\t Train F1 Score - 0.7793427243928007;\t Train Recall - 0.658730149269104;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.3043118417263031;\t Train AUC - 0.8887807726860046;\t Train F1 Score - 0.7404255250089762;\t Train Recall - 0.6170212626457214;\t Train Precision - 0.9255319237709045\n",
      "Train Loss - 0.23853622376918793;\t Train AUC - 0.9178385138511658;\t Train F1 Score - 0.7798164910590738;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9042553305625916\n",
      "Train Loss - 0.2830882966518402;\t Train AUC - 0.8954527974128723;\t Train F1 Score - 0.7654320571223916;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.9489796161651611\n",
      "Train Loss - 0.2508198320865631;\t Train AUC - 0.9166978597640991;\t Train F1 Score - 0.7644444282604024;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.914893627166748\n",
      "Train Loss - 0.29874327778816223;\t Train AUC - 0.8840564489364624;\t Train F1 Score - 0.7394957850492777;\t Train Recall - 0.6470588445663452;\t Train Precision - 0.8627451062202454\n",
      "Train Loss - 0.230105459690094;\t Train AUC - 0.9247483015060425;\t Train F1 Score - 0.7924527702293738;\t Train Recall - 0.699999988079071;\t Train Precision - 0.9130434989929199\n",
      "Train Loss - 0.2783689498901367;\t Train AUC - 0.903433084487915;\t Train F1 Score - 0.7710843391615417;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9230769276618958\n",
      "Train Loss - 0.24869443476200104;\t Train AUC - 0.9123616218566895;\t Train F1 Score - 0.7800830141105615;\t Train Recall - 0.6962962746620178;\t Train Precision - 0.8867924809455872\n",
      "Train Loss - 0.26103606820106506;\t Train AUC - 0.913184642791748;\t Train F1 Score - 0.7679325111182985;\t Train Recall - 0.6594203114509583;\t Train Precision - 0.9191918969154358\n",
      "Train Loss - 0.2502652108669281;\t Train AUC - 0.8947309255599976;\t Train F1 Score - 0.7553191513817092;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9102563858032227\n",
      "Train Loss - 0.25599196553230286;\t Train AUC - 0.9076970815658569;\t Train F1 Score - 0.7860262018461438;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.918367326259613\n",
      "Train Loss - 0.2791798412799835;\t Train AUC - 0.9167935252189636;\t Train F1 Score - 0.7765567773708023;\t Train Recall - 0.654321014881134;\t Train Precision - 0.954954981803894\n",
      "Train Loss - 0.24835418164730072;\t Train AUC - 0.9146189093589783;\t Train F1 Score - 0.7782805599908217;\t Train Recall - 0.6515151262283325;\t Train Precision - 0.966292142868042\n",
      "Train Loss - 0.26635655760765076;\t Train AUC - 0.8855397701263428;\t Train F1 Score - 0.7317073593593508;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.8928571343421936\n",
      "Train Loss - 0.2758145332336426;\t Train AUC - 0.873746931552887;\t Train F1 Score - 0.7326732526229317;\t Train Recall - 0.6115702390670776;\t Train Precision - 0.9135802388191223\n",
      "Train Loss - 0.2437761127948761;\t Train AUC - 0.9147040247917175;\t Train F1 Score - 0.7853881321852059;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9772727489471436\n",
      "Train Loss - 0.2565705478191376;\t Train AUC - 0.897041916847229;\t Train F1 Score - 0.769953019462892;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.9213483333587646\n",
      "Train Loss - 0.26357272267341614;\t Train AUC - 0.9067395925521851;\t Train F1 Score - 0.7488987056354016;\t Train Recall - 0.6390977501869202;\t Train Precision - 0.9042553305625916\n",
      "Train Loss - 0.29115790128707886;\t Train AUC - 0.8837875127792358;\t Train F1 Score - 0.754237293271679;\t Train Recall - 0.6267605423927307;\t Train Precision - 0.9468085169792175\n",
      "Train Loss - 0.27008718252182007;\t Train AUC - 0.8966751098632812;\t Train F1 Score - 0.7833333209060114;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9126213788986206\n",
      "Train Loss - 0.08284943550825119;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2486058622598648;\t Test AUC - 0.8964589834213257;\t Test F1 Score - 0.7777777859790963;\t Test Recall - 0.6525423526763916;\t Test Precision - 0.9624999761581421\n",
      "Test Loss - 0.2989570200443268;\t Test AUC - 0.8587561249732971;\t Test F1 Score - 0.7383177980281479;\t Test Recall - 0.607692301273346;\t Test Precision - 0.9404761791229248\n",
      "Test Loss - 0.24778304994106293;\t Test AUC - 0.9193704128265381;\t Test F1 Score - 0.7655502566421422;\t Test Recall - 0.6299212574958801;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.24668559432029724;\t Test AUC - 0.9064446687698364;\t Test F1 Score - 0.7596153788495695;\t Test Recall - 0.6269841194152832;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.2589522898197174;\t Test AUC - 0.9035897850990295;\t Test F1 Score - 0.748768540855477;\t Test Recall - 0.60317462682724;\t Test Precision - 0.9870129823684692\n",
      "Test Loss - 0.23060661554336548;\t Test AUC - 0.906613290309906;\t Test F1 Score - 0.7619046834380785;\t Test Recall - 0.6315789222717285;\t Test Precision - 0.9599999785423279\n",
      "Test Loss - 0.27582451701164246;\t Test AUC - 0.8701642155647278;\t Test F1 Score - 0.7071823243002076;\t Test Recall - 0.5517241358757019;\t Test Precision - 0.9846153855323792\n",
      "Test Loss - 0.27333566546440125;\t Test AUC - 0.8823317289352417;\t Test F1 Score - 0.6956521841963229;\t Test Recall - 0.5423728823661804;\t Test Precision - 0.9696969985961914\n",
      "Test Loss - 0.2774200439453125;\t Test AUC - 0.8874998092651367;\t Test F1 Score - 0.7589285914173466;\t Test Recall - 0.6204379796981812;\t Test Precision - 0.977011501789093\n",
      "Test Loss - 0.2811395823955536;\t Test AUC - 0.8706345558166504;\t Test F1 Score - 0.7309644351634075;\t Test Recall - 0.5853658318519592;\t Test Precision - 0.9729729890823364\n",
      "Test Loss - 0.29907113313674927;\t Test AUC - 0.8888770341873169;\t Test F1 Score - 0.7053571122028929;\t Test Recall - 0.5524475574493408;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.274679958820343;\t Test AUC - 0.9122177362442017;\t Test F1 Score - 0.7387386999426422;\t Test Recall - 0.5899280309677124;\t Test Precision - 0.9879518151283264\n",
      "Test Loss - 0.2936294674873352;\t Test AUC - 0.8890323638916016;\t Test F1 Score - 0.7222222992044808;\t Test Recall - 0.5735294222831726;\t Test Precision - 0.9750000238418579\n",
      "Test Loss - 0.2790355086326599;\t Test AUC - 0.8815513849258423;\t Test F1 Score - 0.7373737742625337;\t Test Recall - 0.5934959053993225;\t Test Precision - 0.9733333587646484\n",
      "Test Loss - 0.28296568989753723;\t Test AUC - 0.8995966911315918;\t Test F1 Score - 0.725663748880196;\t Test Recall - 0.5815602540969849;\t Test Precision - 0.9647058844566345\n",
      "Test Loss - 0.281993567943573;\t Test AUC - 0.8822450041770935;\t Test F1 Score - 0.6878307444861179;\t Test Recall - 0.5327869057655334;\t Test Precision - 0.9701492786407471\n",
      "Test Loss - 0.326605886220932;\t Test AUC - 0.8828462958335876;\t Test F1 Score - 0.7076922780663315;\t Test Recall - 0.5476190447807312;\t Test Precision - 1.0\n",
      "Epoch - 4\n",
      "Train Loss - 0.24526341259479523;\t Train AUC - 0.9349616765975952;\t Train F1 Score - 0.7750000073298757;\t Train Recall - 0.6369863152503967;\t Train Precision - 0.9893617033958435\n",
      "Train Loss - 0.2910248935222626;\t Train AUC - 0.8828865885734558;\t Train F1 Score - 0.6595744680851063;\t Train Recall - 0.5;\t Train Precision - 0.96875\n",
      "Train Loss - 0.2859596908092499;\t Train AUC - 0.8860135674476624;\t Train F1 Score - 0.7289719825481786;\t Train Recall - 0.5777778029441833;\t Train Precision - 0.9873417615890503\n",
      "Train Loss - 0.264609158039093;\t Train AUC - 0.903510570526123;\t Train F1 Score - 0.7428571688074636;\t Train Recall - 0.6000000238418579;\t Train Precision - 0.9750000238418579\n",
      "Train Loss - 0.27255287766456604;\t Train AUC - 0.8961570858955383;\t Train F1 Score - 0.7522935877049512;\t Train Recall - 0.6212121248245239;\t Train Precision - 0.9534883499145508\n",
      "Train Loss - 0.2807193398475647;\t Train AUC - 0.914208710193634;\t Train F1 Score - 0.765343035459101;\t Train Recall - 0.650306761264801;\t Train Precision - 0.9298245906829834\n",
      "Train Loss - 0.3294360935688019;\t Train AUC - 0.860929548740387;\t Train F1 Score - 0.6523605133348901;\t Train Recall - 0.5390070676803589;\t Train Precision - 0.8260869383811951\n",
      "Train Loss - 0.23483172059059143;\t Train AUC - 0.9155268669128418;\t Train F1 Score - 0.8034188467109026;\t Train Recall - 0.7286821603775024;\t Train Precision - 0.8952381014823914\n",
      "Train Loss - 0.22952015697956085;\t Train AUC - 0.9372385740280151;\t Train F1 Score - 0.7787610487441214;\t Train Recall - 0.6717557311058044;\t Train Precision - 0.9263157844543457\n",
      "Train Loss - 0.25972259044647217;\t Train AUC - 0.9094517230987549;\t Train F1 Score - 0.7665198019930097;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.8969072103500366\n",
      "Train Loss - 0.2550794184207916;\t Train AUC - 0.9047524333000183;\t Train F1 Score - 0.7949790961152128;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.9223300814628601\n",
      "Train Loss - 0.28517428040504456;\t Train AUC - 0.8872897624969482;\t Train F1 Score - 0.6990291706207117;\t Train Recall - 0.5625;\t Train Precision - 0.9230769276618958\n",
      "Train Loss - 0.2306521087884903;\t Train AUC - 0.9135571718215942;\t Train F1 Score - 0.7902439074036137;\t Train Recall - 0.6639344096183777;\t Train Precision - 0.9759036302566528\n",
      "Train Loss - 0.2634690999984741;\t Train AUC - 0.9067491888999939;\t Train F1 Score - 0.7711864758644842;\t Train Recall - 0.6691176295280457;\t Train Precision - 0.9100000262260437\n",
      "Train Loss - 0.2409440577030182;\t Train AUC - 0.9107873439788818;\t Train F1 Score - 0.7809524145770362;\t Train Recall - 0.656000018119812;\t Train Precision - 0.9647058844566345\n",
      "Train Loss - 0.29697564244270325;\t Train AUC - 0.8475543260574341;\t Train F1 Score - 0.698924772017837;\t Train Recall - 0.5508474707603455;\t Train Precision - 0.9558823704719543\n",
      "Train Loss - 0.22637435793876648;\t Train AUC - 0.9091978073120117;\t Train F1 Score - 0.7857142490636684;\t Train Recall - 0.6637930870056152;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.22953349351882935;\t Train AUC - 0.9297685623168945;\t Train F1 Score - 0.7850467138534467;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.2964027225971222;\t Train AUC - 0.8911834359169006;\t Train F1 Score - 0.7499999242184727;\t Train Recall - 0.6170212626457214;\t Train Precision - 0.9560439586639404\n",
      "Train Loss - 0.23420988023281097;\t Train AUC - 0.9169998168945312;\t Train F1 Score - 0.7798164910590738;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9042553305625916\n",
      "Train Loss - 0.2789110243320465;\t Train AUC - 0.8956499099731445;\t Train F1 Score - 0.7654320571223916;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.9489796161651611\n",
      "Train Loss - 0.239338681101799;\t Train AUC - 0.9201647043228149;\t Train F1 Score - 0.7692307634754508;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9444444179534912\n",
      "Train Loss - 0.2867555618286133;\t Train AUC - 0.8886045813560486;\t Train F1 Score - 0.752136753455679;\t Train Recall - 0.6470588445663452;\t Train Precision - 0.8979591727256775\n",
      "Train Loss - 0.2188921570777893;\t Train AUC - 0.9273437857627869;\t Train F1 Score - 0.8019323514025234;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.26617294549942017;\t Train AUC - 0.9057900905609131;\t Train F1 Score - 0.7786885082519794;\t Train Recall - 0.6551724076271057;\t Train Precision - 0.9595959782600403\n",
      "Train Loss - 0.23581969738006592;\t Train AUC - 0.9155476093292236;\t Train F1 Score - 0.7983193012398682;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9223300814628601\n",
      "Train Loss - 0.2504972219467163;\t Train AUC - 0.9141963720321655;\t Train F1 Score - 0.774468068277331;\t Train Recall - 0.6594203114509583;\t Train Precision - 0.938144326210022\n",
      "Train Loss - 0.24623824656009674;\t Train AUC - 0.8927273154258728;\t Train F1 Score - 0.7513226831101855;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.8987341523170471\n",
      "Train Loss - 0.2470739185810089;\t Train AUC - 0.9116522073745728;\t Train F1 Score - 0.7946428402313757;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9569892287254333\n",
      "Train Loss - 0.2643771469593048;\t Train AUC - 0.9215006828308105;\t Train F1 Score - 0.786764699442033;\t Train Recall - 0.6604938507080078;\t Train Precision - 0.9727272987365723\n",
      "Train Loss - 0.24110981822013855;\t Train AUC - 0.9178645610809326;\t Train F1 Score - 0.780269064253531;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9560439586639404\n",
      "Train Loss - 0.2613503336906433;\t Train AUC - 0.8873599767684937;\t Train F1 Score - 0.7299999516093557;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9240506291389465\n",
      "Train Loss - 0.2680523097515106;\t Train AUC - 0.877473771572113;\t Train F1 Score - 0.7336683144652802;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9358974099159241\n",
      "Train Loss - 0.23912999033927917;\t Train AUC - 0.9175849556922913;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.24715794622898102;\t Train AUC - 0.8979144096374512;\t Train F1 Score - 0.7772512024474851;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.9425287246704102\n",
      "Train Loss - 0.2563244700431824;\t Train AUC - 0.9065866470336914;\t Train F1 Score - 0.765765813597401;\t Train Recall - 0.6390977501869202;\t Train Precision - 0.9550561904907227\n",
      "Train Loss - 0.2883782386779785;\t Train AUC - 0.8858479261398315;\t Train F1 Score - 0.7445888033537915;\t Train Recall - 0.6056337952613831;\t Train Precision - 0.966292142868042\n",
      "Train Loss - 0.2599894106388092;\t Train AUC - 0.898882269859314;\t Train F1 Score - 0.7815126294656232;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.9207921028137207\n",
      "Train Loss - 0.07235783338546753;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.23992304503917694;\t Test AUC - 0.8983842134475708;\t Test F1 Score - 0.7839196278686282;\t Test Recall - 0.6610169410705566;\t Test Precision - 0.9629629850387573\n",
      "Test Loss - 0.2862805128097534;\t Test AUC - 0.8635023832321167;\t Test F1 Score - 0.7441860661031489;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9411764740943909\n",
      "Test Loss - 0.2384265661239624;\t Test AUC - 0.9200862050056458;\t Test F1 Score - 0.7714285798712358;\t Test Recall - 0.6377952694892883;\t Test Precision - 0.9759036302566528\n",
      "Test Loss - 0.2411666363477707;\t Test AUC - 0.9040502309799194;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.24889551103115082;\t Test AUC - 0.9081357717514038;\t Test F1 Score - 0.7549019264164886;\t Test Recall - 0.6111111044883728;\t Test Precision - 0.9871794581413269\n",
      "Test Loss - 0.22654825448989868;\t Test AUC - 0.9055212736129761;\t Test F1 Score - 0.7684210541992628;\t Test Recall - 0.640350878238678;\t Test Precision - 0.9605262875556946\n",
      "Test Loss - 0.26640990376472473;\t Test AUC - 0.8761488795280457;\t Test F1 Score - 0.7071823243002076;\t Test Recall - 0.5517241358757019;\t Test Precision - 0.9846153855323792\n",
      "Test Loss - 0.26766255497932434;\t Test AUC - 0.8837031722068787;\t Test F1 Score - 0.7165775405212216;\t Test Recall - 0.5677965879440308;\t Test Precision - 0.9710144996643066\n",
      "Test Loss - 0.2642242908477783;\t Test AUC - 0.897550106048584;\t Test F1 Score - 0.7533632243285249;\t Test Recall - 0.6131386756896973;\t Test Precision - 0.9767441749572754\n",
      "Test Loss - 0.2703588306903839;\t Test AUC - 0.8745632171630859;\t Test F1 Score - 0.733668311255766;\t Test Recall - 0.5934959053993225;\t Test Precision - 0.9605262875556946\n",
      "Test Loss - 0.29902541637420654;\t Test AUC - 0.8794127106666565;\t Test F1 Score - 0.734513317724582;\t Test Recall - 0.5804196000099182;\t Test Precision - 1.0\n",
      "Test Loss - 0.26473140716552734;\t Test AUC - 0.9143244624137878;\t Test F1 Score - 0.7522124325475137;\t Test Recall - 0.6115108132362366;\t Test Precision - 0.977011501789093\n",
      "Test Loss - 0.2854462265968323;\t Test AUC - 0.8905854225158691;\t Test F1 Score - 0.7222222992044808;\t Test Recall - 0.5735294222831726;\t Test Precision - 0.9750000238418579\n",
      "Test Loss - 0.2709208130836487;\t Test AUC - 0.8808099031448364;\t Test F1 Score - 0.7363184251748605;\t Test Recall - 0.6016260385513306;\t Test Precision - 0.9487179517745972\n",
      "Test Loss - 0.2744176387786865;\t Test AUC - 0.9002766013145447;\t Test F1 Score - 0.7368421052631579;\t Test Recall - 0.5957446694374084;\t Test Precision - 0.9655172228813171\n",
      "Test Loss - 0.2754875421524048;\t Test AUC - 0.8821936249732971;\t Test F1 Score - 0.7187499687815715;\t Test Recall - 0.5655737519264221;\t Test Precision - 0.9857142567634583\n",
      "Test Loss - 0.3129923343658447;\t Test AUC - 0.8810425996780396;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 5\n",
      "Train Loss - 0.23645569384098053;\t Train AUC - 0.9406116008758545;\t Train F1 Score - 0.7717842158355093;\t Train Recall - 0.6369863152503967;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.28095266222953796;\t Train AUC - 0.8818700909614563;\t Train F1 Score - 0.6875000198305865;\t Train Recall - 0.5322580933570862;\t Train Precision - 0.970588207244873\n",
      "Train Loss - 0.2707499563694;\t Train AUC - 0.8940421938896179;\t Train F1 Score - 0.7431192896507454;\t Train Recall - 0.6000000238418579;\t Train Precision - 0.9759036302566528\n",
      "Train Loss - 0.25086238980293274;\t Train AUC - 0.9080442190170288;\t Train F1 Score - 0.7663551346405142;\t Train Recall - 0.6307692527770996;\t Train Precision - 0.976190447807312\n",
      "Train Loss - 0.25977933406829834;\t Train AUC - 0.9019522070884705;\t Train F1 Score - 0.7579908386919906;\t Train Recall - 0.6287878751754761;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.27182409167289734;\t Train AUC - 0.9177324175834656;\t Train F1 Score - 0.7785714541109194;\t Train Recall - 0.6687116622924805;\t Train Precision - 0.9316239356994629\n",
      "Train Loss - 0.32251226902008057;\t Train AUC - 0.8651554584503174;\t Train F1 Score - 0.6784140898120238;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.895348846912384\n",
      "Train Loss - 0.2198011726140976;\t Train AUC - 0.9194852113723755;\t Train F1 Score - 0.8260869472499582;\t Train Recall - 0.7364341020584106;\t Train Precision - 0.9405940771102905\n",
      "Train Loss - 0.22258971631526947;\t Train AUC - 0.9396229982376099;\t Train F1 Score - 0.789237660610432;\t Train Recall - 0.6717557311058044;\t Train Precision - 0.95652174949646\n",
      "Train Loss - 0.261078804731369;\t Train AUC - 0.9094762802124023;\t Train F1 Score - 0.7410714103823576;\t Train Recall - 0.6384615302085876;\t Train Precision - 0.8829787373542786\n",
      "Train Loss - 0.2532072067260742;\t Train AUC - 0.9077237248420715;\t Train F1 Score - 0.7966101744462227;\t Train Recall - 0.6911764740943909;\t Train Precision - 0.9399999976158142\n",
      "Train Loss - 0.2788082957267761;\t Train AUC - 0.8917008638381958;\t Train F1 Score - 0.7024390476884151;\t Train Recall - 0.5625;\t Train Precision - 0.9350649118423462\n",
      "Train Loss - 0.22674550116062164;\t Train AUC - 0.9176469445228577;\t Train F1 Score - 0.7826086443630093;\t Train Recall - 0.6639344096183777;\t Train Precision - 0.9529411792755127\n",
      "Train Loss - 0.25840818881988525;\t Train AUC - 0.907802939414978;\t Train F1 Score - 0.776371298510674;\t Train Recall - 0.6764705777168274;\t Train Precision - 0.9108911156654358\n",
      "Train Loss - 0.23563888669013977;\t Train AUC - 0.9111579060554504;\t Train F1 Score - 0.7751195892769989;\t Train Recall - 0.6480000019073486;\t Train Precision - 0.9642857313156128\n",
      "Train Loss - 0.2937255799770355;\t Train AUC - 0.8500510454177856;\t Train F1 Score - 0.6956521841963229;\t Train Recall - 0.5423728823661804;\t Train Precision - 0.9696969985961914\n",
      "Train Loss - 0.22142598032951355;\t Train AUC - 0.914354145526886;\t Train F1 Score - 0.7835051757562457;\t Train Recall - 0.6551724076271057;\t Train Precision - 0.9743589758872986\n",
      "Train Loss - 0.2243829369544983;\t Train AUC - 0.9315769672393799;\t Train F1 Score - 0.7830188658468393;\t Train Recall - 0.658730149269104;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.28826645016670227;\t Train AUC - 0.8931071162223816;\t Train F1 Score - 0.7606837600422255;\t Train Recall - 0.631205677986145;\t Train Precision - 0.9569892287254333\n",
      "Train Loss - 0.22969335317611694;\t Train AUC - 0.9174149632453918;\t Train F1 Score - 0.7657657643825403;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.8673469424247742\n",
      "Train Loss - 0.27032968401908875;\t Train AUC - 0.8997195959091187;\t Train F1 Score - 0.7685950333182696;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.2337156981229782;\t Train AUC - 0.9224433898925781;\t Train F1 Score - 0.7671232641345284;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.28292566537857056;\t Train AUC - 0.8902130126953125;\t Train F1 Score - 0.7435896935614884;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.8877550959587097\n",
      "Train Loss - 0.21407419443130493;\t Train AUC - 0.9290017485618591;\t Train F1 Score - 0.7942584199106303;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.932584285736084\n",
      "Train Loss - 0.2653377652168274;\t Train AUC - 0.9010988473892212;\t Train F1 Score - 0.7868852435063809;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9696969985961914\n",
      "Train Loss - 0.22862543165683746;\t Train AUC - 0.9178255796432495;\t Train F1 Score - 0.8085106030216247;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.24677391350269318;\t Train AUC - 0.9138904213905334;\t Train F1 Score - 0.7639485001182469;\t Train Recall - 0.6449275612831116;\t Train Precision - 0.9368420839309692\n",
      "Train Loss - 0.24045145511627197;\t Train AUC - 0.8946104049682617;\t Train F1 Score - 0.7553191513817092;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9102563858032227\n",
      "Train Loss - 0.2385331690311432;\t Train AUC - 0.9145412445068359;\t Train F1 Score - 0.8035714414357171;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.2624458372592926;\t Train AUC - 0.923353910446167;\t Train F1 Score - 0.786764699442033;\t Train Recall - 0.6604938507080078;\t Train Precision - 0.9727272987365723\n",
      "Train Loss - 0.2378537952899933;\t Train AUC - 0.9199608564376831;\t Train F1 Score - 0.7837837699114149;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.25640806555747986;\t Train AUC - 0.8859279155731201;\t Train F1 Score - 0.7373736450082113;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.948051929473877\n",
      "Train Loss - 0.26627400517463684;\t Train AUC - 0.8744888305664062;\t Train F1 Score - 0.7487179202624087;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.23765376210212708;\t Train AUC - 0.9221910834312439;\t Train F1 Score - 0.7813953552560722;\t Train Recall - 0.6412213444709778;\t Train Precision - 1.0\n",
      "Train Loss - 0.24017572402954102;\t Train AUC - 0.9027344584465027;\t Train F1 Score - 0.788461555261636;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.976190447807312\n",
      "Train Loss - 0.24688811600208282;\t Train AUC - 0.9120768308639526;\t Train F1 Score - 0.7802691061196775;\t Train Recall - 0.6541353464126587;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.28443223237991333;\t Train AUC - 0.8890690803527832;\t Train F1 Score - 0.7478261282135128;\t Train Recall - 0.6056337952613831;\t Train Precision - 0.9772727489471436\n",
      "Train Loss - 0.2560570240020752;\t Train AUC - 0.901459813117981;\t Train F1 Score - 0.7833333209060114;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9126213788986206\n",
      "Train Loss - 0.08433866500854492;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.24098332226276398;\t Test AUC - 0.8977160453796387;\t Test F1 Score - 0.7623762105461473;\t Test Recall - 0.6525423526763916;\t Test Precision - 0.9166666865348816\n",
      "Test Loss - 0.2845722436904907;\t Test AUC - 0.8641407489776611;\t Test F1 Score - 0.7373272186458979;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9195402264595032\n",
      "Test Loss - 0.23446543514728546;\t Test AUC - 0.9213181138038635;\t Test F1 Score - 0.7605634153571413;\t Test Recall - 0.6377952694892883;\t Test Precision - 0.9418604373931885\n",
      "Test Loss - 0.23859402537345886;\t Test AUC - 0.906009316444397;\t Test F1 Score - 0.7793427243928007;\t Test Recall - 0.658730149269104;\t Test Precision - 0.954023003578186\n",
      "Test Loss - 0.24545277655124664;\t Test AUC - 0.9111244678497314;\t Test F1 Score - 0.7536231807612871;\t Test Recall - 0.6190476417541504;\t Test Precision - 0.9629629850387573\n",
      "Test Loss - 0.22716306149959564;\t Test AUC - 0.9058281183242798;\t Test F1 Score - 0.7643979265844961;\t Test Recall - 0.640350878238678;\t Test Precision - 0.948051929473877\n",
      "Test Loss - 0.26581600308418274;\t Test AUC - 0.8773689270019531;\t Test F1 Score - 0.7032966464685974;\t Test Recall - 0.5517241358757019;\t Test Precision - 0.9696969985961914\n",
      "Test Loss - 0.265062540769577;\t Test AUC - 0.8836328387260437;\t Test F1 Score - 0.7165775405212216;\t Test Recall - 0.5677965879440308;\t Test Precision - 0.9710144996643066\n",
      "Test Loss - 0.2618533968925476;\t Test AUC - 0.9016016721725464;\t Test F1 Score - 0.7466666382777845;\t Test Recall - 0.6131386756896973;\t Test Precision - 0.9545454382896423\n",
      "Test Loss - 0.2645028829574585;\t Test AUC - 0.87879878282547;\t Test F1 Score - 0.7524752781542471;\t Test Recall - 0.6178861856460571;\t Test Precision - 0.9620253443717957\n",
      "Test Loss - 0.29147252440452576;\t Test AUC - 0.8881807327270508;\t Test F1 Score - 0.7336244268581791;\t Test Recall - 0.5874125957489014;\t Test Precision - 0.9767441749572754\n",
      "Test Loss - 0.26392510533332825;\t Test AUC - 0.9117105603218079;\t Test F1 Score - 0.7423580889740642;\t Test Recall - 0.6115108132362366;\t Test Precision - 0.9444444179534912\n",
      "Test Loss - 0.2797473073005676;\t Test AUC - 0.8940874934196472;\t Test F1 Score - 0.72146120923391;\t Test Recall - 0.5808823704719543;\t Test Precision - 0.9518072009086609\n",
      "Test Loss - 0.27000313997268677;\t Test AUC - 0.8805117011070251;\t Test F1 Score - 0.7254902099623051;\t Test Recall - 0.6016260385513306;\t Test Precision - 0.9135802388191223\n",
      "Test Loss - 0.2738560736179352;\t Test AUC - 0.899921178817749;\t Test F1 Score - 0.7336244776534405;\t Test Recall - 0.5957446694374084;\t Test Precision - 0.9545454382896423\n",
      "Test Loss - 0.2726846933364868;\t Test AUC - 0.8818848729133606;\t Test F1 Score - 0.7216494511488638;\t Test Recall - 0.5737704634666443;\t Test Precision - 0.9722222089767456\n",
      "Test Loss - 0.31400424242019653;\t Test AUC - 0.880050539970398;\t Test F1 Score - 0.6769230818786948;\t Test Recall - 0.523809552192688;\t Test Precision - 0.95652174949646\n",
      "Epoch - 6\n",
      "Train Loss - 0.23529604077339172;\t Train AUC - 0.9398270845413208;\t Train F1 Score - 0.7818930366181395;\t Train Recall - 0.6506849527359009;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.2829168140888214;\t Train AUC - 0.8882572650909424;\t Train F1 Score - 0.6701030289145293;\t Train Recall - 0.524193525314331;\t Train Precision - 0.9285714030265808\n",
      "Train Loss - 0.2790437340736389;\t Train AUC - 0.8943767547607422;\t Train F1 Score - 0.723004666808259;\t Train Recall - 0.5703703761100769;\t Train Precision - 0.9871794581413269\n",
      "Train Loss - 0.26607590913772583;\t Train AUC - 0.9066448211669922;\t Train F1 Score - 0.7219512168959809;\t Train Recall - 0.5692307949066162;\t Train Precision - 0.9866666793823242\n",
      "Train Loss - 0.2731074392795563;\t Train AUC - 0.8992246389389038;\t Train F1 Score - 0.7177033489124507;\t Train Recall - 0.5681818127632141;\t Train Precision - 0.9740259647369385\n",
      "Train Loss - 0.2731568217277527;\t Train AUC - 0.9187572598457336;\t Train F1 Score - 0.7797834581914311;\t Train Recall - 0.6625766754150391;\t Train Precision - 0.9473684430122375\n",
      "Train Loss - 0.32368558645248413;\t Train AUC - 0.8631545305252075;\t Train F1 Score - 0.6755555513354072;\t Train Recall - 0.5390070676803589;\t Train Precision - 0.9047619104385376\n",
      "Train Loss - 0.22516098618507385;\t Train AUC - 0.917576014995575;\t Train F1 Score - 0.8281938251319229;\t Train Recall - 0.7286821603775024;\t Train Precision - 0.9591836929321289\n",
      "Train Loss - 0.22509856522083282;\t Train AUC - 0.9356434345245361;\t Train F1 Score - 0.792951539264102;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.9375\n",
      "Train Loss - 0.2616891860961914;\t Train AUC - 0.9102782011032104;\t Train F1 Score - 0.7522123914366117;\t Train Recall - 0.6538461446762085;\t Train Precision - 0.8854166865348816\n",
      "Train Loss - 0.2599989175796509;\t Train AUC - 0.9008779525756836;\t Train F1 Score - 0.8033473220542917;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.9320388436317444\n",
      "Train Loss - 0.2936776876449585;\t Train AUC - 0.8909560441970825;\t Train F1 Score - 0.6854460146764447;\t Train Recall - 0.5703125;\t Train Precision - 0.8588235378265381\n",
      "Train Loss - 0.22529155015945435;\t Train AUC - 0.9148861169815063;\t Train F1 Score - 0.7924528468305705;\t Train Recall - 0.688524603843689;\t Train Precision - 0.9333333373069763\n",
      "Train Loss - 0.25903692841529846;\t Train AUC - 0.9128819108009338;\t Train F1 Score - 0.7563024405624088;\t Train Recall - 0.6617646813392639;\t Train Precision - 0.8823529481887817\n",
      "Train Loss - 0.24817103147506714;\t Train AUC - 0.901827335357666;\t Train F1 Score - 0.7641509049364853;\t Train Recall - 0.6480000019073486;\t Train Precision - 0.931034505367279\n",
      "Train Loss - 0.30575916171073914;\t Train AUC - 0.8378666043281555;\t Train F1 Score - 0.7027026942296469;\t Train Recall - 0.5508474707603455;\t Train Precision - 0.9701492786407471\n",
      "Train Loss - 0.22501924633979797;\t Train AUC - 0.9128669500350952;\t Train F1 Score - 0.7772020828296023;\t Train Recall - 0.6465517282485962;\t Train Precision - 0.9740259647369385\n",
      "Train Loss - 0.22118733823299408;\t Train AUC - 0.9312922954559326;\t Train F1 Score - 0.7830188658468393;\t Train Recall - 0.658730149269104;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.2894449234008789;\t Train AUC - 0.89431232213974;\t Train F1 Score - 0.7467811152250173;\t Train Recall - 0.6170212626457214;\t Train Precision - 0.945652186870575\n",
      "Train Loss - 0.2298261970281601;\t Train AUC - 0.9186093807220459;\t Train F1 Score - 0.7685185374824233;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9021739363670349\n",
      "Train Loss - 0.27054962515830994;\t Train AUC - 0.9019325375556946;\t Train F1 Score - 0.7717842286786512;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.96875\n",
      "Train Loss - 0.2346593290567398;\t Train AUC - 0.9235583543777466;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2818717956542969;\t Train AUC - 0.8886520862579346;\t Train F1 Score - 0.754385982261184;\t Train Recall - 0.6323529481887817;\t Train Precision - 0.9347826242446899\n",
      "Train Loss - 0.2189684808254242;\t Train AUC - 0.9251909255981445;\t Train F1 Score - 0.8019323514025234;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.2677292227745056;\t Train AUC - 0.904478907585144;\t Train F1 Score - 0.7818930101546853;\t Train Recall - 0.6551724076271057;\t Train Precision - 0.9693877696990967\n",
      "Train Loss - 0.2285238653421402;\t Train AUC - 0.921401858329773;\t Train F1 Score - 0.8050846892383805;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9405940771102905\n",
      "Train Loss - 0.2478175163269043;\t Train AUC - 0.9142982959747314;\t Train F1 Score - 0.7796610131735642;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9387755393981934\n",
      "Train Loss - 0.23979388177394867;\t Train AUC - 0.8907420635223389;\t Train F1 Score - 0.7526882280099267;\t Train Recall - 0.6363636255264282;\t Train Precision - 0.9210526347160339\n",
      "Train Loss - 0.2447872906923294;\t Train AUC - 0.9148668050765991;\t Train F1 Score - 0.784140983546463;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9270833134651184\n",
      "Train Loss - 0.2646324932575226;\t Train AUC - 0.9196050763130188;\t Train F1 Score - 0.7794117625388564;\t Train Recall - 0.654321014881134;\t Train Precision - 0.9636363387107849\n",
      "Train Loss - 0.2352706342935562;\t Train AUC - 0.9205031394958496;\t Train F1 Score - 0.7837837699114149;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.25759512186050415;\t Train AUC - 0.8863420486450195;\t Train F1 Score - 0.7227722623224992;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9012345671653748\n",
      "Train Loss - 0.26661673188209534;\t Train AUC - 0.8768698573112488;\t Train F1 Score - 0.7411166963222728;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9605262875556946\n",
      "Train Loss - 0.23692083358764648;\t Train AUC - 0.9206448197364807;\t Train F1 Score - 0.7699530891619717;\t Train Recall - 0.6259542107582092;\t Train Precision - 1.0\n",
      "Train Loss - 0.2399074286222458;\t Train AUC - 0.9048776626586914;\t Train F1 Score - 0.7846890488858195;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.9647058844566345\n",
      "Train Loss - 0.24879872798919678;\t Train AUC - 0.914475679397583;\t Train F1 Score - 0.765765813597401;\t Train Recall - 0.6390977501869202;\t Train Precision - 0.9550561904907227\n",
      "Train Loss - 0.2773781716823578;\t Train AUC - 0.8928055167198181;\t Train F1 Score - 0.7619047548463906;\t Train Recall - 0.6197183132171631;\t Train Precision - 0.9887640476226807\n",
      "Train Loss - 0.25315049290657043;\t Train AUC - 0.9022244215011597;\t Train F1 Score - 0.7881356032090371;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.06993243843317032;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2298683375120163;\t Test AUC - 0.9017335772514343;\t Test F1 Score - 0.7960198939953087;\t Test Recall - 0.6779661178588867;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.27756911516189575;\t Test AUC - 0.8701390624046326;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.23069672286510468;\t Test AUC - 0.9188210964202881;\t Test F1 Score - 0.7793427012218024;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9651162624359131\n",
      "Test Loss - 0.22807449102401733;\t Test AUC - 0.9084622859954834;\t Test F1 Score - 0.8093022886838513;\t Test Recall - 0.6904761791229248;\t Test Precision - 0.9775280952453613\n",
      "Test Loss - 0.23914505541324615;\t Test AUC - 0.9138955473899841;\t Test F1 Score - 0.772946818732236;\t Test Recall - 0.6349206566810608;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.22495654225349426;\t Test AUC - 0.9024077653884888;\t Test F1 Score - 0.7748691494849788;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9610389471054077\n",
      "Test Loss - 0.25990286469459534;\t Test AUC - 0.8728269934654236;\t Test F1 Score - 0.73224048629595;\t Test Recall - 0.5775862336158752;\t Test Precision - 1.0\n",
      "Test Loss - 0.25982925295829773;\t Test AUC - 0.8819537162780762;\t Test F1 Score - 0.740740749128541;\t Test Recall - 0.5932203531265259;\t Test Precision - 0.98591548204422\n",
      "Test Loss - 0.24918599426746368;\t Test AUC - 0.902957558631897;\t Test F1 Score - 0.7947598681473532;\t Test Recall - 0.6642335653305054;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.2610701024532318;\t Test AUC - 0.8748359680175781;\t Test F1 Score - 0.7647058516185528;\t Test Recall - 0.6341463327407837;\t Test Precision - 0.9629629850387573\n",
      "Test Loss - 0.2956092953681946;\t Test AUC - 0.8818228244781494;\t Test F1 Score - 0.7368421331369067;\t Test Recall - 0.5874125957489014;\t Test Precision - 0.9882352948188782\n",
      "Test Loss - 0.2521550953388214;\t Test AUC - 0.9112969636917114;\t Test F1 Score - 0.7931034657032413;\t Test Recall - 0.6618704795837402;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.278979629278183;\t Test AUC - 0.8875902891159058;\t Test F1 Score - 0.7454544960426418;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.976190447807312\n",
      "Test Loss - 0.2662351429462433;\t Test AUC - 0.8824376463890076;\t Test F1 Score - 0.7399999877942576;\t Test Recall - 0.6016260385513306;\t Test Precision - 0.9610389471054077\n",
      "Test Loss - 0.2687949240207672;\t Test AUC - 0.8989322781562805;\t Test F1 Score - 0.7598253560410868;\t Test Recall - 0.6170212626457214;\t Test Precision - 0.9886363744735718\n",
      "Test Loss - 0.2726386487483978;\t Test AUC - 0.879432737827301;\t Test F1 Score - 0.7253886049964559;\t Test Recall - 0.5737704634666443;\t Test Precision - 0.98591548204422\n",
      "Test Loss - 0.3089737594127655;\t Test AUC - 0.8827561140060425;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 7\n",
      "Train Loss - 0.22805732488632202;\t Train AUC - 0.9403777718544006;\t Train F1 Score - 0.7967479586755154;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9800000190734863\n",
      "Train Loss - 0.2758752405643463;\t Train AUC - 0.873593807220459;\t Train F1 Score - 0.7272726575180849;\t Train Recall - 0.5806451439857483;\t Train Precision - 0.9729729890823364\n",
      "Train Loss - 0.2649139165878296;\t Train AUC - 0.8965113759040833;\t Train F1 Score - 0.7545454341144099;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.23725228011608124;\t Train AUC - 0.9111783504486084;\t Train F1 Score - 0.7834101305013381;\t Train Recall - 0.6538461446762085;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.2386258989572525;\t Train AUC - 0.9104263782501221;\t Train F1 Score - 0.7782805599908217;\t Train Recall - 0.6515151262283325;\t Train Precision - 0.966292142868042\n",
      "Train Loss - 0.2600717544555664;\t Train AUC - 0.9193258285522461;\t Train F1 Score - 0.7985611599356318;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.9652174115180969\n",
      "Train Loss - 0.3224247097969055;\t Train AUC - 0.8606359958648682;\t Train F1 Score - 0.6877828105015125;\t Train Recall - 0.5390070676803589;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.21881169080734253;\t Train AUC - 0.9169670939445496;\t Train F1 Score - 0.8355555595884933;\t Train Recall - 0.7286821603775024;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.22202499210834503;\t Train AUC - 0.9367014169692993;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.250965416431427;\t Train AUC - 0.911268413066864;\t Train F1 Score - 0.7534883822955664;\t Train Recall - 0.6230769157409668;\t Train Precision - 0.9529411792755127\n",
      "Train Loss - 0.24552983045578003;\t Train AUC - 0.9046494364738464;\t Train F1 Score - 0.8068669346080595;\t Train Recall - 0.6911764740943909;\t Train Precision - 0.969072163105011\n",
      "Train Loss - 0.26873525977134705;\t Train AUC - 0.8973120450973511;\t Train F1 Score - 0.7156862622946071;\t Train Recall - 0.5703125;\t Train Precision - 0.9605262875556946\n",
      "Train Loss - 0.21944819390773773;\t Train AUC - 0.9194217920303345;\t Train F1 Score - 0.7826086443630093;\t Train Recall - 0.6639344096183777;\t Train Precision - 0.9529411792755127\n",
      "Train Loss - 0.24635444581508636;\t Train AUC - 0.9139357805252075;\t Train F1 Score - 0.7811158604106451;\t Train Recall - 0.6691176295280457;\t Train Precision - 0.938144326210022\n",
      "Train Loss - 0.23370696604251862;\t Train AUC - 0.9110063314437866;\t Train F1 Score - 0.7830188846058634;\t Train Recall - 0.6639999747276306;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.300324946641922;\t Train AUC - 0.8381215333938599;\t Train F1 Score - 0.7027026942296469;\t Train Recall - 0.5508474707603455;\t Train Precision - 0.9701492786407471\n",
      "Train Loss - 0.21676981449127197;\t Train AUC - 0.9130717515945435;\t Train F1 Score - 0.802030441873979;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.219675213098526;\t Train AUC - 0.935411274433136;\t Train F1 Score - 0.7830188658468393;\t Train Recall - 0.658730149269104;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.27791741490364075;\t Train AUC - 0.895393967628479;\t Train F1 Score - 0.7606837600422255;\t Train Recall - 0.631205677986145;\t Train Precision - 0.9569892287254333\n",
      "Train Loss - 0.2285240739583969;\t Train AUC - 0.9223028421401978;\t Train F1 Score - 0.7671232782598891;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.8842105269432068\n",
      "Train Loss - 0.26370424032211304;\t Train AUC - 0.9018491506576538;\t Train F1 Score - 0.7800829301072709;\t Train Recall - 0.6482758522033691;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.23073793947696686;\t Train AUC - 0.9256010055541992;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.27486154437065125;\t Train AUC - 0.8939924240112305;\t Train F1 Score - 0.7456140985485973;\t Train Recall - 0.625;\t Train Precision - 0.9239130616188049\n",
      "Train Loss - 0.2075434923171997;\t Train AUC - 0.930980920791626;\t Train F1 Score - 0.8097560627012117;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.26880601048469543;\t Train AUC - 0.9035013318061829;\t Train F1 Score - 0.7851239006414408;\t Train Recall - 0.6551724076271057;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.22119349241256714;\t Train AUC - 0.9232735633850098;\t Train F1 Score - 0.8240343619990743;\t Train Recall - 0.7111111283302307;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.24486224353313446;\t Train AUC - 0.9161412119865417;\t Train F1 Score - 0.7705628101872234;\t Train Recall - 0.6449275612831116;\t Train Precision - 0.9569892287254333\n",
      "Train Loss - 0.23584552109241486;\t Train AUC - 0.8968923687934875;\t Train F1 Score - 0.7499999808923355;\t Train Recall - 0.6272727251052856;\t Train Precision - 0.9324324131011963\n",
      "Train Loss - 0.23273341357707977;\t Train AUC - 0.9201158881187439;\t Train F1 Score - 0.8035714414357171;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.2578779458999634;\t Train AUC - 0.9260033965110779;\t Train F1 Score - 0.7822878155774212;\t Train Recall - 0.654321014881134;\t Train Precision - 0.9724770784378052\n",
      "Train Loss - 0.23391078412532806;\t Train AUC - 0.9214096069335938;\t Train F1 Score - 0.7853881361515602;\t Train Recall - 0.6515151262283325;\t Train Precision - 0.9885057210922241\n",
      "Train Loss - 0.25362521409988403;\t Train AUC - 0.8884642720222473;\t Train F1 Score - 0.7336683144652802;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9358974099159241\n",
      "Train Loss - 0.26258134841918945;\t Train AUC - 0.8754550814628601;\t Train F1 Score - 0.7487179202624087;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.23422150313854218;\t Train AUC - 0.9254463911056519;\t Train F1 Score - 0.7699530891619717;\t Train Recall - 0.6259542107582092;\t Train Precision - 1.0\n",
      "Train Loss - 0.23822139203548431;\t Train AUC - 0.9068006277084351;\t Train F1 Score - 0.7826086511117121;\t Train Recall - 0.6532257795333862;\t Train Precision - 0.9759036302566528\n",
      "Train Loss - 0.24141621589660645;\t Train AUC - 0.9176474213600159;\t Train F1 Score - 0.7802691061196775;\t Train Recall - 0.6541353464126587;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.27619072794914246;\t Train AUC - 0.8940279483795166;\t Train F1 Score - 0.7598253207322118;\t Train Recall - 0.6126760840415955;\t Train Precision - 1.0\n",
      "Train Loss - 0.25265419483184814;\t Train AUC - 0.9069067239761353;\t Train F1 Score - 0.7848101143891365;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.9300000071525574\n",
      "Train Loss - 0.0713760033249855;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2289312183856964;\t Test AUC - 0.9019445776939392;\t Test F1 Score - 0.7960198939953087;\t Test Recall - 0.6779661178588867;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.27534452080726624;\t Test AUC - 0.8724386692047119;\t Test F1 Score - 0.7582938420345072;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.22936703264713287;\t Test AUC - 0.9211100339889526;\t Test F1 Score - 0.7793427012218024;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9651162624359131\n",
      "Test Loss - 0.22877556085586548;\t Test AUC - 0.9046279191970825;\t Test F1 Score - 0.7981220589504767;\t Test Recall - 0.6746031641960144;\t Test Precision - 0.977011501789093\n",
      "Test Loss - 0.23450782895088196;\t Test AUC - 0.9164071083068848;\t Test F1 Score - 0.772946818732236;\t Test Recall - 0.6349206566810608;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.22097566723823547;\t Test AUC - 0.9039870500564575;\t Test F1 Score - 0.7789473545025627;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.253376841545105;\t Test AUC - 0.8839857578277588;\t Test F1 Score - 0.7351351519443977;\t Test Recall - 0.5862069129943848;\t Test Precision - 0.9855072498321533\n",
      "Test Loss - 0.2544938027858734;\t Test AUC - 0.8862525224685669;\t Test F1 Score - 0.7446808622076587;\t Test Recall - 0.5932203531265259;\t Test Precision - 1.0\n",
      "Test Loss - 0.24434033036231995;\t Test AUC - 0.9057401418685913;\t Test F1 Score - 0.7929515808340117;\t Test Recall - 0.6569343209266663;\t Test Precision - 1.0\n",
      "Test Loss - 0.25447478890419006;\t Test AUC - 0.8790543675422668;\t Test F1 Score - 0.774509817649225;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.2919084429740906;\t Test AUC - 0.8847072124481201;\t Test F1 Score - 0.7336244268581791;\t Test Recall - 0.5874125957489014;\t Test Precision - 0.9767441749572754\n",
      "Test Loss - 0.24996846914291382;\t Test AUC - 0.9099938869476318;\t Test F1 Score - 0.7878788186449589;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.2761024534702301;\t Test AUC - 0.8899753093719482;\t Test F1 Score - 0.7431192736528404;\t Test Recall - 0.595588207244873;\t Test Precision - 0.9878048896789551\n",
      "Test Loss - 0.2623337209224701;\t Test AUC - 0.8861958980560303;\t Test F1 Score - 0.7399999877942576;\t Test Recall - 0.6016260385513306;\t Test Precision - 0.9610389471054077\n",
      "Test Loss - 0.26760777831077576;\t Test AUC - 0.9008946418762207;\t Test F1 Score - 0.754385958370284;\t Test Recall - 0.609929084777832;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.26497775316238403;\t Test AUC - 0.8841912746429443;\t Test F1 Score - 0.7357513125161872;\t Test Recall - 0.5819672346115112;\t Test Precision - 1.0\n",
      "Test Loss - 0.31186649203300476;\t Test AUC - 0.8797799348831177;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 8\n",
      "Train Loss - 0.22714553773403168;\t Train AUC - 0.9373906254768372;\t Train F1 Score - 0.7999999856472213;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9898989796638489\n",
      "Train Loss - 0.2669309377670288;\t Train AUC - 0.8818615674972534;\t Train F1 Score - 0.7336683566649974;\t Train Recall - 0.5887096524238586;\t Train Precision - 0.9733333587646484\n",
      "Train Loss - 0.2601369023323059;\t Train AUC - 0.9012425541877747;\t Train F1 Score - 0.7545454341144099;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.22987808287143707;\t Train AUC - 0.9186006784439087;\t Train F1 Score - 0.7813953793694499;\t Train Recall - 0.6461538672447205;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.24139656126499176;\t Train AUC - 0.910895824432373;\t Train F1 Score - 0.7837837699114149;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.25824782252311707;\t Train AUC - 0.923291802406311;\t Train F1 Score - 0.7971014670939874;\t Train Recall - 0.6748466491699219;\t Train Precision - 0.9734513163566589\n",
      "Train Loss - 0.31506845355033875;\t Train AUC - 0.8664920330047607;\t Train F1 Score - 0.6936937496619971;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9506173133850098\n",
      "Train Loss - 0.2169845551252365;\t Train AUC - 0.9170328378677368;\t Train F1 Score - 0.83035716414605;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.21793434023857117;\t Train AUC - 0.9375640153884888;\t Train F1 Score - 0.8;\t Train Recall - 0.6717557311058044;\t Train Precision - 0.9887640476226807\n",
      "Train Loss - 0.24652232229709625;\t Train AUC - 0.9140916466712952;\t Train F1 Score - 0.7465437155284351;\t Train Recall - 0.6230769157409668;\t Train Precision - 0.931034505367279\n",
      "Train Loss - 0.24422353506088257;\t Train AUC - 0.9050694704055786;\t Train F1 Score - 0.7914893913906879;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.25881150364875793;\t Train AUC - 0.9055382609367371;\t Train F1 Score - 0.7211538461538461;\t Train Recall - 0.5859375;\t Train Precision - 0.9375\n",
      "Train Loss - 0.21796931326389313;\t Train AUC - 0.9219768047332764;\t Train F1 Score - 0.8;\t Train Recall - 0.688524603843689;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.23946507275104523;\t Train AUC - 0.9161701202392578;\t Train F1 Score - 0.7914893913906879;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.23578622937202454;\t Train AUC - 0.9063831567764282;\t Train F1 Score - 0.7830188846058634;\t Train Recall - 0.6639999747276306;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.2997969090938568;\t Train AUC - 0.8398797512054443;\t Train F1 Score - 0.6956521841963229;\t Train Recall - 0.5423728823661804;\t Train Precision - 0.9696969985961914\n",
      "Train Loss - 0.21448621153831482;\t Train AUC - 0.9136862754821777;\t Train F1 Score - 0.7897436057872589;\t Train Recall - 0.6637930870056152;\t Train Precision - 0.9746835231781006\n",
      "Train Loss - 0.2181568592786789;\t Train AUC - 0.9349340200424194;\t Train F1 Score - 0.775119576703991;\t Train Recall - 0.6428571343421936;\t Train Precision - 0.9759036302566528\n",
      "Train Loss - 0.2739846706390381;\t Train AUC - 0.9035136699676514;\t Train F1 Score - 0.7606837600422255;\t Train Recall - 0.631205677986145;\t Train Precision - 0.9569892287254333\n",
      "Train Loss - 0.2277841418981552;\t Train AUC - 0.9257166385650635;\t Train F1 Score - 0.7706422310727951;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.8936170339584351\n",
      "Train Loss - 0.2630472183227539;\t Train AUC - 0.9023569226264954;\t Train F1 Score - 0.7800829301072709;\t Train Recall - 0.6482758522033691;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.23260124027729034;\t Train AUC - 0.9223131537437439;\t Train F1 Score - 0.7720930017157879;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.27324771881103516;\t Train AUC - 0.8928356170654297;\t Train F1 Score - 0.7454544960426418;\t Train Recall - 0.6029411554336548;\t Train Precision - 0.976190447807312\n",
      "Train Loss - 0.20651701092720032;\t Train AUC - 0.9312412738800049;\t Train F1 Score - 0.8078817491545502;\t Train Recall - 0.6833333373069763;\t Train Precision - 0.9879518151283264\n",
      "Train Loss - 0.2618386447429657;\t Train AUC - 0.907313346862793;\t Train F1 Score - 0.7866108713984641;\t Train Recall - 0.6482758522033691;\t Train Precision - 1.0\n",
      "Train Loss - 0.22029465436935425;\t Train AUC - 0.9215532541275024;\t Train F1 Score - 0.8189654574040661;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.2424761950969696;\t Train AUC - 0.9175920486450195;\t Train F1 Score - 0.7796610131735642;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9387755393981934\n",
      "Train Loss - 0.235728919506073;\t Train AUC - 0.8964563608169556;\t Train F1 Score - 0.7526882280099267;\t Train Recall - 0.6363636255264282;\t Train Precision - 0.9210526347160339\n",
      "Train Loss - 0.23018330335617065;\t Train AUC - 0.9254789352416992;\t Train F1 Score - 0.8088888598924813;\t Train Recall - 0.694656491279602;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.25133517384529114;\t Train AUC - 0.930668294429779;\t Train F1 Score - 0.7956204691449222;\t Train Recall - 0.6728395223617554;\t Train Precision - 0.9732142686843872\n",
      "Train Loss - 0.23107615113258362;\t Train AUC - 0.9234087467193604;\t Train F1 Score - 0.790909119848174;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.25488463044166565;\t Train AUC - 0.8893441557884216;\t Train F1 Score - 0.7373736450082113;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.948051929473877\n",
      "Train Loss - 0.26217228174209595;\t Train AUC - 0.8769733905792236;\t Train F1 Score - 0.7487179202624087;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.23122888803482056;\t Train AUC - 0.9224840998649597;\t Train F1 Score - 0.7720930017157879;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.232506662607193;\t Train AUC - 0.9103838801383972;\t Train F1 Score - 0.788461555261636;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.976190447807312\n",
      "Train Loss - 0.2412043958902359;\t Train AUC - 0.9132360219955444;\t Train F1 Score - 0.7685589951717209;\t Train Recall - 0.6616541147232056;\t Train Precision - 0.9166666865348816\n",
      "Train Loss - 0.27768373489379883;\t Train AUC - 0.8921597003936768;\t Train F1 Score - 0.754385987055343;\t Train Recall - 0.6056337952613831;\t Train Precision - 1.0\n",
      "Train Loss - 0.24885477125644684;\t Train AUC - 0.907324492931366;\t Train F1 Score - 0.7914893760370687;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.9489796161651611\n",
      "Train Loss - 0.06139727309346199;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22977767884731293;\t Test AUC - 0.9049511551856995;\t Test F1 Score - 0.7899999342960663;\t Test Recall - 0.6694915294647217;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.2731631100177765;\t Test AUC - 0.8739771246910095;\t Test F1 Score - 0.7582938420345072;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.23126770555973053;\t Test AUC - 0.918979287147522;\t Test F1 Score - 0.7830188624049881;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9764705896377563\n",
      "Test Loss - 0.22777682542800903;\t Test AUC - 0.903489351272583;\t Test F1 Score - 0.8075117645527151;\t Test Recall - 0.682539701461792;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.23456965386867523;\t Test AUC - 0.9179559946060181;\t Test F1 Score - 0.772946818732236;\t Test Recall - 0.6349206566810608;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.2197841852903366;\t Test AUC - 0.9026243686676025;\t Test F1 Score - 0.7872340625473251;\t Test Recall - 0.6491228342056274;\t Test Precision - 1.0\n",
      "Test Loss - 0.250821590423584;\t Test AUC - 0.8860430717468262;\t Test F1 Score - 0.7391304478528142;\t Test Recall - 0.5862069129943848;\t Test Precision - 1.0\n",
      "Test Loss - 0.2569326162338257;\t Test AUC - 0.8866218328475952;\t Test F1 Score - 0.7379679160475503;\t Test Recall - 0.5847457647323608;\t Test Precision - 1.0\n",
      "Test Loss - 0.23972971737384796;\t Test AUC - 0.9092320203781128;\t Test F1 Score - 0.798245605866738;\t Test Recall - 0.6642335653305054;\t Test Precision - 1.0\n",
      "Test Loss - 0.2550041079521179;\t Test AUC - 0.8825483918190002;\t Test F1 Score - 0.7684729071338159;\t Test Recall - 0.6341463327407837;\t Test Precision - 0.9750000238418579\n",
      "Test Loss - 0.2949359118938446;\t Test AUC - 0.8831692934036255;\t Test F1 Score - 0.7359307160863721;\t Test Recall - 0.5944055914878845;\t Test Precision - 0.9659090638160706\n",
      "Test Loss - 0.24461232125759125;\t Test AUC - 0.9184210300445557;\t Test F1 Score - 0.7878788186449589;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.2786991000175476;\t Test AUC - 0.8890244364738464;\t Test F1 Score - 0.7373272251942582;\t Test Recall - 0.5882353186607361;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.25919732451438904;\t Test AUC - 0.8894428610801697;\t Test F1 Score - 0.7474747937207497;\t Test Recall - 0.6016260385513306;\t Test Precision - 0.9866666793823242\n",
      "Test Loss - 0.26925796270370483;\t Test AUC - 0.8989323377609253;\t Test F1 Score - 0.754385958370284;\t Test Recall - 0.609929084777832;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.2663433253765106;\t Test AUC - 0.8823565244674683;\t Test F1 Score - 0.729166616168288;\t Test Recall - 0.5737704634666443;\t Test Precision - 1.0\n",
      "Test Loss - 0.307687908411026;\t Test AUC - 0.8875360488891602;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 9\n",
      "Train Loss - 0.22732655704021454;\t Train AUC - 0.9398345947265625;\t Train F1 Score - 0.7950819471292849;\t Train Recall - 0.664383590221405;\t Train Precision - 0.9897959232330322\n",
      "Train Loss - 0.26146769523620605;\t Train AUC - 0.8880709409713745;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.25485217571258545;\t Train AUC - 0.9078454971313477;\t Train F1 Score - 0.7579908916909065;\t Train Recall - 0.614814817905426;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.22554749250411987;\t Train AUC - 0.9195499420166016;\t Train F1 Score - 0.7981650940757441;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.23330235481262207;\t Train AUC - 0.9125792980194092;\t Train F1 Score - 0.7982456478844147;\t Train Recall - 0.689393937587738;\t Train Precision - 0.9479166865348816\n",
      "Train Loss - 0.2550167739391327;\t Train AUC - 0.9241552352905273;\t Train F1 Score - 0.7985611599356318;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.9652174115180969\n",
      "Train Loss - 0.3139741122722626;\t Train AUC - 0.8665770292282104;\t Train F1 Score - 0.6968325999237617;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.21537388861179352;\t Train AUC - 0.9200941324234009;\t Train F1 Score - 0.8325791735557433;\t Train Recall - 0.713178277015686;\t Train Precision - 1.0\n",
      "Train Loss - 0.21984374523162842;\t Train AUC - 0.9377105236053467;\t Train F1 Score - 0.7777777290051637;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.24639540910720825;\t Train AUC - 0.9154828190803528;\t Train F1 Score - 0.7441860661031489;\t Train Recall - 0.6153846383094788;\t Train Precision - 0.9411764740943909\n",
      "Train Loss - 0.24433405697345734;\t Train AUC - 0.9047603607177734;\t Train F1 Score - 0.798283244359865;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.2572427988052368;\t Train AUC - 0.9059438109397888;\t Train F1 Score - 0.7219512180009624;\t Train Recall - 0.578125;\t Train Precision - 0.9610389471054077\n",
      "Train Loss - 0.21514193713665009;\t Train AUC - 0.9239916801452637;\t Train F1 Score - 0.7942583801856304;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.24243387579917908;\t Train AUC - 0.9139119386672974;\t Train F1 Score - 0.7796610346675811;\t Train Recall - 0.6764705777168274;\t Train Precision - 0.9200000166893005\n",
      "Train Loss - 0.23175646364688873;\t Train AUC - 0.9084210991859436;\t Train F1 Score - 0.7830188846058634;\t Train Recall - 0.6639999747276306;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.2914598882198334;\t Train AUC - 0.8493213653564453;\t Train F1 Score - 0.7027026942296469;\t Train Recall - 0.5508474707603455;\t Train Precision - 0.9701492786407471\n",
      "Train Loss - 0.21226857602596283;\t Train AUC - 0.9156187772750854;\t Train F1 Score - 0.802030441873979;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.21576787531375885;\t Train AUC - 0.9360642433166504;\t Train F1 Score - 0.7809523676939819;\t Train Recall - 0.6507936716079712;\t Train Precision - 0.976190447807312\n",
      "Train Loss - 0.26933640241622925;\t Train AUC - 0.9031505584716797;\t Train F1 Score - 0.7586207129063232;\t Train Recall - 0.6241135001182556;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.21945525705814362;\t Train AUC - 0.9277073740959167;\t Train F1 Score - 0.7706422310727951;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.8936170339584351\n",
      "Train Loss - 0.26001787185668945;\t Train AUC - 0.9033042788505554;\t Train F1 Score - 0.7800829301072709;\t Train Recall - 0.6482758522033691;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.2274325042963028;\t Train AUC - 0.9229235649108887;\t Train F1 Score - 0.7720930017157879;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.2639029026031494;\t Train AUC - 0.898770272731781;\t Train F1 Score - 0.764444434833335;\t Train Recall - 0.6323529481887817;\t Train Precision - 0.966292142868042\n",
      "Train Loss - 0.20625737309455872;\t Train AUC - 0.9306163191795349;\t Train F1 Score - 0.8137254748892616;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.26144716143608093;\t Train AUC - 0.9046305418014526;\t Train F1 Score - 0.7901234666514272;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.21745645999908447;\t Train AUC - 0.9221187233924866;\t Train F1 Score - 0.8260869839015675;\t Train Recall - 0.7037037014961243;\t Train Precision - 1.0\n",
      "Train Loss - 0.2395227551460266;\t Train AUC - 0.916164755821228;\t Train F1 Score - 0.7826087560515484;\t Train Recall - 0.6521739363670349;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.2307731658220291;\t Train AUC - 0.898302435874939;\t Train F1 Score - 0.7700534803471686;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9350649118423462\n",
      "Train Loss - 0.22863298654556274;\t Train AUC - 0.9263415932655334;\t Train F1 Score - 0.8035714414357171;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.24620936810970306;\t Train AUC - 0.93145751953125;\t Train F1 Score - 0.7912088399448202;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9729729890823364\n",
      "Train Loss - 0.2280757874250412;\t Train AUC - 0.9253674745559692;\t Train F1 Score - 0.7853881361515602;\t Train Recall - 0.6515151262283325;\t Train Precision - 0.9885057210922241\n",
      "Train Loss - 0.25431662797927856;\t Train AUC - 0.8895857334136963;\t Train F1 Score - 0.7512690179738756;\t Train Recall - 0.6115702390670776;\t Train Precision - 0.9736841917037964\n",
      "Train Loss - 0.2595219016075134;\t Train AUC - 0.8756189346313477;\t Train F1 Score - 0.7487179202624087;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.2291310578584671;\t Train AUC - 0.9257882237434387;\t Train F1 Score - 0.7813953552560722;\t Train Recall - 0.6412213444709778;\t Train Precision - 1.0\n",
      "Train Loss - 0.23050262033939362;\t Train AUC - 0.9124931693077087;\t Train F1 Score - 0.7846890488858195;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.9647058844566345\n",
      "Train Loss - 0.23549820482730865;\t Train AUC - 0.916802167892456;\t Train F1 Score - 0.789237590230526;\t Train Recall - 0.6616541147232056;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.27205565571784973;\t Train AUC - 0.902077317237854;\t Train F1 Score - 0.7598253207322118;\t Train Recall - 0.6126760840415955;\t Train Precision - 1.0\n",
      "Train Loss - 0.24685333669185638;\t Train AUC - 0.9085068702697754;\t Train F1 Score - 0.7881356032090371;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.060330383479595184;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22639940679073334;\t Test AUC - 0.9040456414222717;\t Test F1 Score - 0.7899999342960663;\t Test Recall - 0.6694915294647217;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.2703307569026947;\t Test AUC - 0.8748936057090759;\t Test F1 Score - 0.7582938420345072;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.22770237922668457;\t Test AUC - 0.9221422076225281;\t Test F1 Score - 0.7830188624049881;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9764705896377563\n",
      "Test Loss - 0.22501973807811737;\t Test AUC - 0.9044772386550903;\t Test F1 Score - 0.8075117645527151;\t Test Recall - 0.682539701461792;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.23362691700458527;\t Test AUC - 0.920375406742096;\t Test F1 Score - 0.772946818732236;\t Test Recall - 0.6349206566810608;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.21922403573989868;\t Test AUC - 0.9035539031028748;\t Test F1 Score - 0.7872340625473251;\t Test Recall - 0.6491228342056274;\t Test Precision - 1.0\n",
      "Test Loss - 0.24938130378723145;\t Test AUC - 0.8875570297241211;\t Test F1 Score - 0.7391304478528142;\t Test Recall - 0.5862069129943848;\t Test Precision - 1.0\n",
      "Test Loss - 0.25252196192741394;\t Test AUC - 0.8893997669219971;\t Test F1 Score - 0.7379679160475503;\t Test Recall - 0.5847457647323608;\t Test Precision - 1.0\n",
      "Test Loss - 0.2376563549041748;\t Test AUC - 0.9112342596054077;\t Test F1 Score - 0.798245605866738;\t Test Recall - 0.6642335653305054;\t Test Precision - 1.0\n",
      "Test Loss - 0.25228413939476013;\t Test AUC - 0.8828808069229126;\t Test F1 Score - 0.7783250860399504;\t Test Recall - 0.642276406288147;\t Test Precision - 0.987500011920929\n",
      "Test Loss - 0.2951758801937103;\t Test AUC - 0.8802466988563538;\t Test F1 Score - 0.7359307160863721;\t Test Recall - 0.5944055914878845;\t Test Precision - 0.9659090638160706\n",
      "Test Loss - 0.24238158762454987;\t Test AUC - 0.9192559123039246;\t Test F1 Score - 0.7878788186449589;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.27679353952407837;\t Test AUC - 0.8887709379196167;\t Test F1 Score - 0.7373272251942582;\t Test Recall - 0.5882353186607361;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.25570619106292725;\t Test AUC - 0.8943771719932556;\t Test F1 Score - 0.7437185671065317;\t Test Recall - 0.6016260385513306;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.2648487985134125;\t Test AUC - 0.9008173942565918;\t Test F1 Score - 0.754385958370284;\t Test Recall - 0.609929084777832;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.2614481747150421;\t Test AUC - 0.8870378732681274;\t Test F1 Score - 0.7357513125161872;\t Test Recall - 0.5819672346115112;\t Test Precision - 1.0\n",
      "Test Loss - 0.3070513904094696;\t Test AUC - 0.8911435604095459;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 10\n",
      "Train Loss - 0.22427277266979218;\t Train AUC - 0.9407700300216675;\t Train F1 Score - 0.7999999856472213;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9898989796638489\n",
      "Train Loss - 0.2616147994995117;\t Train AUC - 0.8848773241043091;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.25258535146713257;\t Train AUC - 0.9095738530158997;\t Train F1 Score - 0.7579908916909065;\t Train Recall - 0.614814817905426;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.22236187756061554;\t Train AUC - 0.9218985438346863;\t Train F1 Score - 0.7981650940757441;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.2291307896375656;\t Train AUC - 0.9171603918075562;\t Train F1 Score - 0.7964601802089017;\t Train Recall - 0.6818181872367859;\t Train Precision - 0.957446813583374\n",
      "Train Loss - 0.2552136778831482;\t Train AUC - 0.9220494031906128;\t Train F1 Score - 0.8028673842881675;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.3078745901584625;\t Train AUC - 0.8715678453445435;\t Train F1 Score - 0.7031963896335848;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9871794581413269\n",
      "Train Loss - 0.21353678405284882;\t Train AUC - 0.9230484366416931;\t Train F1 Score - 0.8378378284769914;\t Train Recall - 0.7209302186965942;\t Train Precision - 1.0\n",
      "Train Loss - 0.21705055236816406;\t Train AUC - 0.940339207649231;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.242015540599823;\t Train AUC - 0.91765958070755;\t Train F1 Score - 0.7441860661031489;\t Train Recall - 0.6153846383094788;\t Train Precision - 0.9411764740943909\n",
      "Train Loss - 0.24243919551372528;\t Train AUC - 0.9064480066299438;\t Train F1 Score - 0.801724140418467;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.96875\n",
      "Train Loss - 0.2530585825443268;\t Train AUC - 0.9097424149513245;\t Train F1 Score - 0.7281552994187195;\t Train Recall - 0.5859375;\t Train Precision - 0.9615384340286255\n",
      "Train Loss - 0.21374760568141937;\t Train AUC - 0.9240002632141113;\t Train F1 Score - 0.7980769523348064;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.23929275572299957;\t Train AUC - 0.9142526984214783;\t Train F1 Score - 0.7881355763184279;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.9300000071525574\n",
      "Train Loss - 0.22974634170532227;\t Train AUC - 0.9118316173553467;\t Train F1 Score - 0.7887323726889142;\t Train Recall - 0.671999990940094;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.29439157247543335;\t Train AUC - 0.8466752171516418;\t Train F1 Score - 0.6956521841963229;\t Train Recall - 0.5423728823661804;\t Train Precision - 0.9696969985961914\n",
      "Train Loss - 0.2107107788324356;\t Train AUC - 0.9172128438949585;\t Train F1 Score - 0.802030441873979;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.21408285200595856;\t Train AUC - 0.937721848487854;\t Train F1 Score - 0.7788461482227043;\t Train Recall - 0.6428571343421936;\t Train Precision - 0.9878048896789551\n",
      "Train Loss - 0.2639932334423065;\t Train AUC - 0.904904305934906;\t Train F1 Score - 0.7672414176268485;\t Train Recall - 0.631205677986145;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.22087474167346954;\t Train AUC - 0.9291051030158997;\t Train F1 Score - 0.7706422310727951;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.8936170339584351\n",
      "Train Loss - 0.26018351316452026;\t Train AUC - 0.9049715995788574;\t Train F1 Score - 0.7750000091963934;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.22834929823875427;\t Train AUC - 0.9226875305175781;\t Train F1 Score - 0.7720930017157879;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.26250967383384705;\t Train AUC - 0.9000777006149292;\t Train F1 Score - 0.7567567567567568;\t Train Recall - 0.6176470518112183;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.20615153014659882;\t Train AUC - 0.9305728673934937;\t Train F1 Score - 0.8155339108673318;\t Train Recall - 0.699999988079071;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2587966322898865;\t Train AUC - 0.9069192409515381;\t Train F1 Score - 0.7901234666514272;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.2162061631679535;\t Train AUC - 0.9235364198684692;\t Train F1 Score - 0.8260869839015675;\t Train Recall - 0.7037037014961243;\t Train Precision - 1.0\n",
      "Train Loss - 0.2395237237215042;\t Train AUC - 0.9173097610473633;\t Train F1 Score - 0.7758620306583724;\t Train Recall - 0.6521739363670349;\t Train Precision - 0.957446813583374\n",
      "Train Loss - 0.2294560819864273;\t Train AUC - 0.9001484513282776;\t Train F1 Score - 0.7659573905384713;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9230769276618958\n",
      "Train Loss - 0.22796346247196198;\t Train AUC - 0.9264636635780334;\t Train F1 Score - 0.8035714414357171;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.2439139485359192;\t Train AUC - 0.9333460330963135;\t Train F1 Score - 0.7927272518131928;\t Train Recall - 0.6728395223617554;\t Train Precision - 0.9646017551422119\n",
      "Train Loss - 0.22626221179962158;\t Train AUC - 0.9269457459449768;\t Train F1 Score - 0.790909119848174;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.2551487684249878;\t Train AUC - 0.8906641006469727;\t Train F1 Score - 0.7499999810079737;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.949367105960846\n",
      "Train Loss - 0.2591775953769684;\t Train AUC - 0.8767231702804565;\t Train F1 Score - 0.7487179202624087;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.22587279975414276;\t Train AUC - 0.9248278737068176;\t Train F1 Score - 0.7870370437313172;\t Train Recall - 0.6488549709320068;\t Train Precision - 1.0\n",
      "Train Loss - 0.2282877117395401;\t Train AUC - 0.9155258536338806;\t Train F1 Score - 0.7846890488858195;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.9647058844566345\n",
      "Train Loss - 0.2345496118068695;\t Train AUC - 0.91766357421875;\t Train F1 Score - 0.789237590230526;\t Train Recall - 0.6616541147232056;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.2723194360733032;\t Train AUC - 0.9008010625839233;\t Train F1 Score - 0.7598253207322118;\t Train Recall - 0.6126760840415955;\t Train Precision - 1.0\n",
      "Train Loss - 0.2458575963973999;\t Train AUC - 0.9102883338928223;\t Train F1 Score - 0.7881356032090371;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.05894742161035538;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2262277454137802;\t Test AUC - 0.9024456739425659;\t Test F1 Score - 0.7920792709044567;\t Test Recall - 0.6779661178588867;\t Test Precision - 0.9523809552192688\n",
      "Test Loss - 0.2692825198173523;\t Test AUC - 0.877364993095398;\t Test F1 Score - 0.7582938420345072;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.22906750440597534;\t Test AUC - 0.9230160713195801;\t Test F1 Score - 0.7793427012218024;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9651162624359131\n",
      "Test Loss - 0.22390250861644745;\t Test AUC - 0.9048539996147156;\t Test F1 Score - 0.8075117645527151;\t Test Recall - 0.682539701461792;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.23341765999794006;\t Test AUC - 0.920727014541626;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.21728190779685974;\t Test AUC - 0.9052956700325012;\t Test F1 Score - 0.7830688200850066;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9866666793823242\n",
      "Test Loss - 0.248504638671875;\t Test AUC - 0.8886969089508057;\t Test F1 Score - 0.7391304478528142;\t Test Recall - 0.5862069129943848;\t Test Precision - 1.0\n",
      "Test Loss - 0.25345802307128906;\t Test AUC - 0.8897953629493713;\t Test F1 Score - 0.7379679160475503;\t Test Recall - 0.5847457647323608;\t Test Precision - 1.0\n",
      "Test Loss - 0.23709940910339355;\t Test AUC - 0.91182541847229;\t Test F1 Score - 0.798245605866738;\t Test Recall - 0.6642335653305054;\t Test Precision - 1.0\n",
      "Test Loss - 0.2547805905342102;\t Test AUC - 0.8793015480041504;\t Test F1 Score - 0.7783250860399504;\t Test Recall - 0.642276406288147;\t Test Precision - 0.987500011920929\n",
      "Test Loss - 0.2985687553882599;\t Test AUC - 0.8770256042480469;\t Test F1 Score - 0.7327585808952081;\t Test Recall - 0.5944055914878845;\t Test Precision - 0.9550561904907227\n",
      "Test Loss - 0.2414606213569641;\t Test AUC - 0.920730710029602;\t Test F1 Score - 0.7878788186449589;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.27696508169174194;\t Test AUC - 0.889341413974762;\t Test F1 Score - 0.7373272251942582;\t Test Recall - 0.5882353186607361;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.2513144016265869;\t Test AUC - 0.8966354727745056;\t Test F1 Score - 0.7537689173848651;\t Test Recall - 0.6097561120986938;\t Test Precision - 0.9868420958518982\n",
      "Test Loss - 0.2637619078159332;\t Test AUC - 0.9018758535385132;\t Test F1 Score - 0.754385958370284;\t Test Recall - 0.609929084777832;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.2613864541053772;\t Test AUC - 0.8875351548194885;\t Test F1 Score - 0.7357513125161872;\t Test Recall - 0.5819672346115112;\t Test Precision - 1.0\n",
      "Test Loss - 0.3061157763004303;\t Test AUC - 0.8938491940498352;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 11\n",
      "Train Loss - 0.223493754863739;\t Train AUC - 0.9419241547584534;\t Train F1 Score - 0.7999999856472213;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9898989796638489\n",
      "Train Loss - 0.25976061820983887;\t Train AUC - 0.8849196434020996;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.2511618435382843;\t Train AUC - 0.9109438061714172;\t Train F1 Score - 0.7579908916909065;\t Train Recall - 0.614814817905426;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.22085876762866974;\t Train AUC - 0.9237233996391296;\t Train F1 Score - 0.79262676340133;\t Train Recall - 0.6615384817123413;\t Train Precision - 0.9885057210922241\n",
      "Train Loss - 0.22807057201862335;\t Train AUC - 0.9171766042709351;\t Train F1 Score - 0.8070175564941399;\t Train Recall - 0.6969696879386902;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.25456228852272034;\t Train AUC - 0.9224986433982849;\t Train F1 Score - 0.8028673842881675;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.3069940209388733;\t Train AUC - 0.872695803642273;\t Train F1 Score - 0.7000000235160381;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9746835231781006\n",
      "Train Loss - 0.2132483869791031;\t Train AUC - 0.923229455947876;\t Train F1 Score - 0.83035716414605;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.21717147529125214;\t Train AUC - 0.940021812915802;\t Train F1 Score - 0.7777777290051637;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.24105630815029144;\t Train AUC - 0.9192880988121033;\t Train F1 Score - 0.7476635705889523;\t Train Recall - 0.6153846383094788;\t Train Precision - 0.9523809552192688\n",
      "Train Loss - 0.24297450482845306;\t Train AUC - 0.905742883682251;\t Train F1 Score - 0.801724140418467;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.96875\n",
      "Train Loss - 0.2528430223464966;\t Train AUC - 0.9109755754470825;\t Train F1 Score - 0.7281552994187195;\t Train Recall - 0.5859375;\t Train Precision - 0.9615384340286255\n",
      "Train Loss - 0.21228669583797455;\t Train AUC - 0.9247719049453735;\t Train F1 Score - 0.8019323751443799;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2392168492078781;\t Train AUC - 0.9147201776504517;\t Train F1 Score - 0.7848100946087261;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.9207921028137207\n",
      "Train Loss - 0.2260451763868332;\t Train AUC - 0.9151326417922974;\t Train F1 Score - 0.7887323726889142;\t Train Recall - 0.671999990940094;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.2910263240337372;\t Train AUC - 0.8508157730102539;\t Train F1 Score - 0.698924772017837;\t Train Recall - 0.5508474707603455;\t Train Precision - 0.9558823704719543\n",
      "Train Loss - 0.2087150663137436;\t Train AUC - 0.9186822772026062;\t Train F1 Score - 0.7979797804059968;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9634146094322205\n",
      "Train Loss - 0.21168577671051025;\t Train AUC - 0.9399570822715759;\t Train F1 Score - 0.7962085454856118;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.2628948390483856;\t Train AUC - 0.9069901704788208;\t Train F1 Score - 0.7725321698516844;\t Train Recall - 0.6382978558540344;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.21538014709949493;\t Train AUC - 0.9306808114051819;\t Train F1 Score - 0.7649770309830233;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.8924731016159058\n",
      "Train Loss - 0.258782297372818;\t Train AUC - 0.9059568047523499;\t Train F1 Score - 0.7750000091963934;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.22636574506759644;\t Train AUC - 0.9248278737068176;\t Train F1 Score - 0.7757008997974828;\t Train Recall - 0.6335877776145935;\t Train Precision - 1.0\n",
      "Train Loss - 0.2601064443588257;\t Train AUC - 0.9024705290794373;\t Train F1 Score - 0.7623318599210069;\t Train Recall - 0.625;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.20434221625328064;\t Train AUC - 0.92947918176651;\t Train F1 Score - 0.8097560627012117;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.25760355591773987;\t Train AUC - 0.9075483083724976;\t Train F1 Score - 0.7901234666514272;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.2154546082019806;\t Train AUC - 0.9246914386749268;\t Train F1 Score - 0.8209607124996943;\t Train Recall - 0.6962962746620178;\t Train Precision - 1.0\n",
      "Train Loss - 0.23795074224472046;\t Train AUC - 0.9178587198257446;\t Train F1 Score - 0.7792208002464376;\t Train Recall - 0.6521739363670349;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.22844509780406952;\t Train AUC - 0.9017996191978455;\t Train F1 Score - 0.7700534803471686;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9350649118423462\n",
      "Train Loss - 0.2272489368915558;\t Train AUC - 0.9269682168960571;\t Train F1 Score - 0.807174932833613;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.24187128245830536;\t Train AUC - 0.9352415800094604;\t Train F1 Score - 0.7927272518131928;\t Train Recall - 0.6728395223617554;\t Train Precision - 0.9646017551422119\n",
      "Train Loss - 0.22610445320606232;\t Train AUC - 0.9268971681594849;\t Train F1 Score - 0.790909119848174;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.25319039821624756;\t Train AUC - 0.8896374702453613;\t Train F1 Score - 0.7499999810079737;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.949367105960846\n",
      "Train Loss - 0.2598811388015747;\t Train AUC - 0.8757052421569824;\t Train F1 Score - 0.7487179202624087;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.223741352558136;\t Train AUC - 0.9269112348556519;\t Train F1 Score - 0.7870370437313172;\t Train Recall - 0.6488549709320068;\t Train Precision - 1.0\n",
      "Train Loss - 0.22650489211082458;\t Train AUC - 0.9158902168273926;\t Train F1 Score - 0.7846890488858195;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.9647058844566345\n",
      "Train Loss - 0.23177462816238403;\t Train AUC - 0.9197484850883484;\t Train F1 Score - 0.789237590230526;\t Train Recall - 0.6616541147232056;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.2708198130130768;\t Train AUC - 0.9022618532180786;\t Train F1 Score - 0.7598253207322118;\t Train Recall - 0.6126760840415955;\t Train Precision - 1.0\n",
      "Train Loss - 0.24488118290901184;\t Train AUC - 0.9102962017059326;\t Train F1 Score - 0.7848101143891365;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.9300000071525574\n",
      "Train Loss - 0.061576541513204575;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2263224720954895;\t Test AUC - 0.9026918411254883;\t Test F1 Score - 0.7941176556718632;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9418604373931885\n",
      "Test Loss - 0.26995304226875305;\t Test AUC - 0.8769558072090149;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.2295789122581482;\t Test AUC - 0.9218924045562744;\t Test F1 Score - 0.7757009068578959;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.954023003578186\n",
      "Test Loss - 0.22217106819152832;\t Test AUC - 0.9050214886665344;\t Test F1 Score - 0.8075117645527151;\t Test Recall - 0.682539701461792;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.23357552289962769;\t Test AUC - 0.9207018613815308;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.217018261551857;\t Test AUC - 0.9071005582809448;\t Test F1 Score - 0.7789473545025627;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.24710266292095184;\t Test AUC - 0.8890442848205566;\t Test F1 Score - 0.7351351519443977;\t Test Recall - 0.5862069129943848;\t Test Precision - 0.9855072498321533\n",
      "Test Loss - 0.2512505352497101;\t Test AUC - 0.8912458419799805;\t Test F1 Score - 0.7301587009837709;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9718309640884399\n",
      "Test Loss - 0.23566848039627075;\t Test AUC - 0.9126452207565308;\t Test F1 Score - 0.7947598681473532;\t Test Recall - 0.6642335653305054;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.25728172063827515;\t Test AUC - 0.8787049651145935;\t Test F1 Score - 0.7669902847277571;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9518072009086609\n",
      "Test Loss - 0.3010922372341156;\t Test AUC - 0.8739575147628784;\t Test F1 Score - 0.735042773256108;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9450549483299255\n",
      "Test Loss - 0.24061015248298645;\t Test AUC - 0.9203951358795166;\t Test F1 Score - 0.7811158675323185;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.9680851101875305\n",
      "Test Loss - 0.27749913930892944;\t Test AUC - 0.8879944086074829;\t Test F1 Score - 0.7454544960426418;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.976190447807312\n",
      "Test Loss - 0.24612081050872803;\t Test AUC - 0.8981268405914307;\t Test F1 Score - 0.774509817649225;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.26210927963256836;\t Test AUC - 0.9020071625709534;\t Test F1 Score - 0.754385958370284;\t Test Recall - 0.609929084777832;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.26024219393730164;\t Test AUC - 0.888023853302002;\t Test F1 Score - 0.7357513125161872;\t Test Recall - 0.5819672346115112;\t Test Precision - 1.0\n",
      "Test Loss - 0.3033396601676941;\t Test AUC - 0.8979076743125916;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 12\n",
      "Train Loss - 0.22188079357147217;\t Train AUC - 0.9415318965911865;\t Train F1 Score - 0.7967479586755154;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9800000190734863\n",
      "Train Loss - 0.25859788060188293;\t Train AUC - 0.8863004446029663;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.2498769909143448;\t Train AUC - 0.9130386114120483;\t Train F1 Score - 0.7579908916909065;\t Train Recall - 0.614814817905426;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.22088828682899475;\t Train AUC - 0.9243617653846741;\t Train F1 Score - 0.7981650940757441;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.22772756218910217;\t Train AUC - 0.9165857434272766;\t Train F1 Score - 0.8070175564941399;\t Train Recall - 0.6969696879386902;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.25432151556015015;\t Train AUC - 0.9216632843017578;\t Train F1 Score - 0.8000000289979637;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9572649598121643\n",
      "Train Loss - 0.30719080567359924;\t Train AUC - 0.8725490570068359;\t Train F1 Score - 0.6968325999237617;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.21232320368289948;\t Train AUC - 0.9228262305259705;\t Train F1 Score - 0.83035716414605;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.21627166867256165;\t Train AUC - 0.9406566023826599;\t Train F1 Score - 0.7720930017157879;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.24028851091861725;\t Train AUC - 0.9200164079666138;\t Train F1 Score - 0.7476635705889523;\t Train Recall - 0.6153846383094788;\t Train Precision - 0.9523809552192688\n",
      "Train Loss - 0.242360457777977;\t Train AUC - 0.9044513702392578;\t Train F1 Score - 0.8103448694227046;\t Train Recall - 0.6911764740943909;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.2543337941169739;\t Train AUC - 0.909080445766449;\t Train F1 Score - 0.7317073263924392;\t Train Recall - 0.5859375;\t Train Precision - 0.9740259647369385\n",
      "Train Loss - 0.21268320083618164;\t Train AUC - 0.9255178570747375;\t Train F1 Score - 0.8019323751443799;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.23820136487483978;\t Train AUC - 0.9161226153373718;\t Train F1 Score - 0.7744680796769308;\t Train Recall - 0.6691176295280457;\t Train Precision - 0.9191918969154358\n",
      "Train Loss - 0.22385767102241516;\t Train AUC - 0.9171283841133118;\t Train F1 Score - 0.7887323726889142;\t Train Recall - 0.671999990940094;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.28916680812835693;\t Train AUC - 0.8521081209182739;\t Train F1 Score - 0.7096774319224411;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.970588207244873\n",
      "Train Loss - 0.21013584733009338;\t Train AUC - 0.918700098991394;\t Train F1 Score - 0.7939698782290104;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9518072009086609\n",
      "Train Loss - 0.2118629515171051;\t Train AUC - 0.938852071762085;\t Train F1 Score - 0.79425836632844;\t Train Recall - 0.658730149269104;\t Train Precision - 1.0\n",
      "Train Loss - 0.2586863338947296;\t Train AUC - 0.9080408811569214;\t Train F1 Score - 0.7705627336126593;\t Train Recall - 0.631205677986145;\t Train Precision - 0.9888888597488403\n",
      "Train Loss - 0.2176966369152069;\t Train AUC - 0.9327307343482971;\t Train F1 Score - 0.7557604031980935;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.8817204236984253\n",
      "Train Loss - 0.25657176971435547;\t Train AUC - 0.907472550868988;\t Train F1 Score - 0.7768595485998759;\t Train Recall - 0.6482758522033691;\t Train Precision - 0.969072163105011\n",
      "Train Loss - 0.22731651365756989;\t Train AUC - 0.9254708290100098;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2625443935394287;\t Train AUC - 0.902565598487854;\t Train F1 Score - 0.7533632658421221;\t Train Recall - 0.6176470518112183;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.20370376110076904;\t Train AUC - 0.9312933683395386;\t Train F1 Score - 0.8137254748892616;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.25813940167427063;\t Train AUC - 0.9085941910743713;\t Train F1 Score - 0.7901234666514272;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.21406544744968414;\t Train AUC - 0.9243568778038025;\t Train F1 Score - 0.8189654574040661;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.23900964856147766;\t Train AUC - 0.917568564414978;\t Train F1 Score - 0.7777778024996811;\t Train Recall - 0.6594203114509583;\t Train Precision - 0.9479166865348816\n",
      "Train Loss - 0.22750650346279144;\t Train AUC - 0.9020872116088867;\t Train F1 Score - 0.7700534803471686;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9350649118423462\n",
      "Train Loss - 0.22598835825920105;\t Train AUC - 0.9277169704437256;\t Train F1 Score - 0.8018017784747788;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.24450618028640747;\t Train AUC - 0.9335644841194153;\t Train F1 Score - 0.7912088399448202;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9729729890823364\n",
      "Train Loss - 0.22576472163200378;\t Train AUC - 0.9270185232162476;\t Train F1 Score - 0.790909119848174;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.2526916563510895;\t Train AUC - 0.8897237777709961;\t Train F1 Score - 0.742574255135045;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9259259104728699\n",
      "Train Loss - 0.25946497917175293;\t Train AUC - 0.8756707310676575;\t Train F1 Score - 0.7487179202624087;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.2218123823404312;\t Train AUC - 0.9273099899291992;\t Train F1 Score - 0.7870370437313172;\t Train Recall - 0.6488549709320068;\t Train Precision - 1.0\n",
      "Train Loss - 0.22445577383041382;\t Train AUC - 0.9159324765205383;\t Train F1 Score - 0.788461555261636;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.976190447807312\n",
      "Train Loss - 0.22883234918117523;\t Train AUC - 0.9239989519119263;\t Train F1 Score - 0.789237590230526;\t Train Recall - 0.6616541147232056;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.2699092626571655;\t Train AUC - 0.9004243612289429;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.2416507452726364;\t Train AUC - 0.9120303988456726;\t Train F1 Score - 0.7899159663865546;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9306930899620056\n",
      "Train Loss - 0.060397595167160034;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22634442150592804;\t Test AUC - 0.8990172147750854;\t Test F1 Score - 0.7920792709044567;\t Test Recall - 0.6779661178588867;\t Test Precision - 0.9523809552192688\n",
      "Test Loss - 0.272676557302475;\t Test AUC - 0.8766611814498901;\t Test F1 Score - 0.7511737574717161;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.22992070019245148;\t Test AUC - 0.921168327331543;\t Test F1 Score - 0.7757009068578959;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.954023003578186\n",
      "Test Loss - 0.223050057888031;\t Test AUC - 0.9036735892295837;\t Test F1 Score - 0.8018867748698786;\t Test Recall - 0.6746031641960144;\t Test Precision - 0.9883720874786377\n",
      "Test Loss - 0.23424282670021057;\t Test AUC - 0.9187847375869751;\t Test F1 Score - 0.7596153788495695;\t Test Recall - 0.6269841194152832;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.21674785017967224;\t Test AUC - 0.908003032207489;\t Test F1 Score - 0.7748691494849788;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9610389471054077\n",
      "Test Loss - 0.23848184943199158;\t Test AUC - 0.8974334001541138;\t Test F1 Score - 0.7553191711546617;\t Test Recall - 0.6120689511299133;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.2516038119792938;\t Test AUC - 0.8910613059997559;\t Test F1 Score - 0.726315765890834;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9583333134651184\n",
      "Test Loss - 0.23424316942691803;\t Test AUC - 0.9120383262634277;\t Test F1 Score - 0.7999999856441822;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.2600805461406708;\t Test AUC - 0.8792845010757446;\t Test F1 Score - 0.7609756273623935;\t Test Recall - 0.6341463327407837;\t Test Precision - 0.9512194991111755\n",
      "Test Loss - 0.3070521652698517;\t Test AUC - 0.8668497800827026;\t Test F1 Score - 0.735042773256108;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9450549483299255\n",
      "Test Loss - 0.2412678599357605;\t Test AUC - 0.9186941385269165;\t Test F1 Score - 0.7758620995049257;\t Test Recall - 0.6474820375442505;\t Test Precision - 0.9677419066429138\n",
      "Test Loss - 0.27816614508628845;\t Test AUC - 0.8861799240112305;\t Test F1 Score - 0.7477477204797397;\t Test Recall - 0.6102941036224365;\t Test Precision - 0.9651162624359131\n",
      "Test Loss - 0.2463834583759308;\t Test AUC - 0.8986892700195312;\t Test F1 Score - 0.7562189669320013;\t Test Recall - 0.6178861856460571;\t Test Precision - 0.9743589758872986\n",
      "Test Loss - 0.25989437103271484;\t Test AUC - 0.9019067287445068;\t Test F1 Score - 0.7598253560410868;\t Test Recall - 0.6170212626457214;\t Test Precision - 0.9886363744735718\n",
      "Test Loss - 0.2606106698513031;\t Test AUC - 0.8865320086479187;\t Test F1 Score - 0.7319588255855978;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.3027566373348236;\t Test AUC - 0.8997113704681396;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 13\n",
      "Train Loss - 0.2214471995830536;\t Train AUC - 0.9417129755020142;\t Train F1 Score - 0.7918367906253259;\t Train Recall - 0.664383590221405;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.25863534212112427;\t Train AUC - 0.8867494463920593;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.24681343138217926;\t Train AUC - 0.9172123074531555;\t Train F1 Score - 0.7545454341144099;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.22098591923713684;\t Train AUC - 0.9249427318572998;\t Train F1 Score - 0.7945205499285002;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.225084587931633;\t Train AUC - 0.920365571975708;\t Train F1 Score - 0.8070175564941399;\t Train Recall - 0.6969696879386902;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.25849130749702454;\t Train AUC - 0.9205542206764221;\t Train F1 Score - 0.7971529984656878;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9491525292396545\n",
      "Train Loss - 0.30840209126472473;\t Train AUC - 0.8711892366409302;\t Train F1 Score - 0.7027026772023519;\t Train Recall - 0.5531914830207825;\t Train Precision - 0.9629629850387573\n",
      "Train Loss - 0.2163379192352295;\t Train AUC - 0.9199048280715942;\t Train F1 Score - 0.8230088570942522;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.2148286998271942;\t Train AUC - 0.9405507445335388;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.23883312940597534;\t Train AUC - 0.9191980361938477;\t Train F1 Score - 0.7547170631282487;\t Train Recall - 0.6153846383094788;\t Train Precision - 0.9756097793579102\n",
      "Train Loss - 0.24207615852355957;\t Train AUC - 0.9040393829345703;\t Train F1 Score - 0.8103448694227046;\t Train Recall - 0.6911764740943909;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.2571817636489868;\t Train AUC - 0.9076899886131287;\t Train F1 Score - 0.7317073263924392;\t Train Recall - 0.5859375;\t Train Precision - 0.9740259647369385\n",
      "Train Loss - 0.21422307193279266;\t Train AUC - 0.9241717457771301;\t Train F1 Score - 0.8019323751443799;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.23841656744480133;\t Train AUC - 0.9155758619308472;\t Train F1 Score - 0.7844827300220492;\t Train Recall - 0.6691176295280457;\t Train Precision - 0.9479166865348816\n",
      "Train Loss - 0.22180521488189697;\t Train AUC - 0.918913722038269;\t Train F1 Score - 0.7887323726889142;\t Train Recall - 0.671999990940094;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.2902736961841583;\t Train AUC - 0.8541564345359802;\t Train F1 Score - 0.7096774319224411;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.970588207244873\n",
      "Train Loss - 0.21319687366485596;\t Train AUC - 0.9192344546318054;\t Train F1 Score - 0.7839195775533748;\t Train Recall - 0.6724137663841248;\t Train Precision - 0.9397590160369873\n",
      "Train Loss - 0.212306946516037;\t Train AUC - 0.9399654865264893;\t Train F1 Score - 0.7887324272841363;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.2542130649089813;\t Train AUC - 0.909083902835846;\t Train F1 Score - 0.7777778104044213;\t Train Recall - 0.6453900933265686;\t Train Precision - 0.9784946441650391\n",
      "Train Loss - 0.21570317447185516;\t Train AUC - 0.9335101246833801;\t Train F1 Score - 0.7601809752044629;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.8659793734550476\n",
      "Train Loss - 0.257977694272995;\t Train AUC - 0.9078211188316345;\t Train F1 Score - 0.7717842286786512;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.96875\n",
      "Train Loss - 0.22829926013946533;\t Train AUC - 0.9263659715652466;\t Train F1 Score - 0.7671232641345284;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.2630096971988678;\t Train AUC - 0.903389573097229;\t Train F1 Score - 0.7500000379117998;\t Train Recall - 0.6176470518112183;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.20266014337539673;\t Train AUC - 0.9312065839767456;\t Train F1 Score - 0.8078817491545502;\t Train Recall - 0.6833333373069763;\t Train Precision - 0.9879518151283264\n",
      "Train Loss - 0.2639877498149872;\t Train AUC - 0.9046456813812256;\t Train F1 Score - 0.7750000091963934;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.21277783811092377;\t Train AUC - 0.9278852939605713;\t Train F1 Score - 0.8086956851147581;\t Train Recall - 0.6888889074325562;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.24079132080078125;\t Train AUC - 0.9180704355239868;\t Train F1 Score - 0.7586207288329369;\t Train Recall - 0.6376811861991882;\t Train Precision - 0.936170220375061\n",
      "Train Loss - 0.22619827091693878;\t Train AUC - 0.902755081653595;\t Train F1 Score - 0.7700534803471686;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9350649118423462\n",
      "Train Loss - 0.22975972294807434;\t Train AUC - 0.9232490658760071;\t Train F1 Score - 0.8018017784747788;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.24215303361415863;\t Train AUC - 0.9334869980812073;\t Train F1 Score - 0.7971014282565061;\t Train Recall - 0.6790123581886292;\t Train Precision - 0.9649122953414917\n",
      "Train Loss - 0.2289181500673294;\t Train AUC - 0.9252865314483643;\t Train F1 Score - 0.790909119848174;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.2540086507797241;\t Train AUC - 0.888386607170105;\t Train F1 Score - 0.7487684846139351;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.9268292784690857\n",
      "Train Loss - 0.2638867199420929;\t Train AUC - 0.8691229820251465;\t Train F1 Score - 0.7487179202624087;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.22391800582408905;\t Train AUC - 0.9254138469696045;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.22464701533317566;\t Train AUC - 0.9155428409576416;\t Train F1 Score - 0.7942584279624261;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.22567860782146454;\t Train AUC - 0.9253513813018799;\t Train F1 Score - 0.789237590230526;\t Train Recall - 0.6616541147232056;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.269708514213562;\t Train AUC - 0.9048066139221191;\t Train F1 Score - 0.7488986915544403;\t Train Recall - 0.5985915660858154;\t Train Precision - 1.0\n",
      "Train Loss - 0.2441137731075287;\t Train AUC - 0.9117308259010315;\t Train F1 Score - 0.7881356032090371;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.057010017335414886;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22445732355117798;\t Test AUC - 0.9016104936599731;\t Test F1 Score - 0.8019801987348144;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.27331361174583435;\t Test AUC - 0.8772504329681396;\t Test F1 Score - 0.7511737574717161;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.2270658314228058;\t Test AUC - 0.9237901568412781;\t Test F1 Score - 0.7793427012218024;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9651162624359131\n",
      "Test Loss - 0.2209576964378357;\t Test AUC - 0.9075497388839722;\t Test F1 Score - 0.8075117645527151;\t Test Recall - 0.682539701461792;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.23338645696640015;\t Test AUC - 0.9204172492027283;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.215273916721344;\t Test AUC - 0.9065861105918884;\t Test F1 Score - 0.7789473545025627;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.24648158252239227;\t Test AUC - 0.890905499458313;\t Test F1 Score - 0.7459459229156526;\t Test Recall - 0.5948275923728943;\t Test Precision - 1.0\n",
      "Test Loss - 0.2505265772342682;\t Test AUC - 0.8907711505889893;\t Test F1 Score - 0.726315765890834;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9583333134651184\n",
      "Test Loss - 0.23431558907032013;\t Test AUC - 0.9136463403701782;\t Test F1 Score - 0.7965367927842337;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.978723406791687\n",
      "Test Loss - 0.2547651529312134;\t Test AUC - 0.8804264664649963;\t Test F1 Score - 0.7707317087656925;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.30144596099853516;\t Test AUC - 0.8662683367729187;\t Test F1 Score - 0.7413793273885741;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.966292142868042\n",
      "Test Loss - 0.24162104725837708;\t Test AUC - 0.9189203977584839;\t Test F1 Score - 0.7863247663257549;\t Test Recall - 0.6618704795837402;\t Test Precision - 0.9684210419654846\n",
      "Test Loss - 0.2790130078792572;\t Test AUC - 0.888493537902832;\t Test F1 Score - 0.7305936206329382;\t Test Recall - 0.5882353186607361;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.24689781665802002;\t Test AUC - 0.8999931812286377;\t Test F1 Score - 0.7599999851443265;\t Test Recall - 0.6178861856460571;\t Test Precision - 0.9870129823684692\n",
      "Test Loss - 0.2612293064594269;\t Test AUC - 0.9006551504135132;\t Test F1 Score - 0.7598253560410868;\t Test Recall - 0.6170212626457214;\t Test Precision - 0.9886363744735718\n",
      "Test Loss - 0.2568470239639282;\t Test AUC - 0.8899872303009033;\t Test F1 Score - 0.7319588255855978;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.3003522753715515;\t Test AUC - 0.9013347625732422;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 14\n",
      "Train Loss - 0.22130808234214783;\t Train AUC - 0.9415770769119263;\t Train F1 Score - 0.7967479586755154;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9800000190734863\n",
      "Train Loss - 0.2584848701953888;\t Train AUC - 0.8840386867523193;\t Train F1 Score - 0.7474747685896667;\t Train Recall - 0.5967742204666138;\t Train Precision - 1.0\n",
      "Train Loss - 0.24818997085094452;\t Train AUC - 0.9170768857002258;\t Train F1 Score - 0.7579908916909065;\t Train Recall - 0.614814817905426;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.21559244394302368;\t Train AUC - 0.9264893531799316;\t Train F1 Score - 0.7981650940757441;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.22402730584144592;\t Train AUC - 0.9228907823562622;\t Train F1 Score - 0.8122270000620662;\t Train Recall - 0.7045454382896423;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.25269967317581177;\t Train AUC - 0.9216843843460083;\t Train F1 Score - 0.8071428561163806;\t Train Recall - 0.6932515501976013;\t Train Precision - 0.9658119678497314\n",
      "Train Loss - 0.30530568957328796;\t Train AUC - 0.8755851984024048;\t Train F1 Score - 0.69642861705607;\t Train Recall - 0.5531914830207825;\t Train Precision - 0.9397590160369873\n",
      "Train Loss - 0.2138267457485199;\t Train AUC - 0.9223489761352539;\t Train F1 Score - 0.8193832492196188;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9489796161651611\n",
      "Train Loss - 0.21457484364509583;\t Train AUC - 0.939338207244873;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.23596638441085815;\t Train AUC - 0.9233633279800415;\t Train F1 Score - 0.7476635705889523;\t Train Recall - 0.6153846383094788;\t Train Precision - 0.9523809552192688\n",
      "Train Loss - 0.23649878799915314;\t Train AUC - 0.9071691036224365;\t Train F1 Score - 0.8154506578031245;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.2525504231452942;\t Train AUC - 0.9094693660736084;\t Train F1 Score - 0.7246376834100107;\t Train Recall - 0.5859375;\t Train Precision - 0.949367105960846\n",
      "Train Loss - 0.21414154767990112;\t Train AUC - 0.9234001040458679;\t Train F1 Score - 0.796116459214512;\t Train Recall - 0.6721311211585999;\t Train Precision - 0.976190447807312\n",
      "Train Loss - 0.23677657544612885;\t Train AUC - 0.9131513237953186;\t Train F1 Score - 0.7844827300220492;\t Train Recall - 0.6691176295280457;\t Train Precision - 0.9479166865348816\n",
      "Train Loss - 0.2209441065788269;\t Train AUC - 0.9204463362693787;\t Train F1 Score - 0.7809524145770362;\t Train Recall - 0.656000018119812;\t Train Precision - 0.9647058844566345\n",
      "Train Loss - 0.2828424572944641;\t Train AUC - 0.856239914894104;\t Train F1 Score - 0.7096774319224411;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.970588207244873\n",
      "Train Loss - 0.20752359926700592;\t Train AUC - 0.9216212034225464;\t Train F1 Score - 0.802030441873979;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.20997469127178192;\t Train AUC - 0.9393460154533386;\t Train F1 Score - 0.7924528123964071;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2579023838043213;\t Train AUC - 0.908535361289978;\t Train F1 Score - 0.7672414176268485;\t Train Recall - 0.631205677986145;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.21187709271907806;\t Train AUC - 0.9346452951431274;\t Train F1 Score - 0.7706422310727951;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.8936170339584351\n",
      "Train Loss - 0.2568890452384949;\t Train AUC - 0.9063054323196411;\t Train F1 Score - 0.7750000091963934;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.228417307138443;\t Train AUC - 0.9247384071350098;\t Train F1 Score - 0.7706421432970033;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.2608615458011627;\t Train AUC - 0.9034212827682495;\t Train F1 Score - 0.7623318599210069;\t Train Recall - 0.625;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.20118464529514313;\t Train AUC - 0.9299044609069824;\t Train F1 Score - 0.8155339108673318;\t Train Recall - 0.699999988079071;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.25901955366134644;\t Train AUC - 0.9051079750061035;\t Train F1 Score - 0.7836735038840589;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9599999785423279\n",
      "Train Loss - 0.2107531726360321;\t Train AUC - 0.928132176399231;\t Train F1 Score - 0.8275862528176201;\t Train Recall - 0.7111111283302307;\t Train Precision - 0.9896907210350037\n",
      "Train Loss - 0.2399246245622635;\t Train AUC - 0.9165098071098328;\t Train F1 Score - 0.782978712725607;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9484536051750183\n",
      "Train Loss - 0.2260812371969223;\t Train AUC - 0.9020037055015564;\t Train F1 Score - 0.776595779566074;\t Train Recall - 0.6636363863945007;\t Train Precision - 0.9358974099159241\n",
      "Train Loss - 0.2309122234582901;\t Train AUC - 0.9225573539733887;\t Train F1 Score - 0.8035714414357171;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.24038761854171753;\t Train AUC - 0.935692548751831;\t Train F1 Score - 0.8;\t Train Recall - 0.6790123581886292;\t Train Precision - 0.9734513163566589\n",
      "Train Loss - 0.2252216786146164;\t Train AUC - 0.9278441667556763;\t Train F1 Score - 0.7963800771382238;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9887640476226807\n",
      "Train Loss - 0.2521733343601227;\t Train AUC - 0.8899567127227783;\t Train F1 Score - 0.7462686784237749;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9375\n",
      "Train Loss - 0.2625650465488434;\t Train AUC - 0.8709432482719421;\t Train F1 Score - 0.7448979298656082;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9733333587646484\n",
      "Train Loss - 0.22342531383037567;\t Train AUC - 0.9251452088356018;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.22392740845680237;\t Train AUC - 0.9170337915420532;\t Train F1 Score - 0.7942584279624261;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2267841398715973;\t Train AUC - 0.9254238605499268;\t Train F1 Score - 0.789237590230526;\t Train Recall - 0.6616541147232056;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.2673829197883606;\t Train AUC - 0.9085429906845093;\t Train F1 Score - 0.754385987055343;\t Train Recall - 0.6056337952613831;\t Train Precision - 1.0\n",
      "Train Loss - 0.2463328242301941;\t Train AUC - 0.9093424081802368;\t Train F1 Score - 0.7881356032090371;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.05105841904878616;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22257272899150848;\t Test AUC - 0.9016017317771912;\t Test F1 Score - 0.8019801987348144;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.26709747314453125;\t Test AUC - 0.8802946209907532;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.2241394817829132;\t Test AUC - 0.9251552820205688;\t Test F1 Score - 0.7830188624049881;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9764705896377563\n",
      "Test Loss - 0.21969851851463318;\t Test AUC - 0.9094417691230774;\t Test F1 Score - 0.8018867748698786;\t Test Recall - 0.6746031641960144;\t Test Precision - 0.9883720874786377\n",
      "Test Loss - 0.2326447069644928;\t Test AUC - 0.9249045252799988;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.21584349870681763;\t Test AUC - 0.9074795842170715;\t Test F1 Score - 0.7789473545025627;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.24682293832302094;\t Test AUC - 0.8882516622543335;\t Test F1 Score - 0.7526881688453515;\t Test Recall - 0.6034482717514038;\t Test Precision - 1.0\n",
      "Test Loss - 0.24965733289718628;\t Test AUC - 0.8907359838485718;\t Test F1 Score - 0.7340425144303457;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9857142567634583\n",
      "Test Loss - 0.232574000954628;\t Test AUC - 0.9161529541015625;\t Test F1 Score - 0.7999999856441822;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.2512812912464142;\t Test AUC - 0.8824717402458191;\t Test F1 Score - 0.774509817649225;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.29294484853744507;\t Test AUC - 0.881929874420166;\t Test F1 Score - 0.7391304446775232;\t Test Recall - 0.5944055914878845;\t Test Precision - 0.977011501789093\n",
      "Test Loss - 0.24082082509994507;\t Test AUC - 0.9217371940612793;\t Test F1 Score - 0.7863247663257549;\t Test Recall - 0.6618704795837402;\t Test Precision - 0.9684210419654846\n",
      "Test Loss - 0.27677664160728455;\t Test AUC - 0.8896979093551636;\t Test F1 Score - 0.7373272251942582;\t Test Recall - 0.5882353186607361;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.25033432245254517;\t Test AUC - 0.8985188007354736;\t Test F1 Score - 0.7474747937207497;\t Test Recall - 0.6016260385513306;\t Test Precision - 0.9866666793823242\n",
      "Test Loss - 0.26342514157295227;\t Test AUC - 0.9013581275939941;\t Test F1 Score - 0.7598253560410868;\t Test Recall - 0.6170212626457214;\t Test Precision - 0.9886363744735718\n",
      "Test Loss - 0.25457581877708435;\t Test AUC - 0.8927395343780518;\t Test F1 Score - 0.7357513125161872;\t Test Recall - 0.5819672346115112;\t Test Precision - 1.0\n",
      "Test Loss - 0.3071528375148773;\t Test AUC - 0.8985389471054077;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 15\n",
      "Train Loss - 0.22194607555866241;\t Train AUC - 0.9416978359222412;\t Train F1 Score - 0.8016194340715057;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9801980257034302\n",
      "Train Loss - 0.2561976909637451;\t Train AUC - 0.8897566795349121;\t Train F1 Score - 0.7474747685896667;\t Train Recall - 0.5967742204666138;\t Train Precision - 1.0\n",
      "Train Loss - 0.24780164659023285;\t Train AUC - 0.9172282218933105;\t Train F1 Score - 0.7579908916909065;\t Train Recall - 0.614814817905426;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.2166835516691208;\t Train AUC - 0.926563024520874;\t Train F1 Score - 0.7981650940757441;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.22192199528217316;\t Train AUC - 0.923546314239502;\t Train F1 Score - 0.8017621212321866;\t Train Recall - 0.689393937587738;\t Train Precision - 0.9578947424888611\n",
      "Train Loss - 0.25334256887435913;\t Train AUC - 0.9232708215713501;\t Train F1 Score - 0.8000000289979637;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9572649598121643\n",
      "Train Loss - 0.3006690740585327;\t Train AUC - 0.8780187964439392;\t Train F1 Score - 0.7117116648534695;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.21191775798797607;\t Train AUC - 0.926233172416687;\t Train F1 Score - 0.8157894623475568;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.21447023749351501;\t Train AUC - 0.939533531665802;\t Train F1 Score - 0.7798165756466352;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.23163244128227234;\t Train AUC - 0.9260556697845459;\t Train F1 Score - 0.7649769499012181;\t Train Recall - 0.6384615302085876;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.2369687855243683;\t Train AUC - 0.9086587429046631;\t Train F1 Score - 0.8085106551241308;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.9595959782600403\n",
      "Train Loss - 0.25221049785614014;\t Train AUC - 0.9095355868339539;\t Train F1 Score - 0.7307691773088223;\t Train Recall - 0.59375;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.21213962137699127;\t Train AUC - 0.9254236221313477;\t Train F1 Score - 0.8019323751443799;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.23420532047748566;\t Train AUC - 0.9145854711532593;\t Train F1 Score - 0.7878787567950427;\t Train Recall - 0.6691176295280457;\t Train Precision - 0.9578947424888611\n",
      "Train Loss - 0.21966227889060974;\t Train AUC - 0.9218442440032959;\t Train F1 Score - 0.7830188846058634;\t Train Recall - 0.6639999747276306;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.28481045365333557;\t Train AUC - 0.8543410301208496;\t Train F1 Score - 0.7096774319224411;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.970588207244873\n",
      "Train Loss - 0.20613685250282288;\t Train AUC - 0.9239455461502075;\t Train F1 Score - 0.7979797804059968;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9634146094322205\n",
      "Train Loss - 0.20601221919059753;\t Train AUC - 0.9424519538879395;\t Train F1 Score - 0.7962085454856118;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.25311559438705444;\t Train AUC - 0.9117261171340942;\t Train F1 Score - 0.7619048079729488;\t Train Recall - 0.6241135001182556;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.2105342447757721;\t Train AUC - 0.9347383975982666;\t Train F1 Score - 0.7706422310727951;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.8936170339584351\n",
      "Train Loss - 0.2566789984703064;\t Train AUC - 0.906419038772583;\t Train F1 Score - 0.7750000091963934;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.22625380754470825;\t Train AUC - 0.9293853044509888;\t Train F1 Score - 0.7649768822410304;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.2599111795425415;\t Train AUC - 0.904522716999054;\t Train F1 Score - 0.765765727157475;\t Train Recall - 0.625;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.20080718398094177;\t Train AUC - 0.9316059350967407;\t Train F1 Score - 0.8097560627012117;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.25480642914772034;\t Train AUC - 0.9075634479522705;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.21009910106658936;\t Train AUC - 0.9288491010665894;\t Train F1 Score - 0.8275862528176201;\t Train Recall - 0.7111111283302307;\t Train Precision - 0.9896907210350037\n",
      "Train Loss - 0.23696492612361908;\t Train AUC - 0.9182665348052979;\t Train F1 Score - 0.7777778024996811;\t Train Recall - 0.6594203114509583;\t Train Precision - 0.9479166865348816\n",
      "Train Loss - 0.22443898022174835;\t Train AUC - 0.9043413400650024;\t Train F1 Score - 0.7700534803471686;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9350649118423462\n",
      "Train Loss - 0.22881634533405304;\t Train AUC - 0.923835039138794;\t Train F1 Score - 0.8035714414357171;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.23864372074604034;\t Train AUC - 0.9372428059577942;\t Train F1 Score - 0.8;\t Train Recall - 0.6790123581886292;\t Train Precision - 0.9734513163566589\n",
      "Train Loss - 0.22537879645824432;\t Train AUC - 0.9263225197792053;\t Train F1 Score - 0.7963800771382238;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9887640476226807\n",
      "Train Loss - 0.25126221776008606;\t Train AUC - 0.8908538818359375;\t Train F1 Score - 0.7487684846139351;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.9268292784690857\n",
      "Train Loss - 0.2619808316230774;\t Train AUC - 0.8711588978767395;\t Train F1 Score - 0.7448979298656082;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9733333587646484\n",
      "Train Loss - 0.2216104418039322;\t Train AUC - 0.9275134801864624;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.2233126312494278;\t Train AUC - 0.9176775217056274;\t Train F1 Score - 0.788461555261636;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.976190447807312\n",
      "Train Loss - 0.225067600607872;\t Train AUC - 0.9270579814910889;\t Train F1 Score - 0.789237590230526;\t Train Recall - 0.6616541147232056;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.2661105692386627;\t Train AUC - 0.9092963933944702;\t Train F1 Score - 0.7488986915544403;\t Train Recall - 0.5985915660858154;\t Train Precision - 1.0\n",
      "Train Loss - 0.24330560863018036;\t Train AUC - 0.9113367795944214;\t Train F1 Score - 0.7932489884522943;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9399999976158142\n",
      "Train Loss - 0.04948170855641365;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22373664379119873;\t Test AUC - 0.9018654823303223;\t Test F1 Score - 0.8019801987348144;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.26593250036239624;\t Test AUC - 0.8817348480224609;\t Test F1 Score - 0.7582938420345072;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.22536586225032806;\t Test AUC - 0.92417311668396;\t Test F1 Score - 0.7830188624049881;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9764705896377563\n",
      "Test Loss - 0.21693165600299835;\t Test AUC - 0.9133849143981934;\t Test F1 Score - 0.8018867748698786;\t Test Recall - 0.6746031641960144;\t Test Precision - 0.9883720874786377\n",
      "Test Loss - 0.2316109538078308;\t Test AUC - 0.9264365434646606;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.21481837332248688;\t Test AUC - 0.9087520241737366;\t Test F1 Score - 0.7789473545025627;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.24768783152103424;\t Test AUC - 0.887993335723877;\t Test F1 Score - 0.7459459229156526;\t Test Recall - 0.5948275923728943;\t Test Precision - 1.0\n",
      "Test Loss - 0.2501797378063202;\t Test AUC - 0.8910261392593384;\t Test F1 Score - 0.7301587009837709;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9718309640884399\n",
      "Test Loss - 0.23298782110214233;\t Test AUC - 0.9152700901031494;\t Test F1 Score - 0.7999999856441822;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.2517462372779846;\t Test AUC - 0.8819860219955444;\t Test F1 Score - 0.774509817649225;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.29500848054885864;\t Test AUC - 0.8785634636878967;\t Test F1 Score - 0.7445887612603174;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9772727489471436\n",
      "Test Loss - 0.2400367707014084;\t Test AUC - 0.9214719533920288;\t Test F1 Score - 0.7811158675323185;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.9680851101875305\n",
      "Test Loss - 0.27619293332099915;\t Test AUC - 0.8915203213691711;\t Test F1 Score - 0.7373272251942582;\t Test Recall - 0.5882353186607361;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.2490677833557129;\t Test AUC - 0.8985870480537415;\t Test F1 Score - 0.7537689173848651;\t Test Recall - 0.6097561120986938;\t Test Precision - 0.9868420958518982\n",
      "Test Loss - 0.262638121843338;\t Test AUC - 0.9014277458190918;\t Test F1 Score - 0.754385958370284;\t Test Recall - 0.609929084777832;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.2555745840072632;\t Test AUC - 0.8923108577728271;\t Test F1 Score - 0.7357513125161872;\t Test Recall - 0.5819672346115112;\t Test Precision - 1.0\n",
      "Test Loss - 0.3061065077781677;\t Test AUC - 0.9035894870758057;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 16\n",
      "Train Loss - 0.22161473333835602;\t Train AUC - 0.9416525959968567;\t Train F1 Score - 0.8016194340715057;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9801980257034302\n",
      "Train Loss - 0.25481680035591125;\t Train AUC - 0.8932044506072998;\t Train F1 Score - 0.7474747685896667;\t Train Recall - 0.5967742204666138;\t Train Precision - 1.0\n",
      "Train Loss - 0.2462555170059204;\t Train AUC - 0.9183193445205688;\t Train F1 Score - 0.7545454341144099;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.21525299549102783;\t Train AUC - 0.9262438416481018;\t Train F1 Score - 0.7962963109112896;\t Train Recall - 0.6615384817123413;\t Train Precision - 1.0\n",
      "Train Loss - 0.2203747034072876;\t Train AUC - 0.9255616664886475;\t Train F1 Score - 0.7982456478844147;\t Train Recall - 0.689393937587738;\t Train Precision - 0.9479166865348816\n",
      "Train Loss - 0.25413355231285095;\t Train AUC - 0.9212281703948975;\t Train F1 Score - 0.8000000289979637;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9572649598121643\n",
      "Train Loss - 0.3005150258541107;\t Train AUC - 0.877539873123169;\t Train F1 Score - 0.7085200976270151;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.9634146094322205\n",
      "Train Loss - 0.20918017625808716;\t Train AUC - 0.926323652267456;\t Train F1 Score - 0.8157894623475568;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.21531997621059418;\t Train AUC - 0.9398996829986572;\t Train F1 Score - 0.7853881321852059;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9772727489471436\n",
      "Train Loss - 0.23013794422149658;\t Train AUC - 0.9282242059707642;\t Train F1 Score - 0.7592592648330484;\t Train Recall - 0.6307692527770996;\t Train Precision - 0.9534883499145508\n",
      "Train Loss - 0.2376226782798767;\t Train AUC - 0.9074147343635559;\t Train F1 Score - 0.8085106551241308;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.9595959782600403\n",
      "Train Loss - 0.2518729567527771;\t Train AUC - 0.9083934426307678;\t Train F1 Score - 0.734299532825216;\t Train Recall - 0.59375;\t Train Precision - 0.9620253443717957\n",
      "Train Loss - 0.21089202165603638;\t Train AUC - 0.926118016242981;\t Train F1 Score - 0.8019323751443799;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.23354724049568176;\t Train AUC - 0.9155125021934509;\t Train F1 Score - 0.7878787567950427;\t Train Recall - 0.6691176295280457;\t Train Precision - 0.9578947424888611\n",
      "Train Loss - 0.21923238039016724;\t Train AUC - 0.9216084480285645;\t Train F1 Score - 0.7830188846058634;\t Train Recall - 0.6639999747276306;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.2831001281738281;\t Train AUC - 0.8554663062095642;\t Train F1 Score - 0.7096774319224411;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.970588207244873\n",
      "Train Loss - 0.20381402969360352;\t Train AUC - 0.9245778322219849;\t Train F1 Score - 0.7939698782290104;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9518072009086609\n",
      "Train Loss - 0.2050892859697342;\t Train AUC - 0.9424436092376709;\t Train F1 Score - 0.79425836632844;\t Train Recall - 0.658730149269104;\t Train Precision - 1.0\n",
      "Train Loss - 0.2524819076061249;\t Train AUC - 0.9124136567115784;\t Train F1 Score - 0.7586207129063232;\t Train Recall - 0.6241135001182556;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.2083197683095932;\t Train AUC - 0.9350179433822632;\t Train F1 Score - 0.7720929973110418;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9120879173278809\n",
      "Train Loss - 0.25470462441444397;\t Train AUC - 0.9084122776985168;\t Train F1 Score - 0.7800829301072709;\t Train Recall - 0.6482758522033691;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.2241228222846985;\t Train AUC - 0.9304106831550598;\t Train F1 Score - 0.7649768822410304;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.2568541169166565;\t Train AUC - 0.9072959423065186;\t Train F1 Score - 0.7601809293037148;\t Train Recall - 0.6176470518112183;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.19957146048545837;\t Train AUC - 0.9330469369888306;\t Train F1 Score - 0.8137254748892616;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.2515169680118561;\t Train AUC - 0.9099658727645874;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.2088479846715927;\t Train AUC - 0.9303305149078369;\t Train F1 Score - 0.8225108401872923;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9895833134651184\n",
      "Train Loss - 0.23238502442836761;\t Train AUC - 0.9212701320648193;\t Train F1 Score - 0.7811159294943283;\t Train Recall - 0.6594203114509583;\t Train Precision - 0.9578947424888611\n",
      "Train Loss - 0.22382670640945435;\t Train AUC - 0.9057142734527588;\t Train F1 Score - 0.7700534803471686;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9350649118423462\n",
      "Train Loss - 0.22599457204341888;\t Train AUC - 0.9263496994972229;\t Train F1 Score - 0.8035714414357171;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.23686549067497253;\t Train AUC - 0.9382927417755127;\t Train F1 Score - 0.8086642242642548;\t Train Recall - 0.6913580298423767;\t Train Precision - 0.9739130139350891\n",
      "Train Loss - 0.22422780096530914;\t Train AUC - 0.9280545711517334;\t Train F1 Score - 0.7927928319777304;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.24966460466384888;\t Train AUC - 0.8919754028320312;\t Train F1 Score - 0.7562188889365629;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.2592537999153137;\t Train AUC - 0.8754205703735352;\t Train F1 Score - 0.7448979298656082;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9733333587646484\n",
      "Train Loss - 0.2194068878889084;\t Train AUC - 0.9283517003059387;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.22166603803634644;\t Train AUC - 0.9202189445495605;\t Train F1 Score - 0.7809523373611169;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.9534883499145508\n",
      "Train Loss - 0.22426529228687286;\t Train AUC - 0.9287726879119873;\t Train F1 Score - 0.7946429036671301;\t Train Recall - 0.6691729426383972;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.265470951795578;\t Train AUC - 0.9092963933944702;\t Train F1 Score - 0.7433628172758311;\t Train Recall - 0.591549277305603;\t Train Precision - 1.0\n",
      "Train Loss - 0.24213913083076477;\t Train AUC - 0.9138591289520264;\t Train F1 Score - 0.7932489884522943;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9399999976158142\n",
      "Train Loss - 0.05217323079705238;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22349883615970612;\t Test AUC - 0.9015050530433655;\t Test F1 Score - 0.8019801987348144;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.2659890055656433;\t Test AUC - 0.8814566135406494;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.22705723345279694;\t Test AUC - 0.9225000739097595;\t Test F1 Score - 0.7830188624049881;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9764705896377563\n",
      "Test Loss - 0.2177428901195526;\t Test AUC - 0.9136946201324463;\t Test F1 Score - 0.8018867748698786;\t Test Recall - 0.6746031641960144;\t Test Precision - 0.9883720874786377\n",
      "Test Loss - 0.23153053224086761;\t Test AUC - 0.92698073387146;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.21344050765037537;\t Test AUC - 0.9097267389297485;\t Test F1 Score - 0.7789473545025627;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.2477872520685196;\t Test AUC - 0.8862389922142029;\t Test F1 Score - 0.7526881688453515;\t Test Recall - 0.6034482717514038;\t Test Precision - 1.0\n",
      "Test Loss - 0.2510763704776764;\t Test AUC - 0.8903228044509888;\t Test F1 Score - 0.726315765890834;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9583333134651184\n",
      "Test Loss - 0.23454709351062775;\t Test AUC - 0.9131497144699097;\t Test F1 Score - 0.7999999856441822;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.2527667284011841;\t Test AUC - 0.883238673210144;\t Test F1 Score - 0.7783250860399504;\t Test Recall - 0.642276406288147;\t Test Precision - 0.987500011920929\n",
      "Test Loss - 0.2964285910129547;\t Test AUC - 0.8769261837005615;\t Test F1 Score - 0.7445887612603174;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9772727489471436\n",
      "Test Loss - 0.2413090467453003;\t Test AUC - 0.9197864532470703;\t Test F1 Score - 0.7811158675323185;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.9680851101875305\n",
      "Test Loss - 0.27527907490730286;\t Test AUC - 0.8901258111000061;\t Test F1 Score - 0.7431192736528404;\t Test Recall - 0.595588207244873;\t Test Precision - 0.9878048896789551\n",
      "Test Loss - 0.2481657862663269;\t Test AUC - 0.8979052305221558;\t Test F1 Score - 0.7537689173848651;\t Test Recall - 0.6097561120986938;\t Test Precision - 0.9868420958518982\n",
      "Test Loss - 0.26190853118896484;\t Test AUC - 0.9041471481323242;\t Test F1 Score - 0.7652174112281647;\t Test Recall - 0.6241135001182556;\t Test Precision - 0.9887640476226807\n",
      "Test Loss - 0.25393590331077576;\t Test AUC - 0.8938798904418945;\t Test F1 Score - 0.7357513125161872;\t Test Recall - 0.5819672346115112;\t Test Precision - 1.0\n",
      "Test Loss - 0.3039019703865051;\t Test AUC - 0.9063853025436401;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 17\n",
      "Train Loss - 0.2231723517179489;\t Train AUC - 0.9409434795379639;\t Train F1 Score - 0.8016194340715057;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9801980257034302\n",
      "Train Loss - 0.252982497215271;\t Train AUC - 0.8939498662948608;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.24442028999328613;\t Train AUC - 0.9196097254753113;\t Train F1 Score - 0.7545454341144099;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.21324406564235687;\t Train AUC - 0.9286579489707947;\t Train F1 Score - 0.7981650940757441;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.22079157829284668;\t Train AUC - 0.9244285821914673;\t Train F1 Score - 0.7999999416978717;\t Train Recall - 0.6969696879386902;\t Train Precision - 0.9387755393981934\n",
      "Train Loss - 0.25242194533348083;\t Train AUC - 0.9219440817832947;\t Train F1 Score - 0.7971529984656878;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9491525292396545\n",
      "Train Loss - 0.29892680048942566;\t Train AUC - 0.8779183626174927;\t Train F1 Score - 0.6968325999237617;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.20788973569869995;\t Train AUC - 0.9280929565429688;\t Train F1 Score - 0.8266666619632406;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.96875\n",
      "Train Loss - 0.21555796265602112;\t Train AUC - 0.9407705068588257;\t Train F1 Score - 0.7853881321852059;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9772727489471436\n",
      "Train Loss - 0.23018494248390198;\t Train AUC - 0.9292634725570679;\t Train F1 Score - 0.7534883822955664;\t Train Recall - 0.6230769157409668;\t Train Precision - 0.9529411792755127\n",
      "Train Loss - 0.2383294403553009;\t Train AUC - 0.9064005613327026;\t Train F1 Score - 0.8085106551241308;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.9595959782600403\n",
      "Train Loss - 0.24848368763923645;\t Train AUC - 0.9120514392852783;\t Train F1 Score - 0.7368421093053269;\t Train Recall - 0.6015625;\t Train Precision - 0.9506173133850098\n",
      "Train Loss - 0.20954760909080505;\t Train AUC - 0.9279357194900513;\t Train F1 Score - 0.7922704923477057;\t Train Recall - 0.6721311211585999;\t Train Precision - 0.9647058844566345\n",
      "Train Loss - 0.23307368159294128;\t Train AUC - 0.9159402847290039;\t Train F1 Score - 0.7878787567950427;\t Train Recall - 0.6691176295280457;\t Train Precision - 0.9578947424888611\n",
      "Train Loss - 0.21940241754055023;\t Train AUC - 0.921178936958313;\t Train F1 Score - 0.7887323726889142;\t Train Recall - 0.671999990940094;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.28257161378860474;\t Train AUC - 0.8574530482292175;\t Train F1 Score - 0.7096774319224411;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.970588207244873\n",
      "Train Loss - 0.20343126356601715;\t Train AUC - 0.9249519109725952;\t Train F1 Score - 0.7939698782290104;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9518072009086609\n",
      "Train Loss - 0.20282649993896484;\t Train AUC - 0.9424519538879395;\t Train F1 Score - 0.7962085454856118;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.251755028963089;\t Train AUC - 0.9121819138526917;\t Train F1 Score - 0.7598253560410868;\t Train Recall - 0.6170212626457214;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.20533409714698792;\t Train AUC - 0.9352974891662598;\t Train F1 Score - 0.7904761876977344;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.2528530955314636;\t Train AUC - 0.9091852903366089;\t Train F1 Score - 0.7800829301072709;\t Train Recall - 0.6482758522033691;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.22243179380893707;\t Train AUC - 0.9303944110870361;\t Train F1 Score - 0.7741935555172754;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.25411900877952576;\t Train AUC - 0.9082150459289551;\t Train F1 Score - 0.7555555589087215;\t Train Recall - 0.625;\t Train Precision - 0.9550561904907227\n",
      "Train Loss - 0.19817642867565155;\t Train AUC - 0.93442702293396;\t Train F1 Score - 0.8137254748892616;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.2511930465698242;\t Train AUC - 0.9101780652999878;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.20794855058193207;\t Train AUC - 0.9294065833091736;\t Train F1 Score - 0.8260869839015675;\t Train Recall - 0.7037037014961243;\t Train Precision - 1.0\n",
      "Train Loss - 0.23183268308639526;\t Train AUC - 0.9205408096313477;\t Train F1 Score - 0.7878788275775835;\t Train Recall - 0.6594203114509583;\t Train Precision - 0.9784946441650391\n",
      "Train Loss - 0.22303275763988495;\t Train AUC - 0.905102014541626;\t Train F1 Score - 0.7700534803471686;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9350649118423462\n",
      "Train Loss - 0.22419404983520508;\t Train AUC - 0.9267484545707703;\t Train F1 Score - 0.8018017784747788;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.2360783964395523;\t Train AUC - 0.9374048709869385;\t Train F1 Score - 0.804347852644567;\t Train Recall - 0.6851851940155029;\t Train Precision - 0.9736841917037964\n",
      "Train Loss - 0.22244158387184143;\t Train AUC - 0.9302722215652466;\t Train F1 Score - 0.7853881361515602;\t Train Recall - 0.6515151262283325;\t Train Precision - 0.9885057210922241\n",
      "Train Loss - 0.2477014660835266;\t Train AUC - 0.8939077258110046;\t Train F1 Score - 0.7599999760100734;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.9620253443717957\n",
      "Train Loss - 0.258249968290329;\t Train AUC - 0.8759726881980896;\t Train F1 Score - 0.7487179202624087;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.21917849779129028;\t Train AUC - 0.9273832440376282;\t Train F1 Score - 0.7870370437313172;\t Train Recall - 0.6488549709320068;\t Train Precision - 1.0\n",
      "Train Loss - 0.22113950550556183;\t Train AUC - 0.9205831289291382;\t Train F1 Score - 0.7830188916368213;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9431818127632141\n",
      "Train Loss - 0.22367985546588898;\t Train AUC - 0.9283138513565063;\t Train F1 Score - 0.7946429036671301;\t Train Recall - 0.6691729426383972;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.26176905632019043;\t Train AUC - 0.9120026230812073;\t Train F1 Score - 0.7598253207322118;\t Train Recall - 0.6126760840415955;\t Train Precision - 1.0\n",
      "Train Loss - 0.24355082213878632;\t Train AUC - 0.910580039024353;\t Train F1 Score - 0.7899159663865546;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9306930899620056\n",
      "Train Loss - 0.05186312645673752;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2253323346376419;\t Test AUC - 0.9010391235351562;\t Test F1 Score - 0.7960198939953087;\t Test Recall - 0.6779661178588867;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.26676705479621887;\t Test AUC - 0.8818985223770142;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.22541294991970062;\t Test AUC - 0.9241147637367249;\t Test F1 Score - 0.7772511224796853;\t Test Recall - 0.6456692814826965;\t Test Precision - 0.976190447807312\n",
      "Test Loss - 0.21749180555343628;\t Test AUC - 0.9135439395904541;\t Test F1 Score - 0.7924528123964071;\t Test Recall - 0.6666666865348816;\t Test Precision - 0.9767441749572754\n",
      "Test Loss - 0.23188075423240662;\t Test AUC - 0.9264197945594788;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.21405233442783356;\t Test AUC - 0.9092755317687988;\t Test F1 Score - 0.7789473545025627;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.2479357123374939;\t Test AUC - 0.8856066465377808;\t Test F1 Score - 0.7486630839561824;\t Test Recall - 0.6034482717514038;\t Test Precision - 0.98591548204422\n",
      "Test Loss - 0.2533515393733978;\t Test AUC - 0.8871843814849854;\t Test F1 Score - 0.7340425144303457;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9857142567634583\n",
      "Test Loss - 0.2336386889219284;\t Test AUC - 0.9145370721817017;\t Test F1 Score - 0.7999999856441822;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.252654105424881;\t Test AUC - 0.8834262490272522;\t Test F1 Score - 0.774509817649225;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.29683294892311096;\t Test AUC - 0.8759850263595581;\t Test F1 Score - 0.7445887612603174;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9772727489471436\n",
      "Test Loss - 0.23783737421035767;\t Test AUC - 0.9222366213798523;\t Test F1 Score - 0.7811158675323185;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.9680851101875305\n",
      "Test Loss - 0.2739444375038147;\t Test AUC - 0.8889056444168091;\t Test F1 Score - 0.7373272251942582;\t Test Recall - 0.5882353186607361;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.24654611945152283;\t Test AUC - 0.9012459516525269;\t Test F1 Score - 0.7599999851443265;\t Test Recall - 0.6178861856460571;\t Test Precision - 0.9870129823684692\n",
      "Test Loss - 0.25977185368537903;\t Test AUC - 0.9042398929595947;\t Test F1 Score - 0.7705627336126593;\t Test Recall - 0.631205677986145;\t Test Precision - 0.9888888597488403\n",
      "Test Loss - 0.253836065530777;\t Test AUC - 0.894694447517395;\t Test F1 Score - 0.7422680505113401;\t Test Recall - 0.5901639461517334;\t Test Precision - 1.0\n",
      "Test Loss - 0.3029498755931854;\t Test AUC - 0.908730149269104;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 18\n",
      "Train Loss - 0.22194696962833405;\t Train AUC - 0.9409208297729492;\t Train F1 Score - 0.7967479586755154;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9800000190734863\n",
      "Train Loss - 0.2507259249687195;\t Train AUC - 0.8965082168579102;\t Train F1 Score - 0.7474747685896667;\t Train Recall - 0.5967742204666138;\t Train Precision - 1.0\n",
      "Train Loss - 0.2443397045135498;\t Train AUC - 0.9196256399154663;\t Train F1 Score - 0.7545454341144099;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.21325178444385529;\t Train AUC - 0.9288788437843323;\t Train F1 Score - 0.7962963109112896;\t Train Recall - 0.6615384817123413;\t Train Precision - 1.0\n",
      "Train Loss - 0.22068236768245697;\t Train AUC - 0.9245499968528748;\t Train F1 Score - 0.8070175564941399;\t Train Recall - 0.6969696879386902;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.24945124983787537;\t Train AUC - 0.9256924390792847;\t Train F1 Score - 0.8028673842881675;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.29643967747688293;\t Train AUC - 0.8830482363700867;\t Train F1 Score - 0.7027026772023519;\t Train Recall - 0.5531914830207825;\t Train Precision - 0.9629629850387573\n",
      "Train Loss - 0.20789340138435364;\t Train AUC - 0.926982045173645;\t Train F1 Score - 0.8355555595884933;\t Train Recall - 0.7286821603775024;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.21343328058719635;\t Train AUC - 0.9393138885498047;\t Train F1 Score - 0.7889907771545216;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9885057210922241\n",
      "Train Loss - 0.2293245941400528;\t Train AUC - 0.9280687570571899;\t Train F1 Score - 0.7649769499012181;\t Train Recall - 0.6384615302085876;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.23806923627853394;\t Train AUC - 0.9072483777999878;\t Train F1 Score - 0.8085106551241308;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.9595959782600403\n",
      "Train Loss - 0.25100040435791016;\t Train AUC - 0.9096431732177734;\t Train F1 Score - 0.7333333075402875;\t Train Recall - 0.6015625;\t Train Precision - 0.9390243887901306\n",
      "Train Loss - 0.21003666520118713;\t Train AUC - 0.9251748919487;\t Train F1 Score - 0.8019323751443799;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.23177862167358398;\t Train AUC - 0.9160750508308411;\t Train F1 Score - 0.7931034658771513;\t Train Recall - 0.6764705777168274;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.21765869855880737;\t Train AUC - 0.9231746792793274;\t Train F1 Score - 0.7887323726889142;\t Train Recall - 0.671999990940094;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.28133758902549744;\t Train AUC - 0.8590881824493408;\t Train F1 Score - 0.7096774319224411;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.970588207244873\n",
      "Train Loss - 0.20431910455226898;\t Train AUC - 0.9247292280197144;\t Train F1 Score - 0.7939698782290104;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9518072009086609\n",
      "Train Loss - 0.20171557366847992;\t Train AUC - 0.9440007209777832;\t Train F1 Score - 0.7981220589504767;\t Train Recall - 0.6746031641960144;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.24842427670955658;\t Train AUC - 0.9138506650924683;\t Train F1 Score - 0.7811158957920415;\t Train Recall - 0.6453900933265686;\t Train Precision - 0.989130437374115\n",
      "Train Loss - 0.2053779512643814;\t Train AUC - 0.935195803642273;\t Train F1 Score - 0.7942584279624261;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.252389132976532;\t Train AUC - 0.9091246724128723;\t Train F1 Score - 0.7800829301072709;\t Train Recall - 0.6482758522033691;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.22195535898208618;\t Train AUC - 0.9302560091018677;\t Train F1 Score - 0.7741935555172754;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.255157470703125;\t Train AUC - 0.9081833362579346;\t Train F1 Score - 0.7577092674144152;\t Train Recall - 0.6323529481887817;\t Train Precision - 0.9450549483299255\n",
      "Train Loss - 0.1992674320936203;\t Train AUC - 0.9322916269302368;\t Train F1 Score - 0.8118811621758051;\t Train Recall - 0.6833333373069763;\t Train Precision - 1.0\n",
      "Train Loss - 0.251490980386734;\t Train AUC - 0.9108525514602661;\t Train F1 Score - 0.793388464346472;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9896907210350037\n",
      "Train Loss - 0.208945170044899;\t Train AUC - 0.9305615425109863;\t Train F1 Score - 0.8189654574040661;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.23291447758674622;\t Train AUC - 0.9222504496574402;\t Train F1 Score - 0.7844827744066015;\t Train Recall - 0.6594203114509583;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.2205435186624527;\t Train AUC - 0.9081354141235352;\t Train F1 Score - 0.7659573905384713;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9230769276618958\n",
      "Train Loss - 0.22677068412303925;\t Train AUC - 0.9256172776222229;\t Train F1 Score - 0.8018017784747788;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.23538248240947723;\t Train AUC - 0.9374048709869385;\t Train F1 Score - 0.8086642242642548;\t Train Recall - 0.6913580298423767;\t Train Precision - 0.9739130139350891\n",
      "Train Loss - 0.22208862006664276;\t Train AUC - 0.929713785648346;\t Train F1 Score - 0.7927928319777304;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.24612444639205933;\t Train AUC - 0.8943649530410767;\t Train F1 Score - 0.7599999760100734;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.9620253443717957\n",
      "Train Loss - 0.2583387792110443;\t Train AUC - 0.8748598098754883;\t Train F1 Score - 0.7448979298656082;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9733333587646484\n",
      "Train Loss - 0.21851888298988342;\t Train AUC - 0.9281238317489624;\t Train F1 Score - 0.7870370437313172;\t Train Recall - 0.6488549709320068;\t Train Precision - 1.0\n",
      "Train Loss - 0.22048087418079376;\t Train AUC - 0.9201849699020386;\t Train F1 Score - 0.7904761876977344;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.22319945693016052;\t Train AUC - 0.9294489026069641;\t Train F1 Score - 0.791111131182906;\t Train Recall - 0.6691729426383972;\t Train Precision - 0.967391312122345\n",
      "Train Loss - 0.2615828514099121;\t Train AUC - 0.9125330448150635;\t Train F1 Score - 0.7598253207322118;\t Train Recall - 0.6126760840415955;\t Train Precision - 1.0\n",
      "Train Loss - 0.2458503246307373;\t Train AUC - 0.9110135436058044;\t Train F1 Score - 0.7866108473261698;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9215686321258545\n",
      "Train Loss - 0.04607871174812317;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22434259951114655;\t Test AUC - 0.900239109992981;\t Test F1 Score - 0.7980295709785218;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9529411792755127\n",
      "Test Loss - 0.27001631259918213;\t Test AUC - 0.8793125748634338;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.22714315354824066;\t Test AUC - 0.9202859997749329;\t Test F1 Score - 0.7830188624049881;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9764705896377563\n",
      "Test Loss - 0.2140098363161087;\t Test AUC - 0.9129160642623901;\t Test F1 Score - 0.8093022886838513;\t Test Recall - 0.6904761791229248;\t Test Precision - 0.9775280952453613\n",
      "Test Loss - 0.23103927075862885;\t Test AUC - 0.9260514974594116;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.2154046595096588;\t Test AUC - 0.909392774105072;\t Test F1 Score - 0.7748691494849788;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9610389471054077\n",
      "Test Loss - 0.24670885503292084;\t Test AUC - 0.8881447315216064;\t Test F1 Score - 0.7553191711546617;\t Test Recall - 0.6120689511299133;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.25240617990493774;\t Test AUC - 0.887061357498169;\t Test F1 Score - 0.726315765890834;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9583333134651184\n",
      "Test Loss - 0.22976669669151306;\t Test AUC - 0.9170831441879272;\t Test F1 Score - 0.7999999856441822;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.2553630769252777;\t Test AUC - 0.882625162601471;\t Test F1 Score - 0.7632850448942468;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9404761791229248\n",
      "Test Loss - 0.3020321726799011;\t Test AUC - 0.873812198638916;\t Test F1 Score - 0.735042773256108;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9450549483299255\n",
      "Test Loss - 0.2387511134147644;\t Test AUC - 0.9200440645217896;\t Test F1 Score - 0.7863247663257549;\t Test Recall - 0.6618704795837402;\t Test Precision - 0.9684210419654846\n",
      "Test Loss - 0.2718762159347534;\t Test AUC - 0.8905774354934692;\t Test F1 Score - 0.7511312475550771;\t Test Recall - 0.6102941036224365;\t Test Precision - 0.9764705896377563\n",
      "Test Loss - 0.24828508496284485;\t Test AUC - 0.9031378030776978;\t Test F1 Score - 0.7562189669320013;\t Test Recall - 0.6178861856460571;\t Test Precision - 0.9743589758872986\n",
      "Test Loss - 0.2579582929611206;\t Test AUC - 0.9036604166030884;\t Test F1 Score - 0.7705627336126593;\t Test Recall - 0.631205677986145;\t Test Precision - 0.9888888597488403\n",
      "Test Loss - 0.25314322113990784;\t Test AUC - 0.8933483362197876;\t Test F1 Score - 0.7422680505113401;\t Test Recall - 0.5901639461517334;\t Test Precision - 1.0\n",
      "Test Loss - 0.2991964519023895;\t Test AUC - 0.9114357829093933;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 19\n",
      "Train Loss - 0.21998703479766846;\t Train AUC - 0.9400308132171631;\t Train F1 Score - 0.8064516267580489;\t Train Recall - 0.6849315166473389;\t Train Precision - 0.9803921580314636\n",
      "Train Loss - 0.24759022891521454;\t Train AUC - 0.8998881578445435;\t Train F1 Score - 0.7474747685896667;\t Train Recall - 0.5967742204666138;\t Train Precision - 1.0\n",
      "Train Loss - 0.24462173879146576;\t Train AUC - 0.9195220470428467;\t Train F1 Score - 0.7511312172810917;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.21575741469860077;\t Train AUC - 0.9272749423980713;\t Train F1 Score - 0.7963800885290406;\t Train Recall - 0.6769230961799622;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.2193896472454071;\t Train AUC - 0.9259744882583618;\t Train F1 Score - 0.8105727074059201;\t Train Recall - 0.6969696879386902;\t Train Precision - 0.9684210419654846\n",
      "Train Loss - 0.24698811769485474;\t Train AUC - 0.9284651279449463;\t Train F1 Score - 0.8000000289979637;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9572649598121643\n",
      "Train Loss - 0.2974753677845001;\t Train AUC - 0.8801202178001404;\t Train F1 Score - 0.7085200976270151;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.9634146094322205\n",
      "Train Loss - 0.20783819258213043;\t Train AUC - 0.9264470934867859;\t Train F1 Score - 0.8340807618724737;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9893617033958435\n",
      "Train Loss - 0.21821579337120056;\t Train AUC - 0.9413564205169678;\t Train F1 Score - 0.7605633928261951;\t Train Recall - 0.6183205842971802;\t Train Precision - 0.9878048896789551\n",
      "Train Loss - 0.22997935116291046;\t Train AUC - 0.927463173866272;\t Train F1 Score - 0.7741935698611735;\t Train Recall - 0.6461538672447205;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.2366652488708496;\t Train AUC - 0.9078188538551331;\t Train F1 Score - 0.8119658186853965;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.9693877696990967\n",
      "Train Loss - 0.24829767644405365;\t Train AUC - 0.9120431542396545;\t Train F1 Score - 0.7333333075402875;\t Train Recall - 0.6015625;\t Train Precision - 0.9390243887901306\n",
      "Train Loss - 0.21246019005775452;\t Train AUC - 0.9237344861030579;\t Train F1 Score - 0.7980769523348064;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.23325416445732117;\t Train AUC - 0.9158848524093628;\t Train F1 Score - 0.7914893913906879;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.21758855879306793;\t Train AUC - 0.9240252375602722;\t Train F1 Score - 0.7887323726889142;\t Train Recall - 0.671999990940094;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.2828017473220825;\t Train AUC - 0.8615584373474121;\t Train F1 Score - 0.7021277034744015;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.9428571462631226\n",
      "Train Loss - 0.20677483081817627;\t Train AUC - 0.9242839813232422;\t Train F1 Score - 0.7899999838261672;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9404761791229248\n",
      "Train Loss - 0.20304957032203674;\t Train AUC - 0.9415562152862549;\t Train F1 Score - 0.7904761725517084;\t Train Recall - 0.658730149269104;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.2534359395503998;\t Train AUC - 0.9120814800262451;\t Train F1 Score - 0.7672414176268485;\t Train Recall - 0.631205677986145;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.20439937710762024;\t Train AUC - 0.9342132210731506;\t Train F1 Score - 0.788461555261636;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.976190447807312\n",
      "Train Loss - 0.253158301115036;\t Train AUC - 0.909511148929596;\t Train F1 Score - 0.7800829301072709;\t Train Recall - 0.6482758522033691;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.22350789606571198;\t Train AUC - 0.9300362467765808;\t Train F1 Score - 0.7706421432970033;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.25648337602615356;\t Train AUC - 0.9049743413925171;\t Train F1 Score - 0.7623318599210069;\t Train Recall - 0.625;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.1988270878791809;\t Train AUC - 0.9331597089767456;\t Train F1 Score - 0.8118811621758051;\t Train Recall - 0.6833333373069763;\t Train Precision - 1.0\n",
      "Train Loss - 0.25270766019821167;\t Train AUC - 0.9114891886711121;\t Train F1 Score - 0.7851239006414408;\t Train Recall - 0.6551724076271057;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.20893371105194092;\t Train AUC - 0.9290242791175842;\t Train F1 Score - 0.8225108401872923;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9895833134651184\n",
      "Train Loss - 0.23085831105709076;\t Train AUC - 0.9217956066131592;\t Train F1 Score - 0.7894736728179493;\t Train Recall - 0.6521739363670349;\t Train Precision - 1.0\n",
      "Train Loss - 0.22285395860671997;\t Train AUC - 0.9094434380531311;\t Train F1 Score - 0.7619047691549005;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9113923907279968\n",
      "Train Loss - 0.22755594551563263;\t Train AUC - 0.9237780570983887;\t Train F1 Score - 0.8125000133590692;\t Train Recall - 0.694656491279602;\t Train Precision - 0.9784946441650391\n",
      "Train Loss - 0.234354168176651;\t Train AUC - 0.9362140893936157;\t Train F1 Score - 0.810035826367573;\t Train Recall - 0.6975308656692505;\t Train Precision - 0.9658119678497314\n",
      "Train Loss - 0.22579032182693481;\t Train AUC - 0.9279007911682129;\t Train F1 Score - 0.7837837699114149;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.24806299805641174;\t Train AUC - 0.8952018022537231;\t Train F1 Score - 0.7562188889365629;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.25789907574653625;\t Train AUC - 0.8751876354217529;\t Train F1 Score - 0.7487179202624087;\t Train Recall - 0.6033057570457458;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.21945981681346893;\t Train AUC - 0.9249987602233887;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.2218371033668518;\t Train AUC - 0.9195073246955872;\t Train F1 Score - 0.7830188916368213;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9431818127632141\n",
      "Train Loss - 0.2215154767036438;\t Train AUC - 0.9299560785293579;\t Train F1 Score - 0.791111131182906;\t Train Recall - 0.6691729426383972;\t Train Precision - 0.967391312122345\n",
      "Train Loss - 0.2656562924385071;\t Train AUC - 0.9098268747329712;\t Train F1 Score - 0.754385987055343;\t Train Recall - 0.6056337952613831;\t Train Precision - 1.0\n",
      "Train Loss - 0.2428254634141922;\t Train AUC - 0.9134807586669922;\t Train F1 Score - 0.7863247706011554;\t Train Recall - 0.6715328693389893;\t Train Precision - 0.9484536051750183\n",
      "Train Loss - 0.04890536516904831;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22254501283168793;\t Test AUC - 0.901962161064148;\t Test F1 Score - 0.7899999342960663;\t Test Recall - 0.6694915294647217;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.2674330770969391;\t Test AUC - 0.884901762008667;\t Test F1 Score - 0.7428571688074636;\t Test Recall - 0.6000000238418579;\t Test Precision - 0.9750000238418579\n",
      "Test Loss - 0.2277391105890274;\t Test AUC - 0.9244560599327087;\t Test F1 Score - 0.7772511224796853;\t Test Recall - 0.6456692814826965;\t Test Precision - 0.976190447807312\n",
      "Test Loss - 0.21661725640296936;\t Test AUC - 0.9117189049720764;\t Test F1 Score - 0.8075117645527151;\t Test Recall - 0.682539701461792;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.23653069138526917;\t Test AUC - 0.9254989624023438;\t Test F1 Score - 0.7655502670617305;\t Test Recall - 0.6349206566810608;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.21083888411521912;\t Test AUC - 0.9119016528129578;\t Test F1 Score - 0.7830688200850066;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9866666793823242\n",
      "Test Loss - 0.2439921498298645;\t Test AUC - 0.8942719101905823;\t Test F1 Score - 0.741935503334981;\t Test Recall - 0.5948275923728943;\t Test Precision - 0.9857142567634583\n",
      "Test Loss - 0.25545769929885864;\t Test AUC - 0.8868239521980286;\t Test F1 Score - 0.7340425144303457;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9857142567634583\n",
      "Test Loss - 0.2333831489086151;\t Test AUC - 0.9170910120010376;\t Test F1 Score - 0.7947598681473532;\t Test Recall - 0.6642335653305054;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.25297361612319946;\t Test AUC - 0.8832813501358032;\t Test F1 Score - 0.7783250860399504;\t Test Recall - 0.642276406288147;\t Test Precision - 0.987500011920929\n",
      "Test Loss - 0.29555872082710266;\t Test AUC - 0.8774234056472778;\t Test F1 Score - 0.747826061528892;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.24203786253929138;\t Test AUC - 0.9223223924636841;\t Test F1 Score - 0.784482807701881;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.9784946441650391\n",
      "Test Loss - 0.2724059522151947;\t Test AUC - 0.8932080268859863;\t Test F1 Score - 0.7454544960426418;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.976190447807312\n",
      "Test Loss - 0.25739195942878723;\t Test AUC - 0.8995585441589355;\t Test F1 Score - 0.7499999811828137;\t Test Recall - 0.6097561120986938;\t Test Precision - 0.9740259647369385\n",
      "Test Loss - 0.26387378573417664;\t Test AUC - 0.9051978588104248;\t Test F1 Score - 0.7598253560410868;\t Test Recall - 0.6170212626457214;\t Test Precision - 0.9886363744735718\n",
      "Test Loss - 0.2551107406616211;\t Test AUC - 0.8969836831092834;\t Test F1 Score - 0.7357513125161872;\t Test Recall - 0.5819672346115112;\t Test Precision - 1.0\n",
      "Test Loss - 0.3027040660381317;\t Test AUC - 0.9168469905853271;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 20\n",
      "Train Loss - 0.22460637986660004;\t Train AUC - 0.9416525959968567;\t Train F1 Score - 0.7967479586755154;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9800000190734863\n",
      "Train Loss - 0.2518353760242462;\t Train AUC - 0.8976010084152222;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.24467802047729492;\t Train AUC - 0.9216805696487427;\t Train F1 Score - 0.7545454341144099;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.21109719574451447;\t Train AUC - 0.9306301474571228;\t Train F1 Score - 0.8036530412381315;\t Train Recall - 0.6769230961799622;\t Train Precision - 0.9887640476226807\n",
      "Train Loss - 0.22055359184741974;\t Train AUC - 0.9246066808700562;\t Train F1 Score - 0.7982456478844147;\t Train Recall - 0.689393937587738;\t Train Precision - 0.9479166865348816\n",
      "Train Loss - 0.2483232319355011;\t Train AUC - 0.9271665215492249;\t Train F1 Score - 0.7971529984656878;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9491525292396545\n",
      "Train Loss - 0.29610395431518555;\t Train AUC - 0.8820516467094421;\t Train F1 Score - 0.6968325999237617;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.20842799544334412;\t Train AUC - 0.9283562898635864;\t Train F1 Score - 0.8161434268442516;\t Train Recall - 0.7054263353347778;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.21376389265060425;\t Train AUC - 0.9416739344596863;\t Train F1 Score - 0.7853881321852059;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9772727489471436\n",
      "Train Loss - 0.22509470582008362;\t Train AUC - 0.9315793514251709;\t Train F1 Score - 0.7762556986277356;\t Train Recall - 0.6538461446762085;\t Train Precision - 0.9550561904907227\n",
      "Train Loss - 0.24053055047988892;\t Train AUC - 0.9051565527915955;\t Train F1 Score - 0.8016877716916204;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.9405940771102905\n",
      "Train Loss - 0.2519401013851166;\t Train AUC - 0.9119190573692322;\t Train F1 Score - 0.7368421093053269;\t Train Recall - 0.6015625;\t Train Precision - 0.9506173133850098\n",
      "Train Loss - 0.2116219401359558;\t Train AUC - 0.9264010190963745;\t Train F1 Score - 0.7922704923477057;\t Train Recall - 0.6721311211585999;\t Train Precision - 0.9647058844566345\n",
      "Train Loss - 0.22990867495536804;\t Train AUC - 0.9157264232635498;\t Train F1 Score - 0.798283244359865;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.21556513011455536;\t Train AUC - 0.9248504638671875;\t Train F1 Score - 0.7867298286889421;\t Train Recall - 0.6639999747276306;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.27960002422332764;\t Train AUC - 0.8648902773857117;\t Train F1 Score - 0.6956521841963229;\t Train Recall - 0.5423728823661804;\t Train Precision - 0.9696969985961914\n",
      "Train Loss - 0.2080087661743164;\t Train AUC - 0.9233222007751465;\t Train F1 Score - 0.7918781992303259;\t Train Recall - 0.6724137663841248;\t Train Precision - 0.9629629850387573\n",
      "Train Loss - 0.2053530067205429;\t Train AUC - 0.9404593706130981;\t Train F1 Score - 0.7867298512552765;\t Train Recall - 0.658730149269104;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.24809592962265015;\t Train AUC - 0.9123055338859558;\t Train F1 Score - 0.7758620411789561;\t Train Recall - 0.6382978558540344;\t Train Precision - 0.9890109896659851\n",
      "Train Loss - 0.2231612205505371;\t Train AUC - 0.9351111650466919;\t Train F1 Score - 0.7592592905402812;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.8913043737411499\n",
      "Train Loss - 0.2509291470050812;\t Train AUC - 0.9109435081481934;\t Train F1 Score - 0.7851239006414408;\t Train Recall - 0.6551724076271057;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.23198847472667694;\t Train AUC - 0.9259915947914124;\t Train F1 Score - 0.7511737212686845;\t Train Recall - 0.6106870174407959;\t Train Precision - 0.9756097793579102\n",
      "Train Loss - 0.266968697309494;\t Train AUC - 0.8987306356430054;\t Train F1 Score - 0.7443946222513598;\t Train Recall - 0.6102941036224365;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.21590161323547363;\t Train AUC - 0.9218229055404663;\t Train F1 Score - 0.7817258765295763;\t Train Recall - 0.6416666507720947;\t Train Precision - 1.0\n",
      "Train Loss - 0.27187323570251465;\t Train AUC - 0.902061402797699;\t Train F1 Score - 0.7679324925626763;\t Train Recall - 0.6275861859321594;\t Train Precision - 0.989130437374115\n",
      "Train Loss - 0.21363532543182373;\t Train AUC - 0.9303783178329468;\t Train F1 Score - 0.8070175651399717;\t Train Recall - 0.6814814805984497;\t Train Precision - 0.9892473220825195\n",
      "Train Loss - 0.23420138657093048;\t Train AUC - 0.9193331003189087;\t Train F1 Score - 0.7841410160934561;\t Train Recall - 0.6449275612831116;\t Train Precision - 1.0\n",
      "Train Loss - 0.2236945629119873;\t Train AUC - 0.9086177945137024;\t Train F1 Score - 0.757894729577273;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.8999999761581421\n",
      "Train Loss - 0.2244693487882614;\t Train AUC - 0.9280424118041992;\t Train F1 Score - 0.8105726660367696;\t Train Recall - 0.7022900581359863;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.24492354691028595;\t Train AUC - 0.9331134557723999;\t Train F1 Score - 0.8127208576975656;\t Train Recall - 0.709876537322998;\t Train Precision - 0.9504132270812988\n",
      "Train Loss - 0.22622980177402496;\t Train AUC - 0.9289125204086304;\t Train F1 Score - 0.7767857680101141;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.945652186870575\n",
      "Train Loss - 0.2457951158285141;\t Train AUC - 0.8953484296798706;\t Train F1 Score - 0.763819078655186;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.9743589758872986\n",
      "Train Loss - 0.2622489929199219;\t Train AUC - 0.8756449222564697;\t Train F1 Score - 0.7422680769866321;\t Train Recall - 0.5950413346290588;\t Train Precision - 0.9863013625144958\n",
      "Train Loss - 0.2361663281917572;\t Train AUC - 0.9209622144699097;\t Train F1 Score - 0.7523809644208201;\t Train Recall - 0.6030534505844116;\t Train Precision - 1.0\n",
      "Train Loss - 0.22237177193164825;\t Train AUC - 0.9185077548027039;\t Train F1 Score - 0.7846890488858195;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.9647058844566345\n",
      "Train Loss - 0.22077268362045288;\t Train AUC - 0.9313245415687561;\t Train F1 Score - 0.7964601712174025;\t Train Recall - 0.6766917109489441;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.2596818506717682;\t Train AUC - 0.9154545068740845;\t Train F1 Score - 0.754385987055343;\t Train Recall - 0.6056337952613831;\t Train Precision - 1.0\n",
      "Train Loss - 0.245650053024292;\t Train AUC - 0.9097050428390503;\t Train F1 Score - 0.7833333209060114;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9126213788986206\n",
      "Train Loss - 0.04637308791279793;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2213970124721527;\t Test AUC - 0.9006171226501465;\t Test F1 Score - 0.8019801987348144;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.261694997549057;\t Test AUC - 0.887274980545044;\t Test F1 Score - 0.7605634023326686;\t Test Recall - 0.6230769157409668;\t Test Precision - 0.9759036302566528\n",
      "Test Loss - 0.22341004014015198;\t Test AUC - 0.9220672845840454;\t Test F1 Score - 0.7777778190348402;\t Test Recall - 0.6614173054695129;\t Test Precision - 0.9438202381134033\n",
      "Test Loss - 0.21643850207328796;\t Test AUC - 0.9130584001541138;\t Test F1 Score - 0.8037383660851182;\t Test Recall - 0.682539701461792;\t Test Precision - 0.9772727489471436\n",
      "Test Loss - 0.23117151856422424;\t Test AUC - 0.9254738092422485;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.21500732004642487;\t Test AUC - 0.9094380140304565;\t Test F1 Score - 0.7789473545025627;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.25092533230781555;\t Test AUC - 0.8828815221786499;\t Test F1 Score - 0.7526881688453515;\t Test Recall - 0.6034482717514038;\t Test Precision - 1.0\n",
      "Test Loss - 0.24980448186397552;\t Test AUC - 0.8873074650764465;\t Test F1 Score - 0.736842101255235;\t Test Recall - 0.5932203531265259;\t Test Precision - 0.9722222089767456\n",
      "Test Loss - 0.23294056951999664;\t Test AUC - 0.9177610874176025;\t Test F1 Score - 0.7999999856441822;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.24767524003982544;\t Test AUC - 0.8879685401916504;\t Test F1 Score - 0.774509817649225;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.29868897795677185;\t Test AUC - 0.8746079206466675;\t Test F1 Score - 0.7445887612603174;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9772727489471436\n",
      "Test Loss - 0.2347021996974945;\t Test AUC - 0.922127366065979;\t Test F1 Score - 0.7896995262201468;\t Test Recall - 0.6618704795837402;\t Test Precision - 0.978723406791687\n",
      "Test Loss - 0.2738611400127411;\t Test AUC - 0.8926296234130859;\t Test F1 Score - 0.7431192736528404;\t Test Recall - 0.595588207244873;\t Test Precision - 0.9878048896789551\n",
      "Test Loss - 0.25506746768951416;\t Test AUC - 0.8997033834457397;\t Test F1 Score - 0.7487684740300274;\t Test Recall - 0.6178861856460571;\t Test Precision - 0.949999988079071\n",
      "Test Loss - 0.2629302442073822;\t Test AUC - 0.9021925330162048;\t Test F1 Score - 0.7652174112281647;\t Test Recall - 0.6241135001182556;\t Test Precision - 0.9887640476226807\n",
      "Test Loss - 0.2555624842643738;\t Test AUC - 0.8942999839782715;\t Test F1 Score - 0.7244898543156821;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9594594836235046\n",
      "Test Loss - 0.31276586651802063;\t Test AUC - 0.8997114300727844;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 21\n",
      "Train Loss - 0.22093327343463898;\t Train AUC - 0.9418638348579407;\t Train F1 Score - 0.7967479586755154;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9800000190734863\n",
      "Train Loss - 0.25033092498779297;\t Train AUC - 0.898854672908783;\t Train F1 Score - 0.7373736945654068;\t Train Recall - 0.5887096524238586;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.24262507259845734;\t Train AUC - 0.9239506721496582;\t Train F1 Score - 0.7511312172810917;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.21165579557418823;\t Train AUC - 0.9300654530525208;\t Train F1 Score - 0.8073394919332767;\t Train Recall - 0.6769230961799622;\t Train Precision - 1.0\n",
      "Train Loss - 0.2169380635023117;\t Train AUC - 0.9290905594825745;\t Train F1 Score - 0.8035714696053757;\t Train Recall - 0.6818181872367859;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.24379844963550568;\t Train AUC - 0.9298830032348633;\t Train F1 Score - 0.8086642493594074;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9824561476707458\n",
      "Train Loss - 0.2937200665473938;\t Train AUC - 0.8829478025436401;\t Train F1 Score - 0.7085200976270151;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.9634146094322205\n",
      "Train Loss - 0.20918621122837067;\t Train AUC - 0.9274922013282776;\t Train F1 Score - 0.8230088570942522;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.2082993984222412;\t Train AUC - 0.9405915141105652;\t Train F1 Score - 0.7945205341125408;\t Train Recall - 0.6641221642494202;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.22037124633789062;\t Train AUC - 0.9307610988616943;\t Train F1 Score - 0.7837837777984471;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.945652186870575\n",
      "Train Loss - 0.23341010510921478;\t Train AUC - 0.9088330268859863;\t Train F1 Score - 0.8101266086978051;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.9504950642585754\n",
      "Train Loss - 0.2505652904510498;\t Train AUC - 0.908865213394165;\t Train F1 Score - 0.7307691773088223;\t Train Recall - 0.59375;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.20860286056995392;\t Train AUC - 0.9255006909370422;\t Train F1 Score - 0.811594204959276;\t Train Recall - 0.688524603843689;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.23057085275650024;\t Train AUC - 0.9158611297607422;\t Train F1 Score - 0.7931034658771513;\t Train Recall - 0.6764705777168274;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.21484583616256714;\t Train AUC - 0.9255073070526123;\t Train F1 Score - 0.7962085417710844;\t Train Recall - 0.671999990940094;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.27965885400772095;\t Train AUC - 0.8607233166694641;\t Train F1 Score - 0.7027026942296469;\t Train Recall - 0.5508474707603455;\t Train Precision - 0.9701492786407471\n",
      "Train Loss - 0.20391367375850677;\t Train AUC - 0.9276414513587952;\t Train F1 Score - 0.7979797804059968;\t Train Recall - 0.681034505367279;\t Train Precision - 0.9634146094322205\n",
      "Train Loss - 0.20100514590740204;\t Train AUC - 0.9424352645874023;\t Train F1 Score - 0.7924528123964071;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.24548955261707306;\t Train AUC - 0.9163614511489868;\t Train F1 Score - 0.782978752947427;\t Train Recall - 0.652482271194458;\t Train Precision - 0.978723406791687\n",
      "Train Loss - 0.20097364485263824;\t Train AUC - 0.9358057975769043;\t Train F1 Score - 0.7962085339006066;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.2552933990955353;\t Train AUC - 0.9063432812690735;\t Train F1 Score - 0.7851239006414408;\t Train Recall - 0.6551724076271057;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.22193168103694916;\t Train AUC - 0.929922342300415;\t Train F1 Score - 0.7671232641345284;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.25154659152030945;\t Train AUC - 0.908428966999054;\t Train F1 Score - 0.7610619156775404;\t Train Recall - 0.6323529481887817;\t Train Precision - 0.9555555582046509\n",
      "Train Loss - 0.194257915019989;\t Train AUC - 0.9379253387451172;\t Train F1 Score - 0.8137254748892616;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.24995318055152893;\t Train AUC - 0.9113301038742065;\t Train F1 Score - 0.7901234666514272;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.20648135244846344;\t Train AUC - 0.9310076236724854;\t Train F1 Score - 0.8173912883600787;\t Train Recall - 0.6962962746620178;\t Train Precision - 0.9894737005233765\n",
      "Train Loss - 0.22991111874580383;\t Train AUC - 0.9236385822296143;\t Train F1 Score - 0.7807017006232413;\t Train Recall - 0.6449275612831116;\t Train Precision - 0.9888888597488403\n",
      "Train Loss - 0.2206023633480072;\t Train AUC - 0.9097866415977478;\t Train F1 Score - 0.7553191513817092;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9102563858032227\n",
      "Train Loss - 0.22678187489509583;\t Train AUC - 0.9216621518135071;\t Train F1 Score - 0.8088888598924813;\t Train Recall - 0.694656491279602;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.2320163995027542;\t Train AUC - 0.9361505508422852;\t Train F1 Score - 0.8142856928683763;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9661017060279846\n",
      "Train Loss - 0.22104935348033905;\t Train AUC - 0.9299323558807373;\t Train F1 Score - 0.7927928319777304;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.24223899841308594;\t Train AUC - 0.8980658650398254;\t Train F1 Score - 0.7661691111999189;\t Train Recall - 0.6363636255264282;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.2553730607032776;\t Train AUC - 0.8778619170188904;\t Train F1 Score - 0.7551020240720825;\t Train Recall - 0.6115702390670776;\t Train Precision - 0.9866666793823242\n",
      "Train Loss - 0.22025835514068604;\t Train AUC - 0.9255033731460571;\t Train F1 Score - 0.7926267194880579;\t Train Recall - 0.6564885377883911;\t Train Precision - 1.0\n",
      "Train Loss - 0.21724380552768707;\t Train AUC - 0.9230059385299683;\t Train F1 Score - 0.7809523373611169;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.9534883499145508\n",
      "Train Loss - 0.2194453477859497;\t Train AUC - 0.929714560508728;\t Train F1 Score - 0.7929515351016052;\t Train Recall - 0.6766917109489441;\t Train Precision - 0.957446813583374\n",
      "Train Loss - 0.26104000210762024;\t Train AUC - 0.9112952947616577;\t Train F1 Score - 0.7565217689083319;\t Train Recall - 0.6126760840415955;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.24069832265377045;\t Train AUC - 0.913047194480896;\t Train F1 Score - 0.7899159663865546;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9306930899620056\n",
      "Train Loss - 0.04615813493728638;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22845149040222168;\t Test AUC - 0.894173264503479;\t Test F1 Score - 0.7960198939953087;\t Test Recall - 0.6779661178588867;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.265380322933197;\t Test AUC - 0.8828723430633545;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.2241351306438446;\t Test AUC - 0.920535683631897;\t Test F1 Score - 0.7793427012218024;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9651162624359131\n",
      "Test Loss - 0.21603742241859436;\t Test AUC - 0.9140127897262573;\t Test F1 Score - 0.8093022886838513;\t Test Recall - 0.6904761791229248;\t Test Precision - 0.9775280952453613\n",
      "Test Loss - 0.23000025749206543;\t Test AUC - 0.9261519312858582;\t Test F1 Score - 0.771428541758705;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.21387633681297302;\t Test AUC - 0.9091130495071411;\t Test F1 Score - 0.7789473545025627;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.24841642379760742;\t Test AUC - 0.8868801593780518;\t Test F1 Score - 0.7459459229156526;\t Test Recall - 0.5948275923728943;\t Test Precision - 1.0\n",
      "Test Loss - 0.25298935174942017;\t Test AUC - 0.8894964456558228;\t Test F1 Score - 0.7340425144303457;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9857142567634583\n",
      "Test Loss - 0.23255790770053864;\t Test AUC - 0.9179975390434265;\t Test F1 Score - 0.7947598681473532;\t Test Recall - 0.6642335653305054;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.24757547676563263;\t Test AUC - 0.8882412910461426;\t Test F1 Score - 0.774509817649225;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.29590660333633423;\t Test AUC - 0.8751587271690369;\t Test F1 Score - 0.7510916920044322;\t Test Recall - 0.6013985872268677;\t Test Precision - 1.0\n",
      "Test Loss - 0.23897552490234375;\t Test AUC - 0.9207072854042053;\t Test F1 Score - 0.784482807701881;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.9784946441650391\n",
      "Test Loss - 0.27567383646965027;\t Test AUC - 0.8906725645065308;\t Test F1 Score - 0.7431192736528404;\t Test Recall - 0.595588207244873;\t Test Precision - 0.9878048896789551\n",
      "Test Loss - 0.2491765320301056;\t Test AUC - 0.8994051218032837;\t Test F1 Score - 0.7599999851443265;\t Test Recall - 0.6178861856460571;\t Test Precision - 0.9870129823684692\n",
      "Test Loss - 0.26209965348243713;\t Test AUC - 0.9017676115036011;\t Test F1 Score - 0.7705627336126593;\t Test Recall - 0.631205677986145;\t Test Precision - 0.9888888597488403\n",
      "Test Loss - 0.2556644678115845;\t Test AUC - 0.8941199779510498;\t Test F1 Score - 0.7319588255855978;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.3095869719982147;\t Test AUC - 0.9012446403503418;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 22\n",
      "Train Loss - 0.2216140776872635;\t Train AUC - 0.9385673403739929;\t Train F1 Score - 0.8016194340715057;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9801980257034302\n",
      "Train Loss - 0.24991925060749054;\t Train AUC - 0.9010741114616394;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.2441401183605194;\t Train AUC - 0.9226284027099609;\t Train F1 Score - 0.7511312172810917;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.2098720818758011;\t Train AUC - 0.9311866164207458;\t Train F1 Score - 0.8073394919332767;\t Train Recall - 0.6769230961799622;\t Train Precision - 1.0\n",
      "Train Loss - 0.21299415826797485;\t Train AUC - 0.9320124387741089;\t Train F1 Score - 0.7999999710930714;\t Train Recall - 0.6818181872367859;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.2451840192079544;\t Train AUC - 0.9271314144134521;\t Train F1 Score - 0.8057554023955975;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9739130139350891\n",
      "Train Loss - 0.2916608154773712;\t Train AUC - 0.8850337862968445;\t Train F1 Score - 0.7117116648534695;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.2021941989660263;\t Train AUC - 0.9311542510986328;\t Train F1 Score - 0.8281938251319229;\t Train Recall - 0.7286821603775024;\t Train Precision - 0.9591836929321289\n",
      "Train Loss - 0.2098976969718933;\t Train AUC - 0.9410797357559204;\t Train F1 Score - 0.790909117314736;\t Train Recall - 0.6641221642494202;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.2182561457157135;\t Train AUC - 0.9347790479660034;\t Train F1 Score - 0.7853881365480911;\t Train Recall - 0.6615384817123413;\t Train Precision - 0.966292142868042\n",
      "Train Loss - 0.23631376028060913;\t Train AUC - 0.9098314046859741;\t Train F1 Score - 0.8000000146362515;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.9230769276618958\n",
      "Train Loss - 0.2474634349346161;\t Train AUC - 0.9122501015663147;\t Train F1 Score - 0.7393364626206937;\t Train Recall - 0.609375;\t Train Precision - 0.9397590160369873\n",
      "Train Loss - 0.20800849795341492;\t Train AUC - 0.9286216497421265;\t Train F1 Score - 0.811594204959276;\t Train Recall - 0.688524603843689;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.2343556433916092;\t Train AUC - 0.9122875928878784;\t Train F1 Score - 0.801724140418467;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.96875\n",
      "Train Loss - 0.21248698234558105;\t Train AUC - 0.9280252456665039;\t Train F1 Score - 0.7867298286889421;\t Train Recall - 0.6639999747276306;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.2744797170162201;\t Train AUC - 0.8669122457504272;\t Train F1 Score - 0.7096774319224411;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.970588207244873\n",
      "Train Loss - 0.19983860850334167;\t Train AUC - 0.9278907775878906;\t Train F1 Score - 0.8040201715103227;\t Train Recall - 0.6896551847457886;\t Train Precision - 0.9638554453849792\n",
      "Train Loss - 0.20093396306037903;\t Train AUC - 0.9430630207061768;\t Train F1 Score - 0.7904761725517084;\t Train Recall - 0.658730149269104;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.2483622431755066;\t Train AUC - 0.91456139087677;\t Train F1 Score - 0.7777778104044213;\t Train Recall - 0.6453900933265686;\t Train Precision - 0.9784946441650391\n",
      "Train Loss - 0.1991632878780365;\t Train AUC - 0.935975193977356;\t Train F1 Score - 0.8056872418529097;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.254384309053421;\t Train AUC - 0.9092459678649902;\t Train F1 Score - 0.7818930101546853;\t Train Recall - 0.6551724076271057;\t Train Precision - 0.9693877696990967\n",
      "Train Loss - 0.22322042286396027;\t Train AUC - 0.9287098050117493;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2493136078119278;\t Train AUC - 0.9101483821868896;\t Train F1 Score - 0.7733333716634889;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.19358603656291962;\t Train AUC - 0.9369444847106934;\t Train F1 Score - 0.8137254748892616;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.24756108224391937;\t Train AUC - 0.9129745960235596;\t Train F1 Score - 0.7983538991138868;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9897959232330322\n",
      "Train Loss - 0.20164664089679718;\t Train AUC - 0.9349900484085083;\t Train F1 Score - 0.8311688718837608;\t Train Recall - 0.7111111283302307;\t Train Precision - 1.0\n",
      "Train Loss - 0.2271386682987213;\t Train AUC - 0.9252697229385376;\t Train F1 Score - 0.7913043314773847;\t Train Recall - 0.6594203114509583;\t Train Precision - 0.989130437374115\n",
      "Train Loss - 0.22112345695495605;\t Train AUC - 0.9101669788360596;\t Train F1 Score - 0.7539266591108887;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.8888888955116272\n",
      "Train Loss - 0.22188420593738556;\t Train AUC - 0.9267159104347229;\t Train F1 Score - 0.8125000133590692;\t Train Recall - 0.694656491279602;\t Train Precision - 0.9784946441650391\n",
      "Train Loss - 0.2342372089624405;\t Train AUC - 0.9370877742767334;\t Train F1 Score - 0.8142856928683763;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9661017060279846\n",
      "Train Loss - 0.22087812423706055;\t Train AUC - 0.9302884340286255;\t Train F1 Score - 0.787330296637268;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.24018312990665436;\t Train AUC - 0.9012923240661621;\t Train F1 Score - 0.7722771917470768;\t Train Recall - 0.64462810754776;\t Train Precision - 0.9629629850387573\n",
      "Train Loss - 0.252907931804657;\t Train AUC - 0.8799668550491333;\t Train F1 Score - 0.7551020240720825;\t Train Recall - 0.6115702390670776;\t Train Precision - 0.9866666793823242\n",
      "Train Loss - 0.21757104992866516;\t Train AUC - 0.9254789352416992;\t Train F1 Score - 0.7926267194880579;\t Train Recall - 0.6564885377883911;\t Train Precision - 1.0\n",
      "Train Loss - 0.21901138126850128;\t Train AUC - 0.9188973903656006;\t Train F1 Score - 0.7904761876977344;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.22051559388637543;\t Train AUC - 0.9283540844917297;\t Train F1 Score - 0.7929515351016052;\t Train Recall - 0.6766917109489441;\t Train Precision - 0.957446813583374\n",
      "Train Loss - 0.2583717107772827;\t Train AUC - 0.9132941961288452;\t Train F1 Score - 0.7598253207322118;\t Train Recall - 0.6126760840415955;\t Train Precision - 1.0\n",
      "Train Loss - 0.2407725304365158;\t Train AUC - 0.9117150902748108;\t Train F1 Score - 0.7899159663865546;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9306930899620056\n",
      "Train Loss - 0.04452727362513542;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22400608658790588;\t Test AUC - 0.8991754055023193;\t Test F1 Score - 0.7899999342960663;\t Test Recall - 0.6694915294647217;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.2608443796634674;\t Test AUC - 0.8884533643722534;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.22541366517543793;\t Test AUC - 0.9238900542259216;\t Test F1 Score - 0.773584874932692;\t Test Recall - 0.6456692814826965;\t Test Precision - 0.9647058844566345\n",
      "Test Loss - 0.21568776667118073;\t Test AUC - 0.9125561118125916;\t Test F1 Score - 0.8055554796224362;\t Test Recall - 0.6904761791229248;\t Test Precision - 0.9666666388511658\n",
      "Test Loss - 0.22916178405284882;\t Test AUC - 0.926059901714325;\t Test F1 Score - 0.775119576703991;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9759036302566528\n",
      "Test Loss - 0.2160545140504837;\t Test AUC - 0.9102050065994263;\t Test F1 Score - 0.7772020271919031;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.949367105960846\n",
      "Test Loss - 0.24229207634925842;\t Test AUC - 0.8959639072418213;\t Test F1 Score - 0.741935503334981;\t Test Recall - 0.5948275923728943;\t Test Precision - 0.9857142567634583\n",
      "Test Loss - 0.25534775853157043;\t Test AUC - 0.8859624266624451;\t Test F1 Score - 0.7301587009837709;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9718309640884399\n",
      "Test Loss - 0.23436416685581207;\t Test AUC - 0.9175955057144165;\t Test F1 Score - 0.7947598681473532;\t Test Recall - 0.6642335653305054;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.2484876960515976;\t Test AUC - 0.8871504068374634;\t Test F1 Score - 0.774509817649225;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.30015474557876587;\t Test AUC - 0.8751893639564514;\t Test F1 Score - 0.7381974350795572;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9555555582046509\n",
      "Test Loss - 0.23572345077991486;\t Test AUC - 0.925006628036499;\t Test F1 Score - 0.7826087431593679;\t Test Recall - 0.6474820375442505;\t Test Precision - 0.9890109896659851\n",
      "Test Loss - 0.2757856547832489;\t Test AUC - 0.8892384171485901;\t Test F1 Score - 0.7488583687925513;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.9879518151283264\n",
      "Test Loss - 0.24699491262435913;\t Test AUC - 0.899456262588501;\t Test F1 Score - 0.7722771927833114;\t Test Recall - 0.6341463327407837;\t Test Precision - 0.9873417615890503\n",
      "Test Loss - 0.2587313950061798;\t Test AUC - 0.9068742990493774;\t Test F1 Score - 0.7652174112281647;\t Test Recall - 0.6241135001182556;\t Test Precision - 0.9887640476226807\n",
      "Test Loss - 0.25707635283470154;\t Test AUC - 0.8938627243041992;\t Test F1 Score - 0.7319588255855978;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.3096650540828705;\t Test AUC - 0.9044913649559021;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 23\n",
      "Train Loss - 0.22122721374034882;\t Train AUC - 0.9401589632034302;\t Train F1 Score - 0.8016194340715057;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9801980257034302\n",
      "Train Loss - 0.24942556023597717;\t Train AUC - 0.9028191566467285;\t Train F1 Score - 0.7474747685896667;\t Train Recall - 0.5967742204666138;\t Train Precision - 1.0\n",
      "Train Loss - 0.24234817922115326;\t Train AUC - 0.9237595200538635;\t Train F1 Score - 0.7511312172810917;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.20857074856758118;\t Train AUC - 0.9343535304069519;\t Train F1 Score - 0.8018433393641516;\t Train Recall - 0.6692307591438293;\t Train Precision - 1.0\n",
      "Train Loss - 0.21500159800052643;\t Train AUC - 0.9280303120613098;\t Train F1 Score - 0.8053097459698839;\t Train Recall - 0.689393937587738;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.24347509443759918;\t Train AUC - 0.9309921264648438;\t Train F1 Score - 0.7985611599356318;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.9652174115180969\n",
      "Train Loss - 0.29195258021354675;\t Train AUC - 0.8860613107681274;\t Train F1 Score - 0.7053571104775038;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.9518072009086609\n",
      "Train Loss - 0.2002604752779007;\t Train AUC - 0.9319360256195068;\t Train F1 Score - 0.83035716414605;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.20626015961170197;\t Train AUC - 0.9442373514175415;\t Train F1 Score - 0.790909117314736;\t Train Recall - 0.6641221642494202;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.22125959396362305;\t Train AUC - 0.9320458769798279;\t Train F1 Score - 0.7909090948838664;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.2337804138660431;\t Train AUC - 0.9115666151046753;\t Train F1 Score - 0.8033473220542917;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.9320388436317444\n",
      "Train Loss - 0.24558131396770477;\t Train AUC - 0.9127880334854126;\t Train F1 Score - 0.7358489849417459;\t Train Recall - 0.609375;\t Train Precision - 0.9285714030265808\n",
      "Train Loss - 0.20642942190170288;\t Train AUC - 0.9293504357337952;\t Train F1 Score - 0.8095238641517832;\t Train Recall - 0.6967213153839111;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.23643943667411804;\t Train AUC - 0.9106712937355042;\t Train F1 Score - 0.8085106551241308;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.9595959782600403\n",
      "Train Loss - 0.21215087175369263;\t Train AUC - 0.9312673807144165;\t Train F1 Score - 0.7906976590590268;\t Train Recall - 0.6800000071525574;\t Train Precision - 0.9444444179534912\n",
      "Train Loss - 0.2736820578575134;\t Train AUC - 0.8679407835006714;\t Train F1 Score - 0.7165775405212216;\t Train Recall - 0.5677965879440308;\t Train Precision - 0.9710144996643066\n",
      "Train Loss - 0.200778990983963;\t Train AUC - 0.9288080334663391;\t Train F1 Score - 0.8040201715103227;\t Train Recall - 0.6896551847457886;\t Train Precision - 0.9638554453849792\n",
      "Train Loss - 0.19604232907295227;\t Train AUC - 0.9441765546798706;\t Train F1 Score - 0.794392503669991;\t Train Recall - 0.6746031641960144;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.24927663803100586;\t Train AUC - 0.9138429164886475;\t Train F1 Score - 0.7705627336126593;\t Train Recall - 0.631205677986145;\t Train Precision - 0.9888888597488403\n",
      "Train Loss - 0.1977314054965973;\t Train AUC - 0.9366952180862427;\t Train F1 Score - 0.8095237756103022;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.2524929642677307;\t Train AUC - 0.9116331934928894;\t Train F1 Score - 0.7901234666514272;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.2230483442544937;\t Train AUC - 0.930068850517273;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2492322474718094;\t Train AUC - 0.9108614325523376;\t Train F1 Score - 0.7713004609631656;\t Train Recall - 0.6323529481887817;\t Train Precision - 0.9885057210922241\n",
      "Train Loss - 0.19385579228401184;\t Train AUC - 0.9388194680213928;\t Train F1 Score - 0.8177340161829612;\t Train Recall - 0.6916666626930237;\t Train Precision - 1.0\n",
      "Train Loss - 0.24673426151275635;\t Train AUC - 0.9143159985542297;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.20096418261528015;\t Train AUC - 0.9354041814804077;\t Train F1 Score - 0.8311688718837608;\t Train Recall - 0.7111111283302307;\t Train Precision - 1.0\n",
      "Train Loss - 0.22853200137615204;\t Train AUC - 0.9242973327636719;\t Train F1 Score - 0.794759869559589;\t Train Recall - 0.6594203114509583;\t Train Precision - 1.0\n",
      "Train Loss - 0.21965062618255615;\t Train AUC - 0.9111502766609192;\t Train F1 Score - 0.7513226831101855;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.8987341523170471\n",
      "Train Loss - 0.2209957391023636;\t Train AUC - 0.9273263216018677;\t Train F1 Score - 0.8125000133590692;\t Train Recall - 0.694656491279602;\t Train Precision - 0.9784946441650391\n",
      "Train Loss - 0.23459696769714355;\t Train AUC - 0.9356642961502075;\t Train F1 Score - 0.8127208576975656;\t Train Recall - 0.709876537322998;\t Train Precision - 0.9504132270812988\n",
      "Train Loss - 0.2192445695400238;\t Train AUC - 0.931640088558197;\t Train F1 Score - 0.7892376835405335;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.24094516038894653;\t Train AUC - 0.900179386138916;\t Train F1 Score - 0.782178246817952;\t Train Recall - 0.6528925895690918;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.25388139486312866;\t Train AUC - 0.8790265321731567;\t Train F1 Score - 0.7551020240720825;\t Train Recall - 0.6115702390670776;\t Train Precision - 0.9866666793823242\n",
      "Train Loss - 0.21745026111602783;\t Train AUC - 0.924445390701294;\t Train F1 Score - 0.7981651855903736;\t Train Recall - 0.6641221642494202;\t Train Precision - 1.0\n",
      "Train Loss - 0.21929830312728882;\t Train AUC - 0.9171947240829468;\t Train F1 Score - 0.7904761876977344;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.2192089855670929;\t Train AUC - 0.9289417266845703;\t Train F1 Score - 0.7929515351016052;\t Train Recall - 0.6766917109489441;\t Train Precision - 0.957446813583374\n",
      "Train Loss - 0.2548959255218506;\t Train AUC - 0.9149162769317627;\t Train F1 Score - 0.7598253207322118;\t Train Recall - 0.6126760840415955;\t Train Precision - 1.0\n",
      "Train Loss - 0.2413959801197052;\t Train AUC - 0.9092951416969299;\t Train F1 Score - 0.7899159663865546;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9306930899620056\n",
      "Train Loss - 0.04272269457578659;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2283482849597931;\t Test AUC - 0.8965380191802979;\t Test F1 Score - 0.7920792709044567;\t Test Recall - 0.6779661178588867;\t Test Precision - 0.9523809552192688\n",
      "Test Loss - 0.25951844453811646;\t Test AUC - 0.8896480798721313;\t Test F1 Score - 0.7523809651918706;\t Test Recall - 0.607692301273346;\t Test Precision - 0.987500011920929\n",
      "Test Loss - 0.22716166079044342;\t Test AUC - 0.919262170791626;\t Test F1 Score - 0.773584874932692;\t Test Recall - 0.6456692814826965;\t Test Precision - 0.9647058844566345\n",
      "Test Loss - 0.21692563593387604;\t Test AUC - 0.9095087647438049;\t Test F1 Score - 0.8075117645527151;\t Test Recall - 0.682539701461792;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.23003347218036652;\t Test AUC - 0.9220163822174072;\t Test F1 Score - 0.7788461482227043;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9878048896789551\n",
      "Test Loss - 0.2149876356124878;\t Test AUC - 0.9120460748672485;\t Test F1 Score - 0.7812499861977992;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.9615384340286255\n",
      "Test Loss - 0.2363240271806717;\t Test AUC - 0.89778071641922;\t Test F1 Score - 0.7659574280285951;\t Test Recall - 0.6206896305084229;\t Test Precision - 1.0\n",
      "Test Loss - 0.25496456027030945;\t Test AUC - 0.8828415870666504;\t Test F1 Score - 0.7301587009837709;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9718309640884399\n",
      "Test Loss - 0.2313525378704071;\t Test AUC - 0.9201652407646179;\t Test F1 Score - 0.7999999856441822;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.24613402783870697;\t Test AUC - 0.8893746137619019;\t Test F1 Score - 0.774509817649225;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.2951914370059967;\t Test AUC - 0.8785175085067749;\t Test F1 Score - 0.7445887612603174;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9772727489471436\n",
      "Test Loss - 0.23424598574638367;\t Test AUC - 0.9256776571273804;\t Test F1 Score - 0.7792207935050727;\t Test Recall - 0.6474820375442505;\t Test Precision - 0.97826087474823\n",
      "Test Loss - 0.2744187116622925;\t Test AUC - 0.8869723081588745;\t Test F1 Score - 0.7488583687925513;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.9879518151283264\n",
      "Test Loss - 0.254011332988739;\t Test AUC - 0.8984591960906982;\t Test F1 Score - 0.7562189669320013;\t Test Recall - 0.6178861856460571;\t Test Precision - 0.9743589758872986\n",
      "Test Loss - 0.26182934641838074;\t Test AUC - 0.9010568857192993;\t Test F1 Score - 0.7652174112281647;\t Test Recall - 0.6241135001182556;\t Test Precision - 0.9887640476226807\n",
      "Test Loss - 0.2628943622112274;\t Test AUC - 0.8847057819366455;\t Test F1 Score - 0.7319588255855978;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.30988016724586487;\t Test AUC - 0.9047619700431824;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 24\n",
      "Train Loss - 0.21888142824172974;\t Train AUC - 0.9419618844985962;\t Train F1 Score - 0.7967479586755154;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9800000190734863\n",
      "Train Loss - 0.24675728380680084;\t Train AUC - 0.9058856964111328;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.24190950393676758;\t Train AUC - 0.923647940158844;\t Train F1 Score - 0.7545454341144099;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.21059298515319824;\t Train AUC - 0.9328314065933228;\t Train F1 Score - 0.7962963109112896;\t Train Recall - 0.6615384817123413;\t Train Precision - 1.0\n",
      "Train Loss - 0.21846038103103638;\t Train AUC - 0.9260150194168091;\t Train F1 Score - 0.7982063459699493;\t Train Recall - 0.6742424368858337;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.24351878464221954;\t Train AUC - 0.9319046139717102;\t Train F1 Score - 0.7985611599356318;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.9652174115180969\n",
      "Train Loss - 0.2925925552845001;\t Train AUC - 0.8848869800567627;\t Train F1 Score - 0.7085200976270151;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.9634146094322205\n",
      "Train Loss - 0.20133137702941895;\t Train AUC - 0.9304711818695068;\t Train F1 Score - 0.83035716414605;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.2082151472568512;\t Train AUC - 0.943203866481781;\t Train F1 Score - 0.7889907771545216;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9885057210922241\n",
      "Train Loss - 0.22119785845279694;\t Train AUC - 0.9332814812660217;\t Train F1 Score - 0.7798164664972755;\t Train Recall - 0.6538461446762085;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.2333528697490692;\t Train AUC - 0.9119706749916077;\t Train F1 Score - 0.8050847549549793;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.24385584890842438;\t Train AUC - 0.915932834148407;\t Train F1 Score - 0.7368421093053269;\t Train Recall - 0.6015625;\t Train Precision - 0.9506173133850098\n",
      "Train Loss - 0.2088070660829544;\t Train AUC - 0.9274126887321472;\t Train F1 Score - 0.8133971325944311;\t Train Recall - 0.6967213153839111;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.23373748362064362;\t Train AUC - 0.9129928350448608;\t Train F1 Score - 0.8034188120619834;\t Train Recall - 0.6911764740943909;\t Train Precision - 0.9591836929321289\n",
      "Train Loss - 0.2070726454257965;\t Train AUC - 0.9343158006668091;\t Train F1 Score - 0.7962962854818193;\t Train Recall - 0.6880000233650208;\t Train Precision - 0.9450549483299255\n",
      "Train Loss - 0.2709008753299713;\t Train AUC - 0.8717121481895447;\t Train F1 Score - 0.7127659616049538;\t Train Recall - 0.5677965879440308;\t Train Precision - 0.9571428298950195\n",
      "Train Loss - 0.2053028643131256;\t Train AUC - 0.9254862666130066;\t Train F1 Score - 0.7999999709606184;\t Train Recall - 0.6896551847457886;\t Train Precision - 0.9523809552192688\n",
      "Train Loss - 0.1939522624015808;\t Train AUC - 0.9468303918838501;\t Train F1 Score - 0.7981650787914467;\t Train Recall - 0.6904761791229248;\t Train Precision - 0.945652186870575\n",
      "Train Loss - 0.24858184158802032;\t Train AUC - 0.9133639335632324;\t Train F1 Score - 0.7744680734736525;\t Train Recall - 0.6453900933265686;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.19697120785713196;\t Train AUC - 0.9373136758804321;\t Train F1 Score - 0.8037383528872927;\t Train Recall - 0.6935483813285828;\t Train Precision - 0.9555555582046509\n",
      "Train Loss - 0.2540263235569;\t Train AUC - 0.910632848739624;\t Train F1 Score - 0.7901234666514272;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.2265610694885254;\t Train AUC - 0.9273995161056519;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.25109127163887024;\t Train AUC - 0.9098789095878601;\t Train F1 Score - 0.7767857227831861;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.19332042336463928;\t Train AUC - 0.9389410018920898;\t Train F1 Score - 0.8118811621758051;\t Train Recall - 0.6833333373069763;\t Train Precision - 1.0\n",
      "Train Loss - 0.25615108013153076;\t Train AUC - 0.9078893065452576;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.20169255137443542;\t Train AUC - 0.9343687891960144;\t Train F1 Score - 0.8260869839015675;\t Train Recall - 0.7037037014961243;\t Train Precision - 1.0\n",
      "Train Loss - 0.22842107713222504;\t Train AUC - 0.9254501461982727;\t Train F1 Score - 0.7894736728179493;\t Train Recall - 0.6521739363670349;\t Train Precision - 1.0\n",
      "Train Loss - 0.21755045652389526;\t Train AUC - 0.9121428728103638;\t Train F1 Score - 0.7593582680294142;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9220778942108154\n",
      "Train Loss - 0.22576169669628143;\t Train AUC - 0.9208157658576965;\t Train F1 Score - 0.8018017784747788;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.23306572437286377;\t Train AUC - 0.936467707157135;\t Train F1 Score - 0.810035826367573;\t Train Recall - 0.6975308656692505;\t Train Precision - 0.9658119678497314\n",
      "Train Loss - 0.22221456468105316;\t Train AUC - 0.931057333946228;\t Train F1 Score - 0.7818181498811814;\t Train Recall - 0.6515151262283325;\t Train Precision - 0.9772727489471436\n",
      "Train Loss - 0.24071332812309265;\t Train AUC - 0.8984972238540649;\t Train F1 Score - 0.7920791871613462;\t Train Recall - 0.6611570119857788;\t Train Precision - 0.9876543283462524\n",
      "Train Loss - 0.2561861276626587;\t Train AUC - 0.8774823546409607;\t Train F1 Score - 0.7575757621086542;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9740259647369385\n",
      "Train Loss - 0.218750461935997;\t Train AUC - 0.9237943291664124;\t Train F1 Score - 0.7945205341125408;\t Train Recall - 0.6641221642494202;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.21969330310821533;\t Train AUC - 0.9189397692680359;\t Train F1 Score - 0.7867298727848975;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.954023003578186\n",
      "Train Loss - 0.2185337096452713;\t Train AUC - 0.9296984076499939;\t Train F1 Score - 0.7894736958003183;\t Train Recall - 0.6766917109489441;\t Train Precision - 0.9473684430122375\n",
      "Train Loss - 0.25192347168922424;\t Train AUC - 0.9172919988632202;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.23854652047157288;\t Train AUC - 0.9110372066497803;\t Train F1 Score - 0.7983193203743465;\t Train Recall - 0.6934306621551514;\t Train Precision - 0.9405940771102905\n",
      "Train Loss - 0.04756709188222885;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2288849949836731;\t Test AUC - 0.8959929943084717;\t Test F1 Score - 0.7980295709785218;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9529411792755127\n",
      "Test Loss - 0.2614946961402893;\t Test AUC - 0.88897705078125;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.22555485367774963;\t Test AUC - 0.9199613332748413;\t Test F1 Score - 0.7777778190348402;\t Test Recall - 0.6614173054695129;\t Test Precision - 0.9438202381134033\n",
      "Test Loss - 0.21656885743141174;\t Test AUC - 0.9096007943153381;\t Test F1 Score - 0.8093022886838513;\t Test Recall - 0.6904761791229248;\t Test Precision - 0.9775280952453613\n",
      "Test Loss - 0.23453064262866974;\t Test AUC - 0.9188433289527893;\t Test F1 Score - 0.7655502670617305;\t Test Recall - 0.6349206566810608;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.21997390687465668;\t Test AUC - 0.9057378768920898;\t Test F1 Score - 0.7812499861977992;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.9615384340286255\n",
      "Test Loss - 0.23737680912017822;\t Test AUC - 0.8976471424102783;\t Test F1 Score - 0.7619047124503112;\t Test Recall - 0.6206896305084229;\t Test Precision - 0.9863013625144958\n",
      "Test Loss - 0.25494492053985596;\t Test AUC - 0.8899447917938232;\t Test F1 Score - 0.7340425144303457;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9857142567634583\n",
      "Test Loss - 0.22942478954792023;\t Test AUC - 0.9225457906723022;\t Test F1 Score - 0.7931034758481725;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9684210419654846\n",
      "Test Loss - 0.24949930608272552;\t Test AUC - 0.8885735273361206;\t Test F1 Score - 0.7722771927833114;\t Test Recall - 0.6341463327407837;\t Test Precision - 0.9873417615890503\n",
      "Test Loss - 0.30906274914741516;\t Test AUC - 0.8741182088851929;\t Test F1 Score - 0.7381974350795572;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9555555582046509\n",
      "Test Loss - 0.23214340209960938;\t Test AUC - 0.9270588159561157;\t Test F1 Score - 0.7878788186449589;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.27705636620521545;\t Test AUC - 0.8889056444168091;\t Test F1 Score - 0.7454544960426418;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.976190447807312\n",
      "Test Loss - 0.24923431873321533;\t Test AUC - 0.9006067514419556;\t Test F1 Score - 0.7549019674557857;\t Test Recall - 0.6260162591934204;\t Test Precision - 0.9506173133850098\n",
      "Test Loss - 0.2588094472885132;\t Test AUC - 0.901752233505249;\t Test F1 Score - 0.7863247763949385;\t Test Recall - 0.652482271194458;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.26455846428871155;\t Test AUC - 0.8843627572059631;\t Test F1 Score - 0.7319588255855978;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.3075316846370697;\t Test AUC - 0.9103534817695618;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 25\n",
      "Train Loss - 0.2128080427646637;\t Train AUC - 0.9459297060966492;\t Train F1 Score - 0.803212794445922;\t Train Recall - 0.6849315166473389;\t Train Precision - 0.9708737730979919\n",
      "Train Loss - 0.2514082193374634;\t Train AUC - 0.9028022289276123;\t Train F1 Score - 0.7336683566649974;\t Train Recall - 0.5887096524238586;\t Train Precision - 0.9733333587646484\n",
      "Train Loss - 0.24635785818099976;\t Train AUC - 0.9216088652610779;\t Train F1 Score - 0.7545454341144099;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2127961814403534;\t Train AUC - 0.9306710362434387;\t Train F1 Score - 0.7962963109112896;\t Train Recall - 0.6615384817123413;\t Train Precision - 1.0\n",
      "Train Loss - 0.21619969606399536;\t Train AUC - 0.9280465245246887;\t Train F1 Score - 0.7927928319777304;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.24754445254802704;\t Train AUC - 0.9290196895599365;\t Train F1 Score - 0.8043478416676318;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.982300877571106\n",
      "Train Loss - 0.29767876863479614;\t Train AUC - 0.8806919455528259;\t Train F1 Score - 0.7149321266968326;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.987500011920929\n",
      "Train Loss - 0.1990247666835785;\t Train AUC - 0.9293684959411621;\t Train F1 Score - 0.8340807618724737;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9893617033958435\n",
      "Train Loss - 0.2114933431148529;\t Train AUC - 0.9413076639175415;\t Train F1 Score - 0.7777777290051637;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.22228431701660156;\t Train AUC - 0.9341325759887695;\t Train F1 Score - 0.7741935698611735;\t Train Recall - 0.6461538672447205;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.23950231075286865;\t Train AUC - 0.9091182947158813;\t Train F1 Score - 0.8050847549549793;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.245287224650383;\t Train AUC - 0.9140955805778503;\t Train F1 Score - 0.7368421093053269;\t Train Recall - 0.6015625;\t Train Precision - 0.9506173133850098\n",
      "Train Loss - 0.20840919017791748;\t Train AUC - 0.9280214309692383;\t Train F1 Score - 0.8095238641517832;\t Train Recall - 0.6967213153839111;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.2330356389284134;\t Train AUC - 0.9131750464439392;\t Train F1 Score - 0.7931034658771513;\t Train Recall - 0.6764705777168274;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.2115599811077118;\t Train AUC - 0.9296252727508545;\t Train F1 Score - 0.7850467468989224;\t Train Recall - 0.671999990940094;\t Train Precision - 0.9438202381134033\n",
      "Train Loss - 0.2655526101589203;\t Train AUC - 0.8789120316505432;\t Train F1 Score - 0.7021277034744015;\t Train Recall - 0.5593220591545105;\t Train Precision - 0.9428571462631226\n",
      "Train Loss - 0.21028700470924377;\t Train AUC - 0.9210779666900635;\t Train F1 Score - 0.7920792305081523;\t Train Recall - 0.6896551847457886;\t Train Precision - 0.930232584476471\n",
      "Train Loss - 0.20188352465629578;\t Train AUC - 0.940183162689209;\t Train F1 Score - 0.7962085454856118;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.2443935126066208;\t Train AUC - 0.9165082573890686;\t Train F1 Score - 0.773913046655673;\t Train Recall - 0.631205677986145;\t Train Precision - 1.0\n",
      "Train Loss - 0.19661928713321686;\t Train AUC - 0.9397279024124146;\t Train F1 Score - 0.8019323509358046;\t Train Recall - 0.6693548560142517;\t Train Precision - 1.0\n",
      "Train Loss - 0.25314080715179443;\t Train AUC - 0.9082683324813843;\t Train F1 Score - 0.7851239006414408;\t Train Recall - 0.6551724076271057;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.22177726030349731;\t Train AUC - 0.9278960227966309;\t Train F1 Score - 0.7741935555172754;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2489771991968155;\t Train AUC - 0.910663366317749;\t Train F1 Score - 0.7733333716634889;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.18942365050315857;\t Train AUC - 0.9438628554344177;\t Train F1 Score - 0.8118811621758051;\t Train Recall - 0.6833333373069763;\t Train Precision - 1.0\n",
      "Train Loss - 0.2549821436405182;\t Train AUC - 0.9056233167648315;\t Train F1 Score - 0.7851239006414408;\t Train Recall - 0.6551724076271057;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.20096684992313385;\t Train AUC - 0.9351731538772583;\t Train F1 Score - 0.8260869839015675;\t Train Recall - 0.7037037014961243;\t Train Precision - 1.0\n",
      "Train Loss - 0.2289329469203949;\t Train AUC - 0.9226347208023071;\t Train F1 Score - 0.794759869559589;\t Train Recall - 0.6594203114509583;\t Train Precision - 1.0\n",
      "Train Loss - 0.2210410088300705;\t Train AUC - 0.9105008840560913;\t Train F1 Score - 0.7553191513817092;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9102563858032227\n",
      "Train Loss - 0.22206349670886993;\t Train AUC - 0.9218412041664124;\t Train F1 Score - 0.807174932833613;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.23510411381721497;\t Train AUC - 0.9342268109321594;\t Train F1 Score - 0.8142856928683763;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9661017060279846\n",
      "Train Loss - 0.21941861510276794;\t Train AUC - 0.93021559715271;\t Train F1 Score - 0.790909119848174;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.23745577037334442;\t Train AUC - 0.8991097211837769;\t Train F1 Score - 0.7860697309203589;\t Train Recall - 0.6528925895690918;\t Train Precision - 0.987500011920929\n",
      "Train Loss - 0.25298863649368286;\t Train AUC - 0.8794665336608887;\t Train F1 Score - 0.7614213525637972;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9868420958518982\n",
      "Train Loss - 0.21652893722057343;\t Train AUC - 0.9255928993225098;\t Train F1 Score - 0.8036529436160376;\t Train Recall - 0.6717557311058044;\t Train Precision - 1.0\n",
      "Train Loss - 0.22143983840942383;\t Train AUC - 0.9200579524040222;\t Train F1 Score - 0.7720929973110418;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9120879173278809\n",
      "Train Loss - 0.21848942339420319;\t Train AUC - 0.9301251173019409;\t Train F1 Score - 0.7929515351016052;\t Train Recall - 0.6766917109489441;\t Train Precision - 0.957446813583374\n",
      "Train Loss - 0.25338080525398254;\t Train AUC - 0.9173073768615723;\t Train F1 Score - 0.754385987055343;\t Train Recall - 0.6056337952613831;\t Train Precision - 1.0\n",
      "Train Loss - 0.2456839233636856;\t Train AUC - 0.907986581325531;\t Train F1 Score - 0.7881356032090371;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.04505450278520584;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.23145200312137604;\t Test AUC - 0.8969864845275879;\t Test F1 Score - 0.7941176556718632;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9418604373931885\n",
      "Test Loss - 0.26778388023376465;\t Test AUC - 0.8848527073860168;\t Test F1 Score - 0.7511737574717161;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.22585807740688324;\t Test AUC - 0.9201611876487732;\t Test F1 Score - 0.7720929968648607;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9431818127632141\n",
      "Test Loss - 0.21815267205238342;\t Test AUC - 0.907934844493866;\t Test F1 Score - 0.8130841280737375;\t Test Recall - 0.6904761791229248;\t Test Precision - 0.9886363744735718\n",
      "Test Loss - 0.24432027339935303;\t Test AUC - 0.9137783050537109;\t Test F1 Score - 0.7547169696355303;\t Test Recall - 0.6349206566810608;\t Test Precision - 0.930232584476471\n",
      "Test Loss - 0.2221582531929016;\t Test AUC - 0.9029402136802673;\t Test F1 Score - 0.7772020271919031;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.949367105960846\n",
      "Test Loss - 0.234455868601799;\t Test AUC - 0.8993659019470215;\t Test F1 Score - 0.7619047124503112;\t Test Recall - 0.6206896305084229;\t Test Precision - 0.9863013625144958\n",
      "Test Loss - 0.2539960443973541;\t Test AUC - 0.8886964321136475;\t Test F1 Score - 0.7329842389082042;\t Test Recall - 0.5932203531265259;\t Test Precision - 0.9589040875434875\n",
      "Test Loss - 0.23379631340503693;\t Test AUC - 0.9203780293464661;\t Test F1 Score - 0.7982832546603266;\t Test Recall - 0.6788321137428284;\t Test Precision - 0.96875\n",
      "Test Loss - 0.2552274167537689;\t Test AUC - 0.892715334892273;\t Test F1 Score - 0.7609756273623935;\t Test Recall - 0.6341463327407837;\t Test Precision - 0.9512194991111755\n",
      "Test Loss - 0.31774479150772095;\t Test AUC - 0.8713638782501221;\t Test F1 Score - 0.7288135606459688;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9247311949729919\n",
      "Test Loss - 0.23631739616394043;\t Test AUC - 0.9224706888198853;\t Test F1 Score - 0.7777777942055526;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.9578947424888611\n",
      "Test Loss - 0.2731776833534241;\t Test AUC - 0.8898881077766418;\t Test F1 Score - 0.7533632658421221;\t Test Recall - 0.6176470518112183;\t Test Precision - 0.9655172228813171\n",
      "Test Loss - 0.2520466446876526;\t Test AUC - 0.8985529541969299;\t Test F1 Score - 0.7669902847277571;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9518072009086609\n",
      "Test Loss - 0.2632567882537842;\t Test AUC - 0.8989400267601013;\t Test F1 Score - 0.7811158957920415;\t Test Recall - 0.6453900933265686;\t Test Precision - 0.989130437374115\n",
      "Test Loss - 0.2652743458747864;\t Test AUC - 0.8853059411048889;\t Test F1 Score - 0.7244898543156821;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9594594836235046\n",
      "Test Loss - 0.30426380038261414;\t Test AUC - 0.9077380895614624;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 26\n",
      "Train Loss - 0.2112305909395218;\t Train AUC - 0.9442852139472961;\t Train F1 Score - 0.8064516267580489;\t Train Recall - 0.6849315166473389;\t Train Precision - 0.9803921580314636\n",
      "Train Loss - 0.2510744631290436;\t Train AUC - 0.9046998023986816;\t Train F1 Score - 0.7462686522087659;\t Train Recall - 0.6048387289047241;\t Train Precision - 0.9740259647369385\n",
      "Train Loss - 0.23879727721214294;\t Train AUC - 0.9246435165405273;\t Train F1 Score - 0.7601810528243206;\t Train Recall - 0.6222222447395325;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2117711901664734;\t Train AUC - 0.9286415576934814;\t Train F1 Score - 0.8018433393641516;\t Train Recall - 0.6692307591438293;\t Train Precision - 1.0\n",
      "Train Loss - 0.2123813033103943;\t Train AUC - 0.9309520721435547;\t Train F1 Score - 0.808888889524206;\t Train Recall - 0.689393937587738;\t Train Precision - 0.9784946441650391\n",
      "Train Loss - 0.24388223886489868;\t Train AUC - 0.9316518902778625;\t Train F1 Score - 0.8014440854555313;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.9736841917037964\n",
      "Train Loss - 0.29653245210647583;\t Train AUC - 0.8830174207687378;\t Train F1 Score - 0.6940639150710427;\t Train Recall - 0.5390070676803589;\t Train Precision - 0.9743589758872986\n",
      "Train Loss - 0.20026244223117828;\t Train AUC - 0.931022584438324;\t Train F1 Score - 0.8340807618724737;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9893617033958435\n",
      "Train Loss - 0.20532916486263275;\t Train AUC - 0.9419342875480652;\t Train F1 Score - 0.7889907771545216;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9885057210922241\n",
      "Train Loss - 0.2225620597600937;\t Train AUC - 0.9275531768798828;\t Train F1 Score - 0.7741935698611735;\t Train Recall - 0.6461538672447205;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.23573948442935944;\t Train AUC - 0.9109406471252441;\t Train F1 Score - 0.8050847549549793;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.2459149956703186;\t Train AUC - 0.9151632189750671;\t Train F1 Score - 0.7368421093053269;\t Train Recall - 0.6015625;\t Train Precision - 0.9506173133850098\n",
      "Train Loss - 0.20908664166927338;\t Train AUC - 0.9299077391624451;\t Train F1 Score - 0.7902439074036137;\t Train Recall - 0.6639344096183777;\t Train Precision - 0.9759036302566528\n",
      "Train Loss - 0.23479421436786652;\t Train AUC - 0.9135395884513855;\t Train F1 Score - 0.798283244359865;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.20744214951992035;\t Train AUC - 0.9321852326393127;\t Train F1 Score - 0.7943924858882201;\t Train Recall - 0.6800000071525574;\t Train Precision - 0.9550561904907227\n",
      "Train Loss - 0.26417261362075806;\t Train AUC - 0.8794394731521606;\t Train F1 Score - 0.7195767450690547;\t Train Recall - 0.5762711763381958;\t Train Precision - 0.9577465057373047\n",
      "Train Loss - 0.20930881798267365;\t Train AUC - 0.9223425388336182;\t Train F1 Score - 0.7941176362288684;\t Train Recall - 0.6982758641242981;\t Train Precision - 0.9204545617103577\n",
      "Train Loss - 0.1998433619737625;\t Train AUC - 0.9398483037948608;\t Train F1 Score - 0.8018432796032903;\t Train Recall - 0.6904761791229248;\t Train Precision - 0.9560439586639404\n",
      "Train Loss - 0.24569071829319;\t Train AUC - 0.916685938835144;\t Train F1 Score - 0.7815125344754611;\t Train Recall - 0.6595744490623474;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.19303308427333832;\t Train AUC - 0.9397618174552917;\t Train F1 Score - 0.8169013924520093;\t Train Recall - 0.7016128897666931;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.2528563439846039;\t Train AUC - 0.911163330078125;\t Train F1 Score - 0.7868852435063809;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9696969985961914\n",
      "Train Loss - 0.22579751908779144;\t Train AUC - 0.9262927174568176;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.24942827224731445;\t Train AUC - 0.9110991954803467;\t Train F1 Score - 0.7767857227831861;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.19064967334270477;\t Train AUC - 0.9419617652893066;\t Train F1 Score - 0.8118811621758051;\t Train Recall - 0.6833333373069763;\t Train Precision - 1.0\n",
      "Train Loss - 0.2550611197948456;\t Train AUC - 0.9102084040641785;\t Train F1 Score - 0.7800829301072709;\t Train Recall - 0.6482758522033691;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.20392441749572754;\t Train AUC - 0.9343688488006592;\t Train F1 Score - 0.8189654574040661;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.2304852306842804;\t Train AUC - 0.9234502911567688;\t Train F1 Score - 0.7733333830515553;\t Train Recall - 0.6304348111152649;\t Train Precision - 1.0\n",
      "Train Loss - 0.21904006600379944;\t Train AUC - 0.9080148935317993;\t Train F1 Score - 0.7513226831101855;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.8987341523170471\n",
      "Train Loss - 0.2212308943271637;\t Train AUC - 0.9243314266204834;\t Train F1 Score - 0.8054297921502483;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9888888597488403\n",
      "Train Loss - 0.23443995416164398;\t Train AUC - 0.9358334541320801;\t Train F1 Score - 0.8172042842701475;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9743589758872986\n",
      "Train Loss - 0.21898269653320312;\t Train AUC - 0.9337202310562134;\t Train F1 Score - 0.790909119848174;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.2369479387998581;\t Train AUC - 0.9010938405990601;\t Train F1 Score - 0.7860697309203589;\t Train Recall - 0.6528925895690918;\t Train Precision - 0.987500011920929\n",
      "Train Loss - 0.2520780861377716;\t Train AUC - 0.8801566362380981;\t Train F1 Score - 0.7614213525637972;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9868420958518982\n",
      "Train Loss - 0.21669982373714447;\t Train AUC - 0.925348699092865;\t Train F1 Score - 0.8036529436160376;\t Train Recall - 0.6717557311058044;\t Train Precision - 1.0\n",
      "Train Loss - 0.21440722048282623;\t Train AUC - 0.9229127168655396;\t Train F1 Score - 0.7924528081369108;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.21552284061908722;\t Train AUC - 0.9302619695663452;\t Train F1 Score - 0.7929515351016052;\t Train Recall - 0.6766917109489441;\t Train Precision - 0.957446813583374\n",
      "Train Loss - 0.2501024007797241;\t Train AUC - 0.9163232445716858;\t Train F1 Score - 0.7705627829347478;\t Train Recall - 0.6267605423927307;\t Train Precision - 1.0\n",
      "Train Loss - 0.2398136407136917;\t Train AUC - 0.912574291229248;\t Train F1 Score - 0.7881356032090371;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.04784650355577469;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22631403803825378;\t Test AUC - 0.8951402902603149;\t Test F1 Score - 0.7980295709785218;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9529411792755127\n",
      "Test Loss - 0.2629680037498474;\t Test AUC - 0.8872013092041016;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.22236666083335876;\t Test AUC - 0.9206855297088623;\t Test F1 Score - 0.7850467433525141;\t Test Recall - 0.6614173054695129;\t Test Precision - 0.9655172228813171\n",
      "Test Loss - 0.21909385919570923;\t Test AUC - 0.9080771207809448;\t Test F1 Score - 0.8186047205043374;\t Test Recall - 0.6984127163887024;\t Test Precision - 0.9887640476226807\n",
      "Test Loss - 0.23047220706939697;\t Test AUC - 0.9184247255325317;\t Test F1 Score - 0.775119576703991;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9759036302566528\n",
      "Test Loss - 0.21691203117370605;\t Test AUC - 0.9069380760192871;\t Test F1 Score - 0.7853403141361257;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.9740259647369385\n",
      "Test Loss - 0.23317591845989227;\t Test AUC - 0.9029281735420227;\t Test F1 Score - 0.7593583057741418;\t Test Recall - 0.6120689511299133;\t Test Precision - 1.0\n",
      "Test Loss - 0.2544838786125183;\t Test AUC - 0.8888986706733704;\t Test F1 Score - 0.726315765890834;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9583333134651184\n",
      "Test Loss - 0.2236039787530899;\t Test AUC - 0.9237202405929565;\t Test F1 Score - 0.8051947773532095;\t Test Recall - 0.6788321137428284;\t Test Precision - 0.9893617033958435\n",
      "Test Loss - 0.24485956132411957;\t Test AUC - 0.8941470384597778;\t Test F1 Score - 0.774509817649225;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9753086566925049\n",
      "Test Loss - 0.2906090021133423;\t Test AUC - 0.8757326006889343;\t Test F1 Score - 0.7413793273885741;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.966292142868042\n",
      "Test Loss - 0.23528757691383362;\t Test AUC - 0.9220025539398193;\t Test F1 Score - 0.7811158675323185;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.9680851101875305\n",
      "Test Loss - 0.2737559974193573;\t Test AUC - 0.8861324787139893;\t Test F1 Score - 0.7488583687925513;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.9879518151283264\n",
      "Test Loss - 0.24987822771072388;\t Test AUC - 0.9033423662185669;\t Test F1 Score - 0.7499999811828137;\t Test Recall - 0.6097561120986938;\t Test Precision - 0.9740259647369385\n",
      "Test Loss - 0.2613869607448578;\t Test AUC - 0.9002842903137207;\t Test F1 Score - 0.7705627336126593;\t Test Recall - 0.631205677986145;\t Test Precision - 0.9888888597488403\n",
      "Test Loss - 0.2581593692302704;\t Test AUC - 0.8883668184280396;\t Test F1 Score - 0.7319588255855978;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.29564446210861206;\t Test AUC - 0.9091811180114746;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 27\n",
      "Train Loss - 0.21424570679664612;\t Train AUC - 0.9432668685913086;\t Train F1 Score - 0.8048780208917559;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9900000095367432\n",
      "Train Loss - 0.24601025879383087;\t Train AUC - 0.9022516012191772;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.23890553414821625;\t Train AUC - 0.9246435761451721;\t Train F1 Score - 0.7601810528243206;\t Train Recall - 0.6222222447395325;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.21099305152893066;\t Train AUC - 0.9300491213798523;\t Train F1 Score - 0.8036530412381315;\t Train Recall - 0.6769230961799622;\t Train Precision - 0.9887640476226807\n",
      "Train Loss - 0.2276623547077179;\t Train AUC - 0.9303127527236938;\t Train F1 Score - 0.7947598218091847;\t Train Recall - 0.689393937587738;\t Train Precision - 0.938144326210022\n",
      "Train Loss - 0.23887181282043457;\t Train AUC - 0.9341017603874207;\t Train F1 Score - 0.8115941926041764;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.991150438785553\n",
      "Train Loss - 0.2946058511734009;\t Train AUC - 0.8867257237434387;\t Train F1 Score - 0.7149321266968326;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.987500011920929\n",
      "Train Loss - 0.19869069755077362;\t Train AUC - 0.9335982799530029;\t Train F1 Score - 0.8266666619632406;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.96875\n",
      "Train Loss - 0.21111120283603668;\t Train AUC - 0.9408925771713257;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.22042180597782135;\t Train AUC - 0.9317511916160583;\t Train F1 Score - 0.7720930311525063;\t Train Recall - 0.6384615302085876;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.23742413520812988;\t Train AUC - 0.9071770906448364;\t Train F1 Score - 0.8;\t Train Recall - 0.6911764740943909;\t Train Precision - 0.9494949579238892\n",
      "Train Loss - 0.2421148419380188;\t Train AUC - 0.915444552898407;\t Train F1 Score - 0.7403845809400649;\t Train Recall - 0.6015625;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.20676349103450775;\t Train AUC - 0.9312280416488647;\t Train F1 Score - 0.8038277611965254;\t Train Recall - 0.688524603843689;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.23725056648254395;\t Train AUC - 0.9088884592056274;\t Train F1 Score - 0.8068669346080595;\t Train Recall - 0.6911764740943909;\t Train Precision - 0.969072163105011\n",
      "Train Loss - 0.20621144771575928;\t Train AUC - 0.9344925880432129;\t Train F1 Score - 0.8165137863687115;\t Train Recall - 0.7120000123977661;\t Train Precision - 0.9569892287254333\n",
      "Train Loss - 0.26506301760673523;\t Train AUC - 0.8811537623405457;\t Train F1 Score - 0.7120418868864631;\t Train Recall - 0.5762711763381958;\t Train Precision - 0.931506872177124\n",
      "Train Loss - 0.21157532930374146;\t Train AUC - 0.9229481220245361;\t Train F1 Score - 0.7864077134041056;\t Train Recall - 0.6982758641242981;\t Train Precision - 0.8999999761581421\n",
      "Train Loss - 0.19430740177631378;\t Train AUC - 0.94577556848526;\t Train F1 Score - 0.8055554796224362;\t Train Recall - 0.6904761791229248;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.2412235587835312;\t Train AUC - 0.9216381311416626;\t Train F1 Score - 0.783333404635391;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9494949579238892\n",
      "Train Loss - 0.20124831795692444;\t Train AUC - 0.9379998445510864;\t Train F1 Score - 0.8093023202296311;\t Train Recall - 0.7016128897666931;\t Train Precision - 0.9560439586639404\n",
      "Train Loss - 0.25623011589050293;\t Train AUC - 0.9082000851631165;\t Train F1 Score - 0.7804877561955318;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9504950642585754\n",
      "Train Loss - 0.22680696845054626;\t Train AUC - 0.9278797507286072;\t Train F1 Score - 0.7649768822410304;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.24949106574058533;\t Train AUC - 0.9105365872383118;\t Train F1 Score - 0.765765727157475;\t Train Recall - 0.625;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.1887616664171219;\t Train AUC - 0.9441059231758118;\t Train F1 Score - 0.805970186431947;\t Train Recall - 0.675000011920929;\t Train Precision - 1.0\n",
      "Train Loss - 0.25482672452926636;\t Train AUC - 0.9088745713233948;\t Train F1 Score - 0.7750000091963934;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.207180455327034;\t Train AUC - 0.9343926906585693;\t Train F1 Score - 0.8173912883600787;\t Train Recall - 0.6962962746620178;\t Train Precision - 0.9894737005233765\n",
      "Train Loss - 0.22996042668819427;\t Train AUC - 0.9263128638267517;\t Train F1 Score - 0.7841410160934561;\t Train Recall - 0.6449275612831116;\t Train Precision - 1.0\n",
      "Train Loss - 0.21612253785133362;\t Train AUC - 0.9139239192008972;\t Train F1 Score - 0.7650272648279683;\t Train Recall - 0.6363636255264282;\t Train Precision - 0.9589040875434875\n",
      "Train Loss - 0.219071626663208;\t Train AUC - 0.9250720143318176;\t Train F1 Score - 0.8054297921502483;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9888888597488403\n",
      "Train Loss - 0.2339804321527481;\t Train AUC - 0.935734748840332;\t Train F1 Score - 0.8172042842701475;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9743589758872986\n",
      "Train Loss - 0.21831782162189484;\t Train AUC - 0.932659924030304;\t Train F1 Score - 0.790909119848174;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.23902057111263275;\t Train AUC - 0.8987473845481873;\t Train F1 Score - 0.7761194150691285;\t Train Recall - 0.64462810754776;\t Train Precision - 0.9750000238418579\n",
      "Train Loss - 0.2538678050041199;\t Train AUC - 0.8790783286094666;\t Train F1 Score - 0.7676767900430327;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.9870129823684692\n",
      "Train Loss - 0.21514828503131866;\t Train AUC - 0.9290108680725098;\t Train F1 Score - 0.7981651855903736;\t Train Recall - 0.6641221642494202;\t Train Precision - 1.0\n",
      "Train Loss - 0.22015099227428436;\t Train AUC - 0.9227941036224365;\t Train F1 Score - 0.7887323653685633;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.9438202381134033\n",
      "Train Loss - 0.21890655159950256;\t Train AUC - 0.9287485480308533;\t Train F1 Score - 0.7894736958003183;\t Train Recall - 0.6766917109489441;\t Train Precision - 0.9473684430122375\n",
      "Train Loss - 0.25403666496276855;\t Train AUC - 0.9119949340820312;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.24452781677246094;\t Train AUC - 0.9131813049316406;\t Train F1 Score - 0.7815126294656232;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.9207921028137207\n",
      "Train Loss - 0.04260248318314552;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22307655215263367;\t Test AUC - 0.8991754055023193;\t Test F1 Score - 0.8078817627838591;\t Test Recall - 0.694915235042572;\t Test Precision - 0.9647058844566345\n",
      "Test Loss - 0.2632792294025421;\t Test AUC - 0.8908755779266357;\t Test F1 Score - 0.7511737574717161;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.22291621565818787;\t Test AUC - 0.9241313934326172;\t Test F1 Score - 0.773584874932692;\t Test Recall - 0.6456692814826965;\t Test Precision - 0.9647058844566345\n",
      "Test Loss - 0.22080399096012115;\t Test AUC - 0.9091403484344482;\t Test F1 Score - 0.8186047205043374;\t Test Recall - 0.6984127163887024;\t Test Precision - 0.9887640476226807\n",
      "Test Loss - 0.2310386598110199;\t Test AUC - 0.9178387522697449;\t Test F1 Score - 0.775119576703991;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9759036302566528\n",
      "Test Loss - 0.22244727611541748;\t Test AUC - 0.9028048515319824;\t Test F1 Score - 0.7668394608101079;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9367088675498962\n",
      "Test Loss - 0.23610557615756989;\t Test AUC - 0.9028034806251526;\t Test F1 Score - 0.7593583057741418;\t Test Recall - 0.6120689511299133;\t Test Precision - 1.0\n",
      "Test Loss - 0.25821653008461;\t Test AUC - 0.8871580362319946;\t Test F1 Score - 0.7187500319202943;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9324324131011963\n",
      "Test Loss - 0.23138318955898285;\t Test AUC - 0.9202046394348145;\t Test F1 Score - 0.7982832546603266;\t Test Recall - 0.6788321137428284;\t Test Precision - 0.96875\n",
      "Test Loss - 0.25613901019096375;\t Test AUC - 0.8907552361488342;\t Test F1 Score - 0.7632850448942468;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9404761791229248\n",
      "Test Loss - 0.29996320605278015;\t Test AUC - 0.8722131252288818;\t Test F1 Score - 0.7381974350795572;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9555555582046509\n",
      "Test Loss - 0.23851048946380615;\t Test AUC - 0.9197162389755249;\t Test F1 Score - 0.7863247663257549;\t Test Recall - 0.6618704795837402;\t Test Precision - 0.9684210419654846\n",
      "Test Loss - 0.27429917454719543;\t Test AUC - 0.8875190019607544;\t Test F1 Score - 0.7545454436973263;\t Test Recall - 0.6102941036224365;\t Test Precision - 0.988095223903656\n",
      "Test Loss - 0.2519078552722931;\t Test AUC - 0.8998057246208191;\t Test F1 Score - 0.7623762413105561;\t Test Recall - 0.6260162591934204;\t Test Precision - 0.9746835231781006\n",
      "Test Loss - 0.264415442943573;\t Test AUC - 0.9017907977104187;\t Test F1 Score - 0.7705627336126593;\t Test Recall - 0.631205677986145;\t Test Precision - 0.9888888597488403\n",
      "Test Loss - 0.25590455532073975;\t Test AUC - 0.8959205150604248;\t Test F1 Score - 0.7319588255855978;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.2995069921016693;\t Test AUC - 0.9154942631721497;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 28\n",
      "Train Loss - 0.21345922350883484;\t Train AUC - 0.9449414014816284;\t Train F1 Score - 0.8016194340715057;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9801980257034302\n",
      "Train Loss - 0.2500650882720947;\t Train AUC - 0.8977110981941223;\t Train F1 Score - 0.7474747685896667;\t Train Recall - 0.5967742204666138;\t Train Precision - 1.0\n",
      "Train Loss - 0.2372094690799713;\t Train AUC - 0.9278773069381714;\t Train F1 Score - 0.7601810528243206;\t Train Recall - 0.6222222447395325;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2100238800048828;\t Train AUC - 0.9311293363571167;\t Train F1 Score - 0.8018433393641516;\t Train Recall - 0.6692307591438293;\t Train Precision - 1.0\n",
      "Train Loss - 0.21028009057044983;\t Train AUC - 0.9342543482780457;\t Train F1 Score - 0.8053097459698839;\t Train Recall - 0.689393937587738;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.2416813224554062;\t Train AUC - 0.9326556921005249;\t Train F1 Score - 0.8057554023955975;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9739130139350891\n",
      "Train Loss - 0.2987063527107239;\t Train AUC - 0.887536883354187;\t Train F1 Score - 0.6818181452376787;\t Train Recall - 0.5319148898124695;\t Train Precision - 0.949367105960846\n",
      "Train Loss - 0.20637859404087067;\t Train AUC - 0.9289817810058594;\t Train F1 Score - 0.83035716414605;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.20879511535167694;\t Train AUC - 0.938483715057373;\t Train F1 Score - 0.7813953552560722;\t Train Recall - 0.6412213444709778;\t Train Precision - 1.0\n",
      "Train Loss - 0.22075490653514862;\t Train AUC - 0.9312110543251038;\t Train F1 Score - 0.7777777288080614;\t Train Recall - 0.6461538672447205;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.22816075384616852;\t Train AUC - 0.913000762462616;\t Train F1 Score - 0.8101266086978051;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.9504950642585754\n",
      "Train Loss - 0.2429383099079132;\t Train AUC - 0.9147907495498657;\t Train F1 Score - 0.7403845809400649;\t Train Recall - 0.6015625;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.20176497101783752;\t Train AUC - 0.9341003894805908;\t Train F1 Score - 0.8076923324719436;\t Train Recall - 0.688524603843689;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2369774878025055;\t Train AUC - 0.9094827771186829;\t Train F1 Score - 0.7931034658771513;\t Train Recall - 0.6764705777168274;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.20585057139396667;\t Train AUC - 0.9349809885025024;\t Train F1 Score - 0.8037383312262812;\t Train Recall - 0.6880000233650208;\t Train Precision - 0.966292142868042\n",
      "Train Loss - 0.2592045068740845;\t Train AUC - 0.8844063878059387;\t Train F1 Score - 0.7225130649366172;\t Train Recall - 0.5847457647323608;\t Train Precision - 0.9452054500579834\n",
      "Train Loss - 0.20921732485294342;\t Train AUC - 0.9259048700332642;\t Train F1 Score - 0.7881773417261098;\t Train Recall - 0.6896551847457886;\t Train Precision - 0.9195402264595032\n",
      "Train Loss - 0.2037813812494278;\t Train AUC - 0.9370270371437073;\t Train F1 Score - 0.811059890681767;\t Train Recall - 0.6984127163887024;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.24521341919898987;\t Train AUC - 0.9185864925384521;\t Train F1 Score - 0.7796610194422026;\t Train Recall - 0.652482271194458;\t Train Precision - 0.9684210419654846\n",
      "Train Loss - 0.19369345903396606;\t Train AUC - 0.9396855235099792;\t Train F1 Score - 0.8169013924520093;\t Train Recall - 0.7016128897666931;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.2520947754383087;\t Train AUC - 0.9085789918899536;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.22260211408138275;\t Train AUC - 0.9303210973739624;\t Train F1 Score - 0.7649768822410304;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9651162624359131\n",
      "Train Loss - 0.24687007069587708;\t Train AUC - 0.9128739833831787;\t Train F1 Score - 0.7753303844376773;\t Train Recall - 0.6470588445663452;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.19714060425758362;\t Train AUC - 0.9374566078186035;\t Train F1 Score - 0.8097560627012117;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.25252920389175415;\t Train AUC - 0.908359169960022;\t Train F1 Score - 0.7918367198501088;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9700000286102295\n",
      "Train Loss - 0.19964361190795898;\t Train AUC - 0.9381362199783325;\t Train F1 Score - 0.8173912883600787;\t Train Recall - 0.6962962746620178;\t Train Precision - 0.9894737005233765\n",
      "Train Loss - 0.22825609147548676;\t Train AUC - 0.9254344701766968;\t Train F1 Score - 0.7860262214905991;\t Train Recall - 0.6521739363670349;\t Train Precision - 0.9890109896659851\n",
      "Train Loss - 0.21711578965187073;\t Train AUC - 0.9103617668151855;\t Train F1 Score - 0.7675675817330154;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9466666579246521\n",
      "Train Loss - 0.2240859419107437;\t Train AUC - 0.9190172553062439;\t Train F1 Score - 0.807174932833613;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.23176059126853943;\t Train AUC - 0.9375880360603333;\t Train F1 Score - 0.8142856928683763;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9661017060279846\n",
      "Train Loss - 0.22142374515533447;\t Train AUC - 0.9315025210380554;\t Train F1 Score - 0.787330296637268;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.23452290892601013;\t Train AUC - 0.9028710126876831;\t Train F1 Score - 0.7860697309203589;\t Train Recall - 0.6528925895690918;\t Train Precision - 0.987500011920929\n",
      "Train Loss - 0.24911275506019592;\t Train AUC - 0.880001425743103;\t Train F1 Score - 0.7676767900430327;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.9870129823684692\n",
      "Train Loss - 0.21766291558742523;\t Train AUC - 0.9251452684402466;\t Train F1 Score - 0.7981651855903736;\t Train Recall - 0.6641221642494202;\t Train Precision - 1.0\n",
      "Train Loss - 0.21361850202083588;\t Train AUC - 0.9249457716941833;\t Train F1 Score - 0.7942584279624261;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.218878835439682;\t Train AUC - 0.927532970905304;\t Train F1 Score - 0.7982456305919327;\t Train Recall - 0.6842105388641357;\t Train Precision - 0.9578947424888611\n",
      "Train Loss - 0.2498866468667984;\t Train AUC - 0.9168229699134827;\t Train F1 Score - 0.7705627829347478;\t Train Recall - 0.6267605423927307;\t Train Precision - 1.0\n",
      "Train Loss - 0.2405991405248642;\t Train AUC - 0.9109505414962769;\t Train F1 Score - 0.7899159663865546;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9306930899620056\n",
      "Train Loss - 0.045619454234838486;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2224750816822052;\t Test AUC - 0.8987798094749451;\t Test F1 Score - 0.8019801987348144;\t Test Recall - 0.6864407062530518;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.2644414007663727;\t Test AUC - 0.8854336738586426;\t Test F1 Score - 0.7441860661031489;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9411764740943909\n",
      "Test Loss - 0.21892115473747253;\t Test AUC - 0.9269031286239624;\t Test F1 Score - 0.7830188624049881;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9764705896377563\n",
      "Test Loss - 0.21840617060661316;\t Test AUC - 0.9113839864730835;\t Test F1 Score - 0.811059890681767;\t Test Recall - 0.6984127163887024;\t Test Precision - 0.9670329689979553\n",
      "Test Loss - 0.23164202272891998;\t Test AUC - 0.9177382588386536;\t Test F1 Score - 0.775119576703991;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9759036302566528\n",
      "Test Loss - 0.21935038268566132;\t Test AUC - 0.9046549201011658;\t Test F1 Score - 0.7789473545025627;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9736841917037964\n",
      "Test Loss - 0.2290271818637848;\t Test AUC - 0.9060629606246948;\t Test F1 Score - 0.7659574280285951;\t Test Recall - 0.6206896305084229;\t Test Precision - 1.0\n",
      "Test Loss - 0.25317034125328064;\t Test AUC - 0.8896371126174927;\t Test F1 Score - 0.7291666892564141;\t Test Recall - 0.5932203531265259;\t Test Precision - 0.9459459185600281\n",
      "Test Loss - 0.22736725211143494;\t Test AUC - 0.9209534525871277;\t Test F1 Score - 0.8051947773532095;\t Test Recall - 0.6788321137428284;\t Test Precision - 0.9893617033958435\n",
      "Test Loss - 0.25300437211990356;\t Test AUC - 0.8875168561935425;\t Test F1 Score - 0.7669902847277571;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9518072009086609\n",
      "Test Loss - 0.2952063977718353;\t Test AUC - 0.8740723133087158;\t Test F1 Score - 0.7413793273885741;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.966292142868042\n",
      "Test Loss - 0.23623506724834442;\t Test AUC - 0.9187877178192139;\t Test F1 Score - 0.7896995262201468;\t Test Recall - 0.6618704795837402;\t Test Precision - 0.978723406791687\n",
      "Test Loss - 0.27283909916877747;\t Test AUC - 0.8872020840644836;\t Test F1 Score - 0.7488583687925513;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.9879518151283264\n",
      "Test Loss - 0.2496512085199356;\t Test AUC - 0.9017401933670044;\t Test F1 Score - 0.7524752781542471;\t Test Recall - 0.6178861856460571;\t Test Precision - 0.9620253443717957\n",
      "Test Loss - 0.2645648419857025;\t Test AUC - 0.8993571996688843;\t Test F1 Score - 0.7652174112281647;\t Test Recall - 0.6241135001182556;\t Test Precision - 0.9887640476226807\n",
      "Test Loss - 0.2563258409500122;\t Test AUC - 0.8930996656417847;\t Test F1 Score - 0.7244898543156821;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9594594836235046\n",
      "Test Loss - 0.29921019077301025;\t Test AUC - 0.9049422740936279;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 29\n",
      "Train Loss - 0.21986928582191467;\t Train AUC - 0.9392387270927429;\t Train F1 Score - 0.7999999856472213;\t Train Recall - 0.6712328791618347;\t Train Precision - 0.9898989796638489\n",
      "Train Loss - 0.24768520891666412;\t Train AUC - 0.8985496759414673;\t Train F1 Score - 0.7474747685896667;\t Train Recall - 0.5967742204666138;\t Train Precision - 1.0\n",
      "Train Loss - 0.24107269942760468;\t Train AUC - 0.9223815202713013;\t Train F1 Score - 0.7567567770489568;\t Train Recall - 0.6222222447395325;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.2120632380247116;\t Train AUC - 0.9305400848388672;\t Train F1 Score - 0.8036530412381315;\t Train Recall - 0.6769230961799622;\t Train Precision - 0.9887640476226807\n",
      "Train Loss - 0.21471163630485535;\t Train AUC - 0.9316805601119995;\t Train F1 Score - 0.8053097459698839;\t Train Recall - 0.689393937587738;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.24185048043727875;\t Train AUC - 0.9346983432769775;\t Train F1 Score - 0.7985611599356318;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.9652174115180969\n",
      "Train Loss - 0.3043209910392761;\t Train AUC - 0.8851264119148254;\t Train F1 Score - 0.6902654566014345;\t Train Recall - 0.5531914830207825;\t Train Precision - 0.9176470637321472\n",
      "Train Loss - 0.19980323314666748;\t Train AUC - 0.9347915649414062;\t Train F1 Score - 0.8251120646529554;\t Train Recall - 0.713178277015686;\t Train Precision - 0.978723406791687\n",
      "Train Loss - 0.21840819716453552;\t Train AUC - 0.9358225464820862;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2343894988298416;\t Train AUC - 0.926153838634491;\t Train F1 Score - 0.7476635705889523;\t Train Recall - 0.6153846383094788;\t Train Precision - 0.9523809552192688\n",
      "Train Loss - 0.24314910173416138;\t Train AUC - 0.9052120447158813;\t Train F1 Score - 0.798283244359865;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.25395211577415466;\t Train AUC - 0.9094280004501343;\t Train F1 Score - 0.7000000235421319;\t Train Recall - 0.546875;\t Train Precision - 0.9722222089767456\n",
      "Train Loss - 0.20886489748954773;\t Train AUC - 0.929298996925354;\t Train F1 Score - 0.8039215784126046;\t Train Recall - 0.6721311211585999;\t Train Precision - 1.0\n",
      "Train Loss - 0.23595918715000153;\t Train AUC - 0.9107425808906555;\t Train F1 Score - 0.7914893913906879;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.939393937587738\n",
      "Train Loss - 0.21017347276210785;\t Train AUC - 0.9333894848823547;\t Train F1 Score - 0.7962962854818193;\t Train Recall - 0.6880000233650208;\t Train Precision - 0.9450549483299255\n",
      "Train Loss - 0.25958409905433655;\t Train AUC - 0.8871843814849854;\t Train F1 Score - 0.726315765890834;\t Train Recall - 0.5847457647323608;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.23986074328422546;\t Train AUC - 0.9228768348693848;\t Train F1 Score - 0.7619047655891669;\t Train Recall - 0.6896551847457886;\t Train Precision - 0.8510638475418091\n",
      "Train Loss - 0.19807320833206177;\t Train AUC - 0.9425607919692993;\t Train F1 Score - 0.8055554796224362;\t Train Recall - 0.6904761791229248;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.25485101342201233;\t Train AUC - 0.9198148846626282;\t Train F1 Score - 0.756521693624052;\t Train Recall - 0.6170212626457214;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.19439564645290375;\t Train AUC - 0.9427098035812378;\t Train F1 Score - 0.8056872418529097;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.2507435381412506;\t Train AUC - 0.9097461104393005;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.2188054919242859;\t Train AUC - 0.9331856966018677;\t Train F1 Score - 0.7777777290051637;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.25223252177238464;\t Train AUC - 0.9147835373878479;\t Train F1 Score - 0.7631578828641182;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.945652186870575\n",
      "Train Loss - 0.1940733790397644;\t Train AUC - 0.9384374618530273;\t Train F1 Score - 0.8137254748892616;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.253082811832428;\t Train AUC - 0.9080864191055298;\t Train F1 Score - 0.7901234666514272;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.1991877555847168;\t Train AUC - 0.9375627040863037;\t Train F1 Score - 0.8260869839015675;\t Train Recall - 0.7037037014961243;\t Train Precision - 1.0\n",
      "Train Loss - 0.23073948919773102;\t Train AUC - 0.9237797260284424;\t Train F1 Score - 0.7841410160934561;\t Train Recall - 0.6449275612831116;\t Train Precision - 1.0\n",
      "Train Loss - 0.22076952457427979;\t Train AUC - 0.9070593118667603;\t Train F1 Score - 0.7675675817330154;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9466666579246521\n",
      "Train Loss - 0.22084854543209076;\t Train AUC - 0.9230456352233887;\t Train F1 Score - 0.8035714414357171;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.2367260456085205;\t Train AUC - 0.937383770942688;\t Train F1 Score - 0.8014184268219551;\t Train Recall - 0.6975308656692505;\t Train Precision - 0.9416666626930237\n",
      "Train Loss - 0.21454447507858276;\t Train AUC - 0.9333317279815674;\t Train F1 Score - 0.7982063459699493;\t Train Recall - 0.6742424368858337;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.24133315682411194;\t Train AUC - 0.9009040594100952;\t Train F1 Score - 0.782178246817952;\t Train Recall - 0.6528925895690918;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.25216108560562134;\t Train AUC - 0.8837195634841919;\t Train F1 Score - 0.7575757621086542;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9740259647369385\n",
      "Train Loss - 0.22415746748447418;\t Train AUC - 0.9256335496902466;\t Train F1 Score - 0.7813953552560722;\t Train Recall - 0.6412213444709778;\t Train Precision - 1.0\n",
      "Train Loss - 0.21509243547916412;\t Train AUC - 0.923844575881958;\t Train F1 Score - 0.7942584279624261;\t Train Recall - 0.6693548560142517;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2154158502817154;\t Train AUC - 0.932958722114563;\t Train F1 Score - 0.80701756023653;\t Train Recall - 0.6917293071746826;\t Train Precision - 0.9684210419654846\n",
      "Train Loss - 0.25034379959106445;\t Train AUC - 0.9194215536117554;\t Train F1 Score - 0.7553648458818716;\t Train Recall - 0.6197183132171631;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.23991434276103973;\t Train AUC - 0.9117624163627625;\t Train F1 Score - 0.7815126294656232;\t Train Recall - 0.6788321137428284;\t Train Precision - 0.9207921028137207\n",
      "Train Loss - 0.04149038344621658;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2241089940071106;\t Test AUC - 0.9003358483314514;\t Test F1 Score - 0.7960198939953087;\t Test Recall - 0.6779661178588867;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.2628418505191803;\t Test AUC - 0.8902699947357178;\t Test F1 Score - 0.7393365033737866;\t Test Recall - 0.6000000238418579;\t Test Precision - 0.9629629850387573\n",
      "Test Loss - 0.22257690131664276;\t Test AUC - 0.9238901138305664;\t Test F1 Score - 0.7830188624049881;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9764705896377563\n",
      "Test Loss - 0.21779784560203552;\t Test AUC - 0.9124221205711365;\t Test F1 Score - 0.8130841280737375;\t Test Recall - 0.6904761791229248;\t Test Precision - 0.9886363744735718\n",
      "Test Loss - 0.23192255198955536;\t Test AUC - 0.9170182943344116;\t Test F1 Score - 0.775119576703991;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9759036302566528\n",
      "Test Loss - 0.21784840524196625;\t Test AUC - 0.9057739973068237;\t Test F1 Score - 0.7772020271919031;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.949367105960846\n",
      "Test Loss - 0.2506215274333954;\t Test AUC - 0.8820888996124268;\t Test F1 Score - 0.741935503334981;\t Test Recall - 0.5948275923728943;\t Test Precision - 0.9857142567634583\n",
      "Test Loss - 0.25657644867897034;\t Test AUC - 0.8885205984115601;\t Test F1 Score - 0.7157894522300343;\t Test Recall - 0.5762711763381958;\t Test Precision - 0.9444444179534912\n",
      "Test Loss - 0.23098815977573395;\t Test AUC - 0.9209219813346863;\t Test F1 Score - 0.7999999856441822;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.24986349046230316;\t Test AUC - 0.8889996409416199;\t Test F1 Score - 0.7707317087656925;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.2913849651813507;\t Test AUC - 0.8782420754432678;\t Test F1 Score - 0.7381974350795572;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9555555582046509\n",
      "Test Loss - 0.23811589181423187;\t Test AUC - 0.9189983606338501;\t Test F1 Score - 0.784482807701881;\t Test Recall - 0.6546762585639954;\t Test Precision - 0.9784946441650391\n",
      "Test Loss - 0.27628880739212036;\t Test AUC - 0.8866791129112244;\t Test F1 Score - 0.7431192736528404;\t Test Recall - 0.595588207244873;\t Test Precision - 0.9878048896789551\n",
      "Test Loss - 0.2402733862400055;\t Test AUC - 0.9069898724555969;\t Test F1 Score - 0.7599999851443265;\t Test Recall - 0.6178861856460571;\t Test Precision - 0.9870129823684692\n",
      "Test Loss - 0.2647765278816223;\t Test AUC - 0.8990482091903687;\t Test F1 Score - 0.7705627336126593;\t Test Recall - 0.631205677986145;\t Test Precision - 0.9888888597488403\n",
      "Test Loss - 0.2560640573501587;\t Test AUC - 0.8930482268333435;\t Test F1 Score - 0.7319588255855978;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9861111044883728\n",
      "Test Loss - 0.2956065535545349;\t Test AUC - 0.9110749959945679;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 30\n",
      "Train Loss - 0.21836593747138977;\t Train AUC - 0.9420976042747498;\t Train F1 Score - 0.8016194340715057;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9801980257034302\n",
      "Train Loss - 0.24686884880065918;\t Train AUC - 0.9010826349258423;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.23984451591968536;\t Train AUC - 0.922660231590271;\t Train F1 Score - 0.7545454341144099;\t Train Recall - 0.614814817905426;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.20993967354297638;\t Train AUC - 0.9309165477752686;\t Train F1 Score - 0.8127853803729491;\t Train Recall - 0.6846153736114502;\t Train Precision - 1.0\n",
      "Train Loss - 0.21731966733932495;\t Train AUC - 0.9285483360290527;\t Train F1 Score - 0.7999999710930714;\t Train Recall - 0.6818181872367859;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.24485041201114655;\t Train AUC - 0.9299742579460144;\t Train F1 Score - 0.8014440854555313;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.9736841917037964\n",
      "Train Loss - 0.2933558523654938;\t Train AUC - 0.889468252658844;\t Train F1 Score - 0.7117116648534695;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.19592756032943726;\t Train AUC - 0.9314175248146057;\t Train F1 Score - 0.8378378284769914;\t Train Recall - 0.7209302186965942;\t Train Precision - 1.0\n",
      "Train Loss - 0.21056124567985535;\t Train AUC - 0.9390777349472046;\t Train F1 Score - 0.7741935555172754;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.21690882742404938;\t Train AUC - 0.9366447925567627;\t Train F1 Score - 0.7798164664972755;\t Train Recall - 0.6538461446762085;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.22431673109531403;\t Train AUC - 0.9175963401794434;\t Train F1 Score - 0.8085106551241308;\t Train Recall - 0.6985294222831726;\t Train Precision - 0.9595959782600403\n",
      "Train Loss - 0.23632395267486572;\t Train AUC - 0.916685938835144;\t Train F1 Score - 0.7582938271282594;\t Train Recall - 0.625;\t Train Precision - 0.9638554453849792\n",
      "Train Loss - 0.20397824048995972;\t Train AUC - 0.933620274066925;\t Train F1 Score - 0.8151658801578728;\t Train Recall - 0.7049180269241333;\t Train Precision - 0.966292142868042\n",
      "Train Loss - 0.23035794496536255;\t Train AUC - 0.9146884083747864;\t Train F1 Score - 0.801724140418467;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.96875\n",
      "Train Loss - 0.20744413137435913;\t Train AUC - 0.9368084669113159;\t Train F1 Score - 0.8093023115753423;\t Train Recall - 0.6959999799728394;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.2594238817691803;\t Train AUC - 0.8829647302627563;\t Train F1 Score - 0.7157894522300343;\t Train Recall - 0.5762711763381958;\t Train Precision - 0.9444444179534912\n",
      "Train Loss - 0.20667187869548798;\t Train AUC - 0.9276947975158691;\t Train F1 Score - 0.7804877975567122;\t Train Recall - 0.6896551847457886;\t Train Precision - 0.898876428604126\n",
      "Train Loss - 0.20092307031154633;\t Train AUC - 0.9378390908241272;\t Train F1 Score - 0.799999985540152;\t Train Recall - 0.682539701461792;\t Train Precision - 0.966292142868042\n",
      "Train Loss - 0.24422001838684082;\t Train AUC - 0.9179220795631409;\t Train F1 Score - 0.7725321698516844;\t Train Recall - 0.6382978558540344;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.19358180463314056;\t Train AUC - 0.9409053325653076;\t Train F1 Score - 0.8018867979009142;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.25192204117774963;\t Train AUC - 0.9073285460472107;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.22083786129951477;\t Train AUC - 0.9313709735870361;\t Train F1 Score - 0.7720930017157879;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.24557103216648102;\t Train AUC - 0.9154648780822754;\t Train F1 Score - 0.7747747800381344;\t Train Recall - 0.6323529481887817;\t Train Precision - 1.0\n",
      "Train Loss - 0.1888837218284607;\t Train AUC - 0.9420833587646484;\t Train F1 Score - 0.8177340161829612;\t Train Recall - 0.6916666626930237;\t Train Precision - 1.0\n",
      "Train Loss - 0.25019511580467224;\t Train AUC - 0.91037517786026;\t Train F1 Score - 0.7868852435063809;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9696969985961914\n",
      "Train Loss - 0.19516293704509735;\t Train AUC - 0.938988447189331;\t Train F1 Score - 0.8311688718837608;\t Train Recall - 0.7111111283302307;\t Train Precision - 1.0\n",
      "Train Loss - 0.22384057939052582;\t Train AUC - 0.9271363019943237;\t Train F1 Score - 0.794759869559589;\t Train Recall - 0.6594203114509583;\t Train Precision - 1.0\n",
      "Train Loss - 0.218560129404068;\t Train AUC - 0.9075881242752075;\t Train F1 Score - 0.7634408861814761;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9342105388641357\n",
      "Train Loss - 0.22432133555412292;\t Train AUC - 0.9212389588356018;\t Train F1 Score - 0.8017621433115643;\t Train Recall - 0.694656491279602;\t Train Precision - 0.9479166865348816\n",
      "Train Loss - 0.2299356609582901;\t Train AUC - 0.9378066062927246;\t Train F1 Score - 0.8185053188440449;\t Train Recall - 0.709876537322998;\t Train Precision - 0.9663865566253662\n",
      "Train Loss - 0.21456566452980042;\t Train AUC - 0.9335097074508667;\t Train F1 Score - 0.790909119848174;\t Train Recall - 0.6590909361839294;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.23819293081760406;\t Train AUC - 0.9014648199081421;\t Train F1 Score - 0.7860697309203589;\t Train Recall - 0.6528925895690918;\t Train Precision - 0.987500011920929\n",
      "Train Loss - 0.25209376215934753;\t Train AUC - 0.8815282583236694;\t Train F1 Score - 0.763819078655186;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.9743589758872986\n",
      "Train Loss - 0.21598172187805176;\t Train AUC - 0.927619218826294;\t Train F1 Score - 0.8036529436160376;\t Train Recall - 0.6717557311058044;\t Train Precision - 1.0\n",
      "Train Loss - 0.2147933393716812;\t Train AUC - 0.9235818982124329;\t Train F1 Score - 0.7887323653685633;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.9438202381134033\n",
      "Train Loss - 0.21557846665382385;\t Train AUC - 0.9330714344978333;\t Train F1 Score - 0.7982456305919327;\t Train Recall - 0.6842105388641357;\t Train Precision - 0.9578947424888611\n",
      "Train Loss - 0.24609313905239105;\t Train AUC - 0.9199904203414917;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.23569539189338684;\t Train AUC - 0.9151124954223633;\t Train F1 Score - 0.7932489884522943;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9399999976158142\n",
      "Train Loss - 0.054358262568712234;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.2236432582139969;\t Test AUC - 0.9024896621704102;\t Test F1 Score - 0.7899999342960663;\t Test Recall - 0.6694915294647217;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.2597304582595825;\t Test AUC - 0.888379693031311;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.2215079814195633;\t Test AUC - 0.9229495525360107;\t Test F1 Score - 0.7793427012218024;\t Test Recall - 0.6535432934761047;\t Test Precision - 0.9651162624359131\n",
      "Test Loss - 0.22162488102912903;\t Test AUC - 0.9098352193832397;\t Test F1 Score - 0.8130841280737375;\t Test Recall - 0.6904761791229248;\t Test Precision - 0.9886363744735718\n",
      "Test Loss - 0.2358972132205963;\t Test AUC - 0.9156033992767334;\t Test F1 Score - 0.7692307863119969;\t Test Recall - 0.6349206566810608;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.21888884902000427;\t Test AUC - 0.9055302739143372;\t Test F1 Score - 0.7748691494849788;\t Test Recall - 0.6491228342056274;\t Test Precision - 0.9610389471054077\n",
      "Test Loss - 0.24957875907421112;\t Test AUC - 0.8893114328384399;\t Test F1 Score - 0.73224048629595;\t Test Recall - 0.5775862336158752;\t Test Precision - 1.0\n",
      "Test Loss - 0.2613089978694916;\t Test AUC - 0.8843008875846863;\t Test F1 Score - 0.7195767450690547;\t Test Recall - 0.5762711763381958;\t Test Precision - 0.9577465057373047\n",
      "Test Loss - 0.24255098402500153;\t Test AUC - 0.9154199361801147;\t Test F1 Score - 0.7787610988128987;\t Test Recall - 0.6423357725143433;\t Test Precision - 0.9887640476226807\n",
      "Test Loss - 0.2498924285173416;\t Test AUC - 0.8889826536178589;\t Test F1 Score - 0.7707317087656925;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.29412955045700073;\t Test AUC - 0.8738580942153931;\t Test F1 Score - 0.747826061528892;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9885057210922241\n",
      "Test Loss - 0.2392367571592331;\t Test AUC - 0.9216124415397644;\t Test F1 Score - 0.7792207935050727;\t Test Recall - 0.6474820375442505;\t Test Precision - 0.97826087474823\n",
      "Test Loss - 0.2808801829814911;\t Test AUC - 0.8859580755233765;\t Test F1 Score - 0.7314814793701538;\t Test Recall - 0.5808823704719543;\t Test Precision - 0.987500011920929\n",
      "Test Loss - 0.2422526329755783;\t Test AUC - 0.9029247760772705;\t Test F1 Score - 0.7661691520229942;\t Test Recall - 0.6260162591934204;\t Test Precision - 0.9871794581413269\n",
      "Test Loss - 0.2691272795200348;\t Test AUC - 0.8986155986785889;\t Test F1 Score - 0.7598253560410868;\t Test Recall - 0.6170212626457214;\t Test Precision - 0.9886363744735718\n",
      "Test Loss - 0.2598569989204407;\t Test AUC - 0.8911705017089844;\t Test F1 Score - 0.7216494511488638;\t Test Recall - 0.5737704634666443;\t Test Precision - 0.9722222089767456\n",
      "Test Loss - 0.29577359557151794;\t Test AUC - 0.9071969985961914;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 31\n",
      "Train Loss - 0.2210744172334671;\t Train AUC - 0.9434478282928467;\t Train F1 Score - 0.7818930366181395;\t Train Recall - 0.6506849527359009;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.24667048454284668;\t Train AUC - 0.9009301066398621;\t Train F1 Score - 0.7373736945654068;\t Train Recall - 0.5887096524238586;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.2397928684949875;\t Train AUC - 0.9213780164718628;\t Train F1 Score - 0.7601810528243206;\t Train Recall - 0.6222222447395325;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.20832474529743195;\t Train AUC - 0.9303027987480164;\t Train F1 Score - 0.8181818309894276;\t Train Recall - 0.692307710647583;\t Train Precision - 1.0\n",
      "Train Loss - 0.21403305232524872;\t Train AUC - 0.9323118925094604;\t Train F1 Score - 0.7982063459699493;\t Train Recall - 0.6742424368858337;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.24075450003147125;\t Train AUC - 0.9300304651260376;\t Train F1 Score - 0.8086642493594074;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9824561476707458\n",
      "Train Loss - 0.3051135241985321;\t Train AUC - 0.8883558511734009;\t Train F1 Score - 0.7085200976270151;\t Train Recall - 0.5602836608886719;\t Train Precision - 0.9634146094322205\n",
      "Train Loss - 0.2071797251701355;\t Train AUC - 0.933326780796051;\t Train F1 Score - 0.8230088570942522;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.21012377738952637;\t Train AUC - 0.9396474361419678;\t Train F1 Score - 0.7762557525966692;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.21520909667015076;\t Train AUC - 0.9353600740432739;\t Train F1 Score - 0.7834101305013381;\t Train Recall - 0.6538461446762085;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.22427459061145782;\t Train AUC - 0.9162968993186951;\t Train F1 Score - 0.8135593183952924;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.9599999785423279\n",
      "Train Loss - 0.2406885027885437;\t Train AUC - 0.916015625;\t Train F1 Score - 0.7439613205057134;\t Train Recall - 0.6015625;\t Train Precision - 0.9746835231781006\n",
      "Train Loss - 0.20197080075740814;\t Train AUC - 0.9334231019020081;\t Train F1 Score - 0.8058252406373707;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.22977188229560852;\t Train AUC - 0.9140149354934692;\t Train F1 Score - 0.8051947856421265;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.9789473414421082\n",
      "Train Loss - 0.20519626140594482;\t Train AUC - 0.9352673292160034;\t Train F1 Score - 0.8018868318175082;\t Train Recall - 0.6800000071525574;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.25991711020469666;\t Train AUC - 0.884793221950531;\t Train F1 Score - 0.708994707325495;\t Train Recall - 0.5677965879440308;\t Train Precision - 0.9436619877815247\n",
      "Train Loss - 0.20469224452972412;\t Train AUC - 0.928166925907135;\t Train F1 Score - 0.7881773417261098;\t Train Recall - 0.6896551847457886;\t Train Precision - 0.9195402264595032\n",
      "Train Loss - 0.20056122541427612;\t Train AUC - 0.940275251865387;\t Train F1 Score - 0.799999985540152;\t Train Recall - 0.682539701461792;\t Train Precision - 0.966292142868042\n",
      "Train Loss - 0.23954655230045319;\t Train AUC - 0.9196063280105591;\t Train F1 Score - 0.7866108467556326;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9591836929321289\n",
      "Train Loss - 0.19329358637332916;\t Train AUC - 0.9406343102455139;\t Train F1 Score - 0.8056872418529097;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.25069573521614075;\t Train AUC - 0.9082076549530029;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.2152692973613739;\t Train AUC - 0.9362539052963257;\t Train F1 Score - 0.7834101593877293;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.9883720874786377\n",
      "Train Loss - 0.24766647815704346;\t Train AUC - 0.9150370955467224;\t Train F1 Score - 0.7601809293037148;\t Train Recall - 0.6176470518112183;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.18851333856582642;\t Train AUC - 0.9440885782241821;\t Train F1 Score - 0.8195122082109632;\t Train Recall - 0.699999988079071;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.25063759088516235;\t Train AUC - 0.9094202518463135;\t Train F1 Score - 0.7717842286786512;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.96875\n",
      "Train Loss - 0.19891349971294403;\t Train AUC - 0.937355637550354;\t Train F1 Score - 0.8340425638964374;\t Train Recall - 0.7259259223937988;\t Train Precision - 0.9800000190734863\n",
      "Train Loss - 0.22664174437522888;\t Train AUC - 0.9252933263778687;\t Train F1 Score - 0.7913043314773847;\t Train Recall - 0.6594203114509583;\t Train Precision - 0.989130437374115\n",
      "Train Loss - 0.21587666869163513;\t Train AUC - 0.9101391434669495;\t Train F1 Score - 0.7634408861814761;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9342105388641357\n",
      "Train Loss - 0.2201407104730606;\t Train AUC - 0.9220609068870544;\t Train F1 Score - 0.8054297921502483;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9888888597488403\n",
      "Train Loss - 0.23094703257083893;\t Train AUC - 0.9382646083831787;\t Train F1 Score - 0.8185053188440449;\t Train Recall - 0.709876537322998;\t Train Precision - 0.9663865566253662\n",
      "Train Loss - 0.21577270328998566;\t Train AUC - 0.9315186738967896;\t Train F1 Score - 0.7892376835405335;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.22901886701583862;\t Train AUC - 0.9052088856697083;\t Train F1 Score - 0.7920791871613462;\t Train Recall - 0.6611570119857788;\t Train Precision - 0.9876543283462524\n",
      "Train Loss - 0.2516253888607025;\t Train AUC - 0.8813213109970093;\t Train F1 Score - 0.763819078655186;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.9743589758872986\n",
      "Train Loss - 0.21429839730262756;\t Train AUC - 0.9285306930541992;\t Train F1 Score - 0.7981651855903736;\t Train Recall - 0.6641221642494202;\t Train Precision - 1.0\n",
      "Train Loss - 0.2153089940547943;\t Train AUC - 0.922946572303772;\t Train F1 Score - 0.7870370205768632;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9239130616188049\n",
      "Train Loss - 0.2167503833770752;\t Train AUC - 0.9308978915214539;\t Train F1 Score - 0.8034934655557456;\t Train Recall - 0.6917293071746826;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.2475465089082718;\t Train AUC - 0.9177302122116089;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.23806039988994598;\t Train AUC - 0.9121171236038208;\t Train F1 Score - 0.7899159663865546;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9306930899620056\n",
      "Train Loss - 0.04861607030034065;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22210314869880676;\t Test AUC - 0.9058126211166382;\t Test F1 Score - 0.8039215459394443;\t Test Recall - 0.694915235042572;\t Test Precision - 0.9534883499145508\n",
      "Test Loss - 0.2603464126586914;\t Test AUC - 0.8877986669540405;\t Test F1 Score - 0.7547170631282487;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.22018946707248688;\t Test AUC - 0.9223752021789551;\t Test F1 Score - 0.7906976388153288;\t Test Recall - 0.6692913174629211;\t Test Precision - 0.9659090638160706\n",
      "Test Loss - 0.21417665481567383;\t Test AUC - 0.9133346676826477;\t Test F1 Score - 0.811059890681767;\t Test Recall - 0.6984127163887024;\t Test Precision - 0.9670329689979553\n",
      "Test Loss - 0.23822219669818878;\t Test AUC - 0.9091486930847168;\t Test F1 Score - 0.7692307863119969;\t Test Recall - 0.6349206566810608;\t Test Precision - 0.9756097793579102\n",
      "Test Loss - 0.21772941946983337;\t Test AUC - 0.9045827388763428;\t Test F1 Score - 0.7812499861977992;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.9615384340286255\n",
      "Test Loss - 0.23365356028079987;\t Test AUC - 0.8970593214035034;\t Test F1 Score - 0.7619047124503112;\t Test Recall - 0.6206896305084229;\t Test Precision - 0.9863013625144958\n",
      "Test Loss - 0.2574566602706909;\t Test AUC - 0.8853031396865845;\t Test F1 Score - 0.7225130649366172;\t Test Recall - 0.5847457647323608;\t Test Precision - 0.9452054500579834\n",
      "Test Loss - 0.22720825672149658;\t Test AUC - 0.9206223487854004;\t Test F1 Score - 0.8103448251329646;\t Test Recall - 0.6861313581466675;\t Test Precision - 0.9894737005233765\n",
      "Test Loss - 0.2503635585308075;\t Test AUC - 0.887261152267456;\t Test F1 Score - 0.7609756273623935;\t Test Recall - 0.6341463327407837;\t Test Precision - 0.9512194991111755\n",
      "Test Loss - 0.29800471663475037;\t Test AUC - 0.8740723729133606;\t Test F1 Score - 0.7381974350795572;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9555555582046509\n",
      "Test Loss - 0.23511527478694916;\t Test AUC - 0.9174377918243408;\t Test F1 Score - 0.7896995262201468;\t Test Recall - 0.6618704795837402;\t Test Precision - 0.978723406791687\n",
      "Test Loss - 0.27497509121894836;\t Test AUC - 0.8838504552841187;\t Test F1 Score - 0.7488583687925513;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.9879518151283264\n",
      "Test Loss - 0.24475792050361633;\t Test AUC - 0.8983314037322998;\t Test F1 Score - 0.7707317087656925;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.25645142793655396;\t Test AUC - 0.9024397730827332;\t Test F1 Score - 0.7777778104044213;\t Test Recall - 0.6453900933265686;\t Test Precision - 0.9784946441650391\n",
      "Test Loss - 0.2651316225528717;\t Test AUC - 0.8803158402442932;\t Test F1 Score - 0.7244898543156821;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9594594836235046\n",
      "Test Loss - 0.29554030299186707;\t Test AUC - 0.9111652374267578;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 32\n",
      "Train Loss - 0.21358896791934967;\t Train AUC - 0.9432215690612793;\t Train F1 Score - 0.8048780208917559;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9900000095367432\n",
      "Train Loss - 0.2459462434053421;\t Train AUC - 0.9034206867218018;\t Train F1 Score - 0.7400000455443921;\t Train Recall - 0.5967742204666138;\t Train Precision - 0.9736841917037964\n",
      "Train Loss - 0.23846831917762756;\t Train AUC - 0.9223417043685913;\t Train F1 Score - 0.7601810528243206;\t Train Recall - 0.6222222447395325;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.21209374070167542;\t Train AUC - 0.9282242059707642;\t Train F1 Score - 0.8090908838354536;\t Train Recall - 0.6846153736114502;\t Train Precision - 0.9888888597488403\n",
      "Train Loss - 0.21180053055286407;\t Train AUC - 0.933631181716919;\t Train F1 Score - 0.8053097459698839;\t Train Recall - 0.689393937587738;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.2429717779159546;\t Train AUC - 0.9328171610832214;\t Train F1 Score - 0.7985611599356318;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.9652174115180969\n",
      "Train Loss - 0.2982679307460785;\t Train AUC - 0.8868956565856934;\t Train F1 Score - 0.6968325999237617;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.1985933631658554;\t Train AUC - 0.9307345151901245;\t Train F1 Score - 0.8318583555051624;\t Train Recall - 0.7286821603775024;\t Train Precision - 0.969072163105011\n",
      "Train Loss - 0.20764486491680145;\t Train AUC - 0.9404125213623047;\t Train F1 Score - 0.7889907771545216;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9885057210922241\n",
      "Train Loss - 0.22365015745162964;\t Train AUC - 0.9275204539299011;\t Train F1 Score - 0.7834101305013381;\t Train Recall - 0.6538461446762085;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.22340741753578186;\t Train AUC - 0.9165821671485901;\t Train F1 Score - 0.8135593183952924;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.9599999785423279\n",
      "Train Loss - 0.24173416197299957;\t Train AUC - 0.9163962602615356;\t Train F1 Score - 0.7307691773088223;\t Train Recall - 0.59375;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.19867828488349915;\t Train AUC - 0.9335345029830933;\t Train F1 Score - 0.8097561141722687;\t Train Recall - 0.6803278923034668;\t Train Precision - 1.0\n",
      "Train Loss - 0.2286350578069687;\t Train AUC - 0.9194979667663574;\t Train F1 Score - 0.801724140418467;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.96875\n",
      "Train Loss - 0.2001839131116867;\t Train AUC - 0.9378694295883179;\t Train F1 Score - 0.8093023115753423;\t Train Recall - 0.6959999799728394;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.26116830110549927;\t Train AUC - 0.8822262287139893;\t Train F1 Score - 0.7195767450690547;\t Train Recall - 0.5762711763381958;\t Train Precision - 0.9577465057373047\n",
      "Train Loss - 0.20508360862731934;\t Train AUC - 0.9260918498039246;\t Train F1 Score - 0.796019899406509;\t Train Recall - 0.6896551847457886;\t Train Precision - 0.9411764740943909\n",
      "Train Loss - 0.19434212148189545;\t Train AUC - 0.9435988664627075;\t Train F1 Score - 0.8018432796032903;\t Train Recall - 0.6904761791229248;\t Train Precision - 0.9560439586639404\n",
      "Train Loss - 0.24152065813541412;\t Train AUC - 0.9229979515075684;\t Train F1 Score - 0.7796610194422026;\t Train Recall - 0.652482271194458;\t Train Precision - 0.9684210419654846\n",
      "Train Loss - 0.19473965466022491;\t Train AUC - 0.940973162651062;\t Train F1 Score - 0.7943924556949805;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9444444179534912\n",
      "Train Loss - 0.24846869707107544;\t Train AUC - 0.9099734425544739;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.21901428699493408;\t Train AUC - 0.9326974749565125;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2519325017929077;\t Train AUC - 0.9106712937355042;\t Train F1 Score - 0.7623318599210069;\t Train Recall - 0.625;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.18389002978801727;\t Train AUC - 0.9469444751739502;\t Train F1 Score - 0.8118811621758051;\t Train Recall - 0.6833333373069763;\t Train Precision - 1.0\n",
      "Train Loss - 0.24672937393188477;\t Train AUC - 0.9119439125061035;\t Train F1 Score - 0.793388464346472;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9896907210350037\n",
      "Train Loss - 0.1977301985025406;\t Train AUC - 0.9396654367446899;\t Train F1 Score - 0.8225108401872923;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9895833134651184\n",
      "Train Loss - 0.22351928055286407;\t Train AUC - 0.9285635948181152;\t Train F1 Score - 0.7965367616325436;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9892473220825195\n",
      "Train Loss - 0.2190874218940735;\t Train AUC - 0.907541811466217;\t Train F1 Score - 0.774193493174641;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9473684430122375\n",
      "Train Loss - 0.21994076669216156;\t Train AUC - 0.9248034954071045;\t Train F1 Score - 0.8054297921502483;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9888888597488403\n",
      "Train Loss - 0.2286207526922226;\t Train AUC - 0.9389199018478394;\t Train F1 Score - 0.8185053188440449;\t Train Recall - 0.709876537322998;\t Train Precision - 0.9663865566253662\n",
      "Train Loss - 0.21089640259742737;\t Train AUC - 0.9365367889404297;\t Train F1 Score - 0.7982063459699493;\t Train Recall - 0.6742424368858337;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.23482152819633484;\t Train AUC - 0.9057178497314453;\t Train F1 Score - 0.7799999503285474;\t Train Recall - 0.64462810754776;\t Train Precision - 0.9873417615890503\n",
      "Train Loss - 0.2509734034538269;\t Train AUC - 0.8823565244674683;\t Train F1 Score - 0.7614213525637972;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9868420958518982\n",
      "Train Loss - 0.2136673778295517;\t Train AUC - 0.9280993938446045;\t Train F1 Score - 0.8090909271594915;\t Train Recall - 0.6793892979621887;\t Train Precision - 1.0\n",
      "Train Loss - 0.21094109117984772;\t Train AUC - 0.9262164831161499;\t Train F1 Score - 0.7943924556949805;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9444444179534912\n",
      "Train Loss - 0.2167469561100006;\t Train AUC - 0.9327656030654907;\t Train F1 Score - 0.7965367775466955;\t Train Recall - 0.6917293071746826;\t Train Precision - 0.9387755393981934\n",
      "Train Loss - 0.24611206352710724;\t Train AUC - 0.9194753170013428;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.2437884509563446;\t Train AUC - 0.9133152365684509;\t Train F1 Score - 0.7777777695116399;\t Train Recall - 0.6642335653305054;\t Train Precision - 0.938144326210022\n",
      "Train Loss - 0.04228515177965164;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.24868439137935638;\t Test AUC - 0.8923710584640503;\t Test F1 Score - 0.7422680593850635;\t Test Recall - 0.6101694703102112;\t Test Precision - 0.9473684430122375\n",
      "Test Loss - 0.28394296765327454;\t Test AUC - 0.8781341910362244;\t Test F1 Score - 0.7121951113430083;\t Test Recall - 0.5615384578704834;\t Test Precision - 0.9733333587646484\n",
      "Test Loss - 0.25284844636917114;\t Test AUC - 0.9089077711105347;\t Test F1 Score - 0.7192118004760671;\t Test Recall - 0.5748031735420227;\t Test Precision - 0.9605262875556946\n",
      "Test Loss - 0.234852135181427;\t Test AUC - 0.9057581424713135;\t Test F1 Score - 0.7772512299480393;\t Test Recall - 0.6507936716079712;\t Test Precision - 0.9647058844566345\n",
      "Test Loss - 0.2531184256076813;\t Test AUC - 0.9031544923782349;\t Test F1 Score - 0.7450980332888723;\t Test Recall - 0.60317462682724;\t Test Precision - 0.9743589758872986\n",
      "Test Loss - 0.21749147772789001;\t Test AUC - 0.9063786268234253;\t Test F1 Score - 0.7684210541992628;\t Test Recall - 0.640350878238678;\t Test Precision - 0.9605262875556946\n",
      "Test Loss - 0.24544578790664673;\t Test AUC - 0.8974334001541138;\t Test F1 Score - 0.741935503334981;\t Test Recall - 0.5948275923728943;\t Test Precision - 0.9857142567634583\n",
      "Test Loss - 0.28945526480674744;\t Test AUC - 0.8640111684799194;\t Test F1 Score - 0.6666666939692207;\t Test Recall - 0.5169491767883301;\t Test Precision - 0.9384615421295166\n",
      "Test Loss - 0.23799875378608704;\t Test AUC - 0.917926549911499;\t Test F1 Score - 0.784140978778072;\t Test Recall - 0.6496350169181824;\t Test Precision - 0.9888888597488403\n",
      "Test Loss - 0.2786775231361389;\t Test AUC - 0.8700039386749268;\t Test F1 Score - 0.7272726711710169;\t Test Recall - 0.5853658318519592;\t Test Precision - 0.9599999785423279\n",
      "Test Loss - 0.30698978900909424;\t Test AUC - 0.872128963470459;\t Test F1 Score - 0.7136563825190778;\t Test Recall - 0.5664335489273071;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.2681393623352051;\t Test AUC - 0.9032912850379944;\t Test F1 Score - 0.7500000187135651;\t Test Recall - 0.6043165326118469;\t Test Precision - 0.9882352948188782\n",
      "Test Loss - 0.2945224642753601;\t Test AUC - 0.8792707324028015;\t Test F1 Score - 0.7102804101648772;\t Test Recall - 0.5588235259056091;\t Test Precision - 0.9743589758872986\n",
      "Test Loss - 0.261734277009964;\t Test AUC - 0.8960815668106079;\t Test F1 Score - 0.7272726711710169;\t Test Recall - 0.5853658318519592;\t Test Precision - 0.9599999785423279\n",
      "Test Loss - 0.2798217535018921;\t Test AUC - 0.8989169001579285;\t Test F1 Score - 0.7264573802835128;\t Test Recall - 0.5744680762290955;\t Test Precision - 0.9878048896789551\n",
      "Test Loss - 0.29275426268577576;\t Test AUC - 0.8735681176185608;\t Test F1 Score - 0.6559139784946236;\t Test Recall - 0.5;\t Test Precision - 0.953125\n",
      "Test Loss - 0.2984699606895447;\t Test AUC - 0.9186508059501648;\t Test F1 Score - 0.6666666666666666;\t Test Recall - 0.5;\t Test Precision - 1.0\n",
      "Epoch - 33\n",
      "Train Loss - 0.2267465740442276;\t Train AUC - 0.9434026479721069;\t Train F1 Score - 0.7818930366181395;\t Train Recall - 0.6506849527359009;\t Train Precision - 0.9793814420700073\n",
      "Train Loss - 0.2607980966567993;\t Train AUC - 0.8904852867126465;\t Train F1 Score - 0.7150259388799202;\t Train Recall - 0.5564516186714172;\t Train Precision - 1.0\n",
      "Train Loss - 0.2516101002693176;\t Train AUC - 0.9182476997375488;\t Train F1 Score - 0.7373271906916249;\t Train Recall - 0.5925925970077515;\t Train Precision - 0.9756097793579102\n",
      "Train Loss - 0.23294603824615479;\t Train AUC - 0.9160065054893494;\t Train F1 Score - 0.7777777288080614;\t Train Recall - 0.6461538672447205;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2371918261051178;\t Train AUC - 0.9173060655593872;\t Train F1 Score - 0.7671233223318239;\t Train Recall - 0.6363636255264282;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.25726714730262756;\t Train AUC - 0.9284862279891968;\t Train F1 Score - 0.7732342023856599;\t Train Recall - 0.6380367875099182;\t Train Precision - 0.9811320900917053\n",
      "Train Loss - 0.28683772683143616;\t Train AUC - 0.8908048272132874;\t Train F1 Score - 0.7174888218041763;\t Train Recall - 0.567375898361206;\t Train Precision - 0.9756097793579102\n",
      "Train Loss - 0.21977590024471283;\t Train AUC - 0.9315574765205383;\t Train F1 Score - 0.8296943330217913;\t Train Recall - 0.7364341020584106;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.24399404227733612;\t Train AUC - 0.935261070728302;\t Train F1 Score - 0.7753304344961178;\t Train Recall - 0.6717557311058044;\t Train Precision - 0.9166666865348816\n",
      "Train Loss - 0.2514001429080963;\t Train AUC - 0.9318330883979797;\t Train F1 Score - 0.7894736725244206;\t Train Recall - 0.692307710647583;\t Train Precision - 0.918367326259613\n",
      "Train Loss - 0.23045849800109863;\t Train AUC - 0.9162889719009399;\t Train F1 Score - 0.8049792434430135;\t Train Recall - 0.7132353186607361;\t Train Precision - 0.9238095283508301\n",
      "Train Loss - 0.2370242327451706;\t Train AUC - 0.9170998334884644;\t Train F1 Score - 0.7523809394517799;\t Train Recall - 0.6171875;\t Train Precision - 0.9634146094322205\n",
      "Train Loss - 0.210235133767128;\t Train AUC - 0.925723671913147;\t Train F1 Score - 0.7941176088501316;\t Train Recall - 0.6639344096183777;\t Train Precision - 0.9878048896789551\n",
      "Train Loss - 0.235359326004982;\t Train AUC - 0.9133176803588867;\t Train F1 Score - 0.7894736497796262;\t Train Recall - 0.6617646813392639;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.21320132911205292;\t Train AUC - 0.9274274110794067;\t Train F1 Score - 0.778846157375437;\t Train Recall - 0.6480000019073486;\t Train Precision - 0.9759036302566528\n",
      "Train Loss - 0.28880545496940613;\t Train AUC - 0.8598442077636719;\t Train F1 Score - 0.6885246122660035;\t Train Recall - 0.5338982939720154;\t Train Precision - 0.9692307710647583\n",
      "Train Loss - 0.22328875958919525;\t Train AUC - 0.9178006649017334;\t Train F1 Score - 0.755102047042686;\t Train Recall - 0.6379310488700867;\t Train Precision - 0.925000011920929\n",
      "Train Loss - 0.21867230534553528;\t Train AUC - 0.9292411804199219;\t Train F1 Score - 0.7655502670617305;\t Train Recall - 0.6349206566810608;\t Train Precision - 0.9638554453849792\n",
      "Train Loss - 0.26990416646003723;\t Train AUC - 0.9082727432250977;\t Train F1 Score - 0.7423581044857384;\t Train Recall - 0.6028369069099426;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.19885312020778656;\t Train AUC - 0.9409562349319458;\t Train F1 Score - 0.7924528081369108;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.2533445358276367;\t Train AUC - 0.9029707908630371;\t Train F1 Score - 0.7918367198501088;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9700000286102295\n",
      "Train Loss - 0.2195318639278412;\t Train AUC - 0.9318674206733704;\t Train F1 Score - 0.7741935555172754;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2599707543849945;\t Train AUC - 0.9129691123962402;\t Train F1 Score - 0.7577092674144152;\t Train Recall - 0.6323529481887817;\t Train Precision - 0.9450549483299255\n",
      "Train Loss - 0.19502879679203033;\t Train AUC - 0.9418142437934875;\t Train F1 Score - 0.8155339108673318;\t Train Recall - 0.699999988079071;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.24823008477687836;\t Train AUC - 0.9100795984268188;\t Train F1 Score - 0.7918367198501088;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9700000286102295\n",
      "Train Loss - 0.19867821037769318;\t Train AUC - 0.9394185543060303;\t Train F1 Score - 0.8173912883600787;\t Train Recall - 0.6962962746620178;\t Train Precision - 0.9894737005233765\n",
      "Train Loss - 0.2262481153011322;\t Train AUC - 0.9310104250907898;\t Train F1 Score - 0.7894736728179493;\t Train Recall - 0.6521739363670349;\t Train Precision - 1.0\n",
      "Train Loss - 0.21975140273571014;\t Train AUC - 0.9134044647216797;\t Train F1 Score - 0.7582416937999078;\t Train Recall - 0.6272727251052856;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.22175191342830658;\t Train AUC - 0.925153374671936;\t Train F1 Score - 0.8;\t Train Recall - 0.6717557311058044;\t Train Precision - 0.9887640476226807\n",
      "Train Loss - 0.2294764667749405;\t Train AUC - 0.9407590627670288;\t Train F1 Score - 0.8172042842701475;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9743589758872986\n",
      "Train Loss - 0.2159181535243988;\t Train AUC - 0.9304503202438354;\t Train F1 Score - 0.7927928319777304;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.2389989197254181;\t Train AUC - 0.9021118879318237;\t Train F1 Score - 0.7586206818272622;\t Train Recall - 0.6363636255264282;\t Train Precision - 0.9390243887901306\n",
      "Train Loss - 0.24910913407802582;\t Train AUC - 0.8827964663505554;\t Train F1 Score - 0.7614213525637972;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9868420958518982\n",
      "Train Loss - 0.21551279723644257;\t Train AUC - 0.930898904800415;\t Train F1 Score - 0.7926267194880579;\t Train Recall - 0.6564885377883911;\t Train Precision - 1.0\n",
      "Train Loss - 0.21245183050632477;\t Train AUC - 0.9261147975921631;\t Train F1 Score - 0.7846890488858195;\t Train Recall - 0.6612903475761414;\t Train Precision - 0.9647058844566345\n",
      "Train Loss - 0.21712489426136017;\t Train AUC - 0.9332243800163269;\t Train F1 Score - 0.7929515351016052;\t Train Recall - 0.6766917109489441;\t Train Precision - 0.957446813583374\n",
      "Train Loss - 0.24462880194187164;\t Train AUC - 0.9209745526313782;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.23356710374355316;\t Train AUC - 0.9155697226524353;\t Train F1 Score - 0.7899159663865546;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9306930899620056\n",
      "Train Loss - 0.04434556886553764;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.23004287481307983;\t Test AUC - 0.8962568044662476;\t Test F1 Score - 0.7884614727998713;\t Test Recall - 0.694915235042572;\t Test Precision - 0.9111111164093018\n",
      "Test Loss - 0.26933592557907104;\t Test AUC - 0.8863174915313721;\t Test F1 Score - 0.7420814331745659;\t Test Recall - 0.6307692527770996;\t Test Precision - 0.901098906993866\n",
      "Test Loss - 0.22224830090999603;\t Test AUC - 0.9242063760757446;\t Test F1 Score - 0.7853881082680076;\t Test Recall - 0.6771653294563293;\t Test Precision - 0.9347826242446899\n",
      "Test Loss - 0.21536797285079956;\t Test AUC - 0.9178973436355591;\t Test F1 Score - 0.8071748693367776;\t Test Recall - 0.7142857313156128;\t Test Precision - 0.9278350472450256\n",
      "Test Loss - 0.23446691036224365;\t Test AUC - 0.9171689748764038;\t Test F1 Score - 0.7735848930422176;\t Test Recall - 0.6507936716079712;\t Test Precision - 0.9534883499145508\n",
      "Test Loss - 0.22556543350219727;\t Test AUC - 0.9094740152359009;\t Test F1 Score - 0.7638191135163671;\t Test Recall - 0.6666666865348816;\t Test Precision - 0.8941176533699036\n",
      "Test Loss - 0.23426249623298645;\t Test AUC - 0.8974334001541138;\t Test F1 Score - 0.7604167385245142;\t Test Recall - 0.6293103694915771;\t Test Precision - 0.9605262875556946\n",
      "Test Loss - 0.25821760296821594;\t Test AUC - 0.8867976665496826;\t Test F1 Score - 0.7346938838979263;\t Test Recall - 0.6101694703102112;\t Test Precision - 0.9230769276618958\n",
      "Test Loss - 0.23702535033226013;\t Test AUC - 0.9184311032295227;\t Test F1 Score - 0.7983193203743465;\t Test Recall - 0.6934306621551514;\t Test Precision - 0.9405940771102905\n",
      "Test Loss - 0.24947789311408997;\t Test AUC - 0.8909853100776672;\t Test F1 Score - 0.7632850448942468;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9404761791229248\n",
      "Test Loss - 0.29219532012939453;\t Test AUC - 0.8806291818618774;\t Test F1 Score - 0.7319148790874612;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9347826242446899\n",
      "Test Loss - 0.23059722781181335;\t Test AUC - 0.9191388487815857;\t Test F1 Score - 0.8101265985405878;\t Test Recall - 0.6906474828720093;\t Test Precision - 0.9795918464660645\n",
      "Test Loss - 0.2754165530204773;\t Test AUC - 0.8880181908607483;\t Test F1 Score - 0.7410714806430572;\t Test Recall - 0.6102941036224365;\t Test Precision - 0.9431818127632141\n",
      "Test Loss - 0.2517721951007843;\t Test AUC - 0.8995670676231384;\t Test F1 Score - 0.7559808517430626;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9186046719551086\n",
      "Test Loss - 0.2595054507255554;\t Test AUC - 0.9039153456687927;\t Test F1 Score - 0.7627118618583286;\t Test Recall - 0.6382978558540344;\t Test Precision - 0.9473684430122375\n",
      "Test Loss - 0.26135584712028503;\t Test AUC - 0.8903560042381287;\t Test F1 Score - 0.7200000409642867;\t Test Recall - 0.5901639461517334;\t Test Precision - 0.9230769276618958\n",
      "Test Loss - 0.29017966985702515;\t Test AUC - 0.9071969389915466;\t Test F1 Score - 0.6769230818786948;\t Test Recall - 0.523809552192688;\t Test Precision - 0.95652174949646\n",
      "Epoch - 34\n",
      "Train Loss - 0.21607579290866852;\t Train AUC - 0.9421806335449219;\t Train F1 Score - 0.8031496234376165;\t Train Recall - 0.698630154132843;\t Train Precision - 0.9444444179534912\n",
      "Train Loss - 0.2498701959848404;\t Train AUC - 0.9042593240737915;\t Train F1 Score - 0.7389162319760103;\t Train Recall - 0.6048387289047241;\t Train Precision - 0.949367105960846\n",
      "Train Loss - 0.2369532734155655;\t Train AUC - 0.9257665872573853;\t Train F1 Score - 0.7522123765621535;\t Train Recall - 0.6296296119689941;\t Train Precision - 0.9340659379959106\n",
      "Train Loss - 0.20810256898403168;\t Train AUC - 0.9305155277252197;\t Train F1 Score - 0.8108108146680277;\t Train Recall - 0.692307710647583;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.209983691573143;\t Train AUC - 0.9347724318504333;\t Train F1 Score - 0.8035714696053757;\t Train Recall - 0.6818181872367859;\t Train Precision - 0.97826087474823\n",
      "Train Loss - 0.241974338889122;\t Train AUC - 0.9344387054443359;\t Train F1 Score - 0.7985611599356318;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.9652174115180969\n",
      "Train Loss - 0.2888093590736389;\t Train AUC - 0.8970858454704285;\t Train F1 Score - 0.7058823345866421;\t Train Recall - 0.5531914830207825;\t Train Precision - 0.9750000238418579\n",
      "Train Loss - 0.19199880957603455;\t Train AUC - 0.9348244667053223;\t Train F1 Score - 0.8430493205510675;\t Train Recall - 0.7286821603775024;\t Train Precision - 1.0\n",
      "Train Loss - 0.20738618075847626;\t Train AUC - 0.9398590326309204;\t Train F1 Score - 0.7927927783753963;\t Train Recall - 0.6717557311058044;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.2153080701828003;\t Train AUC - 0.9329296350479126;\t Train F1 Score - 0.781818183158513;\t Train Recall - 0.6615384817123413;\t Train Precision - 0.9555555582046509\n",
      "Train Loss - 0.21822839975357056;\t Train AUC - 0.9211539030075073;\t Train F1 Score - 0.818565387019053;\t Train Recall - 0.7132353186607361;\t Train Precision - 0.9603960514068604\n",
      "Train Loss - 0.24049772322177887;\t Train AUC - 0.915833592414856;\t Train F1 Score - 0.7476636173069382;\t Train Recall - 0.625;\t Train Precision - 0.930232584476471\n",
      "Train Loss - 0.1941566914319992;\t Train AUC - 0.9360296130180359;\t Train F1 Score - 0.8155339901785967;\t Train Recall - 0.688524603843689;\t Train Precision - 1.0\n",
      "Train Loss - 0.2296605408191681;\t Train AUC - 0.9178341031074524;\t Train F1 Score - 0.798283244359865;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.9587628841400146\n",
      "Train Loss - 0.20177775621414185;\t Train AUC - 0.9371200203895569;\t Train F1 Score - 0.8075118187571049;\t Train Recall - 0.6880000233650208;\t Train Precision - 0.9772727489471436\n",
      "Train Loss - 0.2635572850704193;\t Train AUC - 0.8828327655792236;\t Train F1 Score - 0.708994707325495;\t Train Recall - 0.5677965879440308;\t Train Precision - 0.9436619877815247\n",
      "Train Loss - 0.20337575674057007;\t Train AUC - 0.9326108694076538;\t Train F1 Score - 0.7941176362288684;\t Train Recall - 0.6982758641242981;\t Train Precision - 0.9204545617103577\n",
      "Train Loss - 0.19404788315296173;\t Train AUC - 0.9458257555961609;\t Train F1 Score - 0.8036529746559915;\t Train Recall - 0.6984127163887024;\t Train Precision - 0.9462365508079529\n",
      "Train Loss - 0.23306497931480408;\t Train AUC - 0.9275637269020081;\t Train F1 Score - 0.7932489420915207;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.19796906411647797;\t Train AUC - 0.9375592470169067;\t Train F1 Score - 0.7943924556949805;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9444444179534912\n",
      "Train Loss - 0.2462042272090912;\t Train AUC - 0.9105191230773926;\t Train F1 Score - 0.7935222666167001;\t Train Recall - 0.6758620738983154;\t Train Precision - 0.9607843160629272\n",
      "Train Loss - 0.21926602721214294;\t Train AUC - 0.9331694841384888;\t Train F1 Score - 0.7685185294874601;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.24491561949253082;\t Train AUC - 0.913048267364502;\t Train F1 Score - 0.7733333716634889;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.18179364502429962;\t Train AUC - 0.9492968916893005;\t Train F1 Score - 0.8078817491545502;\t Train Recall - 0.6833333373069763;\t Train Precision - 0.9879518151283264\n",
      "Train Loss - 0.24583284556865692;\t Train AUC - 0.9108525514602661;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.19415955245494843;\t Train AUC - 0.9422460794448853;\t Train F1 Score - 0.8260869839015675;\t Train Recall - 0.7037037014961243;\t Train Precision - 1.0\n",
      "Train Loss - 0.22351470589637756;\t Train AUC - 0.9295673966407776;\t Train F1 Score - 0.794759869559589;\t Train Recall - 0.6594203114509583;\t Train Precision - 1.0\n",
      "Train Loss - 0.21681660413742065;\t Train AUC - 0.9099814891815186;\t Train F1 Score - 0.774193493174641;\t Train Recall - 0.6545454263687134;\t Train Precision - 0.9473684430122375\n",
      "Train Loss - 0.2189999371767044;\t Train AUC - 0.925788164138794;\t Train F1 Score - 0.8088888598924813;\t Train Recall - 0.694656491279602;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.2295590490102768;\t Train AUC - 0.939420223236084;\t Train F1 Score - 0.8185053188440449;\t Train Recall - 0.709876537322998;\t Train Precision - 0.9663865566253662\n",
      "Train Loss - 0.21086768805980682;\t Train AUC - 0.9352499842643738;\t Train F1 Score - 0.8071749211664926;\t Train Recall - 0.6818181872367859;\t Train Precision - 0.9890109896659851\n",
      "Train Loss - 0.23379261791706085;\t Train AUC - 0.9039579033851624;\t Train F1 Score - 0.7761194150691285;\t Train Recall - 0.64462810754776;\t Train Precision - 0.9750000238418579\n",
      "Train Loss - 0.2517867386341095;\t Train AUC - 0.8831760883331299;\t Train F1 Score - 0.7575757621086542;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9740259647369385\n",
      "Train Loss - 0.21550722420215607;\t Train AUC - 0.9288400411605835;\t Train F1 Score - 0.8036529436160376;\t Train Recall - 0.6717557311058044;\t Train Precision - 1.0\n",
      "Train Loss - 0.21156896650791168;\t Train AUC - 0.9266231060028076;\t Train F1 Score - 0.7924528081369108;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.9545454382896423\n",
      "Train Loss - 0.20902717113494873;\t Train AUC - 0.9365812540054321;\t Train F1 Score - 0.8017621348786403;\t Train Recall - 0.6842105388641357;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.2440081238746643;\t Train AUC - 0.9205363392829895;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.23217344284057617;\t Train AUC - 0.9163421988487244;\t Train F1 Score - 0.7932489884522943;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9399999976158142\n",
      "Train Loss - 0.03894639015197754;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22020792961120605;\t Test AUC - 0.9034127593040466;\t Test F1 Score - 0.8039215459394443;\t Test Recall - 0.694915235042572;\t Test Precision - 0.9534883499145508\n",
      "Test Loss - 0.2608060836791992;\t Test AUC - 0.8885433673858643;\t Test F1 Score - 0.7605634023326686;\t Test Recall - 0.6230769157409668;\t Test Precision - 0.9759036302566528\n",
      "Test Loss - 0.2210446149110794;\t Test AUC - 0.9213014841079712;\t Test F1 Score - 0.7906976388153288;\t Test Recall - 0.6692913174629211;\t Test Precision - 0.9659090638160706\n",
      "Test Loss - 0.217800110578537;\t Test AUC - 0.9117523431777954;\t Test F1 Score - 0.8073394918356769;\t Test Recall - 0.6984127163887024;\t Test Precision - 0.95652174949646\n",
      "Test Loss - 0.2316276580095291;\t Test AUC - 0.9168592095375061;\t Test F1 Score - 0.7788461482227043;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9878048896789551\n",
      "Test Loss - 0.21754008531570435;\t Test AUC - 0.9048444032669067;\t Test F1 Score - 0.7812499861977992;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.9615384340286255\n",
      "Test Loss - 0.23545365035533905;\t Test AUC - 0.8970504999160767;\t Test F1 Score - 0.7619047124503112;\t Test Recall - 0.6206896305084229;\t Test Precision - 0.9863013625144958\n",
      "Test Loss - 0.2548328638076782;\t Test AUC - 0.8852239847183228;\t Test F1 Score - 0.7291666892564141;\t Test Recall - 0.5932203531265259;\t Test Precision - 0.9459459185600281\n",
      "Test Loss - 0.2317524403333664;\t Test AUC - 0.915711522102356;\t Test F1 Score - 0.8051947773532095;\t Test Recall - 0.6788321137428284;\t Test Precision - 0.9893617033958435\n",
      "Test Loss - 0.24920593202114105;\t Test AUC - 0.8868265748023987;\t Test F1 Score - 0.7707317087656925;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9634146094322205\n",
      "Test Loss - 0.28823497891426086;\t Test AUC - 0.8801472187042236;\t Test F1 Score - 0.7445887612603174;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9772727489471436\n",
      "Test Loss - 0.23422695696353912;\t Test AUC - 0.9197162389755249;\t Test F1 Score - 0.7948717670505641;\t Test Recall - 0.6690647602081299;\t Test Precision - 0.9789473414421082\n",
      "Test Loss - 0.2772025167942047;\t Test AUC - 0.8860135674476624;\t Test F1 Score - 0.7454544960426418;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.976190447807312\n",
      "Test Loss - 0.24593554437160492;\t Test AUC - 0.9007346630096436;\t Test F1 Score - 0.7647058516185528;\t Test Recall - 0.6341463327407837;\t Test Precision - 0.9629629850387573\n",
      "Test Loss - 0.25984615087509155;\t Test AUC - 0.9009332656860352;\t Test F1 Score - 0.7619048079729488;\t Test Recall - 0.6241135001182556;\t Test Precision - 0.9777777791023254\n",
      "Test Loss - 0.2612565755844116;\t Test AUC - 0.8864634037017822;\t Test F1 Score - 0.7244898543156821;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9594594836235046\n",
      "Test Loss - 0.2902705669403076;\t Test AUC - 0.9157647490501404;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 35\n",
      "Train Loss - 0.21115432679653168;\t Train AUC - 0.944926381111145;\t Train F1 Score - 0.8016194340715057;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9801980257034302\n",
      "Train Loss - 0.2448178082704544;\t Train AUC - 0.9014722108840942;\t Train F1 Score - 0.7373736945654068;\t Train Recall - 0.5887096524238586;\t Train Precision - 0.9864864945411682\n",
      "Train Loss - 0.23367436230182648;\t Train AUC - 0.925225019454956;\t Train F1 Score - 0.7601810528243206;\t Train Recall - 0.6222222447395325;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.204689159989357;\t Train AUC - 0.931988537311554;\t Train F1 Score - 0.8181818309894276;\t Train Recall - 0.692307710647583;\t Train Precision - 1.0\n",
      "Train Loss - 0.21013455092906952;\t Train AUC - 0.934699535369873;\t Train F1 Score - 0.8053097459698839;\t Train Recall - 0.689393937587738;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.2375372052192688;\t Train AUC - 0.9331120252609253;\t Train F1 Score - 0.8115941926041764;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.991150438785553\n",
      "Train Loss - 0.2862161695957184;\t Train AUC - 0.8967613577842712;\t Train F1 Score - 0.7000000235160381;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9746835231781006\n",
      "Train Loss - 0.197352796792984;\t Train AUC - 0.9332773685455322;\t Train F1 Score - 0.8347826142007718;\t Train Recall - 0.7441860437393188;\t Train Precision - 0.9504950642585754\n",
      "Train Loss - 0.20820128917694092;\t Train AUC - 0.9387359619140625;\t Train F1 Score - 0.7853881321852059;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9772727489471436\n",
      "Train Loss - 0.21025973558425903;\t Train AUC - 0.9376922845840454;\t Train F1 Score - 0.7741935698611735;\t Train Recall - 0.6461538672447205;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.22005051374435425;\t Train AUC - 0.920702338218689;\t Train F1 Score - 0.8101266086978051;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.9504950642585754\n",
      "Train Loss - 0.23205119371414185;\t Train AUC - 0.9207494258880615;\t Train F1 Score - 0.7523809394517799;\t Train Recall - 0.6171875;\t Train Precision - 0.9634146094322205\n",
      "Train Loss - 0.19240738451480865;\t Train AUC - 0.937444269657135;\t Train F1 Score - 0.8151658801578728;\t Train Recall - 0.7049180269241333;\t Train Precision - 0.966292142868042\n",
      "Train Loss - 0.23009872436523438;\t Train AUC - 0.917461633682251;\t Train F1 Score - 0.7931034658771513;\t Train Recall - 0.6764705777168274;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.19889011979103088;\t Train AUC - 0.9382147192955017;\t Train F1 Score - 0.8186046927034697;\t Train Recall - 0.7039999961853027;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.25931957364082336;\t Train AUC - 0.885610818862915;\t Train F1 Score - 0.708994707325495;\t Train Recall - 0.5677965879440308;\t Train Precision - 0.9436619877815247\n",
      "Train Loss - 0.2016284465789795;\t Train AUC - 0.9329937100410461;\t Train F1 Score - 0.7941176362288684;\t Train Recall - 0.6982758641242981;\t Train Precision - 0.9204545617103577\n",
      "Train Loss - 0.1893864870071411;\t Train AUC - 0.9465625286102295;\t Train F1 Score - 0.812785393691177;\t Train Recall - 0.7063491940498352;\t Train Precision - 0.9569892287254333\n",
      "Train Loss - 0.2332315891981125;\t Train AUC - 0.9273397326469421;\t Train F1 Score - 0.7899159804722082;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.969072163105011\n",
      "Train Loss - 0.19513307511806488;\t Train AUC - 0.9397193789482117;\t Train F1 Score - 0.8093023202296311;\t Train Recall - 0.7016128897666931;\t Train Precision - 0.9560439586639404\n",
      "Train Loss - 0.24792052805423737;\t Train AUC - 0.9130352735519409;\t Train F1 Score - 0.7901234666514272;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.2154725342988968;\t Train AUC - 0.9351714253425598;\t Train F1 Score - 0.7777777290051637;\t Train Recall - 0.6412213444709778;\t Train Precision - 0.9882352948188782\n",
      "Train Loss - 0.24248932301998138;\t Train AUC - 0.9154332876205444;\t Train F1 Score - 0.7767857227831861;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.1867656260728836;\t Train AUC - 0.9464148879051208;\t Train F1 Score - 0.8097560627012117;\t Train Recall - 0.6916666626930237;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.2500781714916229;\t Train AUC - 0.9061387181282043;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.19765761494636536;\t Train AUC - 0.9374671578407288;\t Train F1 Score - 0.8260869839015675;\t Train Recall - 0.7037037014961243;\t Train Precision - 1.0\n",
      "Train Loss - 0.22466933727264404;\t Train AUC - 0.9270734786987305;\t Train F1 Score - 0.799999985694886;\t Train Recall - 0.6666666865348816;\t Train Precision - 1.0\n",
      "Train Loss - 0.22092419862747192;\t Train AUC - 0.9065120816230774;\t Train F1 Score - 0.7717391837209465;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9594594836235046\n",
      "Train Loss - 0.21972322463989258;\t Train AUC - 0.9282702803611755;\t Train F1 Score - 0.796460215073841;\t Train Recall - 0.6870229244232178;\t Train Precision - 0.9473684430122375\n",
      "Train Loss - 0.22702515125274658;\t Train AUC - 0.9409564137458801;\t Train F1 Score - 0.8172042842701475;\t Train Recall - 0.7037037014961243;\t Train Precision - 0.9743589758872986\n",
      "Train Loss - 0.20815697312355042;\t Train AUC - 0.9376457333564758;\t Train F1 Score - 0.8071749211664926;\t Train Recall - 0.6818181872367859;\t Train Precision - 0.9890109896659851\n",
      "Train Loss - 0.23323138058185577;\t Train AUC - 0.9045963883399963;\t Train F1 Score - 0.7684729295865971;\t Train Recall - 0.64462810754776;\t Train Precision - 0.9512194991111755\n",
      "Train Loss - 0.25400224328041077;\t Train AUC - 0.8810883164405823;\t Train F1 Score - 0.7499999810079737;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.949367105960846\n",
      "Train Loss - 0.21343857049942017;\t Train AUC - 0.9295154809951782;\t Train F1 Score - 0.8090909271594915;\t Train Recall - 0.6793892979621887;\t Train Precision - 1.0\n",
      "Train Loss - 0.2099326103925705;\t Train AUC - 0.9264620542526245;\t Train F1 Score - 0.8018867979009142;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.20789052546024323;\t Train AUC - 0.9375473260879517;\t Train F1 Score - 0.8017621348786403;\t Train Recall - 0.6842105388641357;\t Train Precision - 0.9680851101875305\n",
      "Train Loss - 0.24452781677246094;\t Train AUC - 0.9196444749832153;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.23179122805595398;\t Train AUC - 0.9175876379013062;\t Train F1 Score - 0.7932489884522943;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9399999976158142\n",
      "Train Loss - 0.03950214385986328;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22244033217430115;\t Test AUC - 0.8993160724639893;\t Test F1 Score - 0.8078817627838591;\t Test Recall - 0.694915235042572;\t Test Precision - 0.9647058844566345\n",
      "Test Loss - 0.25731945037841797;\t Test AUC - 0.89029461145401;\t Test F1 Score - 0.7605634023326686;\t Test Recall - 0.6230769157409668;\t Test Precision - 0.9759036302566528\n",
      "Test Loss - 0.22426478564739227;\t Test AUC - 0.9204108715057373;\t Test F1 Score - 0.7906976388153288;\t Test Recall - 0.6692913174629211;\t Test Precision - 0.9659090638160706\n",
      "Test Loss - 0.21534527838230133;\t Test AUC - 0.9136025905609131;\t Test F1 Score - 0.812785393691177;\t Test Recall - 0.7063491940498352;\t Test Precision - 0.9569892287254333\n",
      "Test Loss - 0.2311956286430359;\t Test AUC - 0.9191865921020508;\t Test F1 Score - 0.7788461482227043;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9878048896789551\n",
      "Test Loss - 0.2181480973958969;\t Test AUC - 0.9046096801757812;\t Test F1 Score - 0.7772020271919031;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.949367105960846\n",
      "Test Loss - 0.23607902228832245;\t Test AUC - 0.8969613909721375;\t Test F1 Score - 0.7619047124503112;\t Test Recall - 0.6206896305084229;\t Test Precision - 0.9863013625144958\n",
      "Test Loss - 0.2571699023246765;\t Test AUC - 0.884731650352478;\t Test F1 Score - 0.7291666892564141;\t Test Recall - 0.5932203531265259;\t Test Precision - 0.9459459185600281\n",
      "Test Loss - 0.2319190502166748;\t Test AUC - 0.914142906665802;\t Test F1 Score - 0.8017241193338751;\t Test Recall - 0.6788321137428284;\t Test Precision - 0.9789473414421082\n",
      "Test Loss - 0.24303731322288513;\t Test AUC - 0.8955191373825073;\t Test F1 Score - 0.7669902847277571;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9518072009086609\n",
      "Test Loss - 0.2892228662967682;\t Test AUC - 0.8846383094787598;\t Test F1 Score - 0.7381974350795572;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9555555582046509\n",
      "Test Loss - 0.23457174003124237;\t Test AUC - 0.9199347496032715;\t Test F1 Score - 0.7948717670505641;\t Test Recall - 0.6690647602081299;\t Test Precision - 0.9789473414421082\n",
      "Test Loss - 0.27715611457824707;\t Test AUC - 0.8842862844467163;\t Test F1 Score - 0.7488583687925513;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.9879518151283264\n",
      "Test Loss - 0.2504028379917145;\t Test AUC - 0.9012715220451355;\t Test F1 Score - 0.7647058516185528;\t Test Recall - 0.6341463327407837;\t Test Precision - 0.9629629850387573\n",
      "Test Loss - 0.2635986804962158;\t Test AUC - 0.8970009088516235;\t Test F1 Score - 0.7652174112281647;\t Test Recall - 0.6241135001182556;\t Test Precision - 0.9887640476226807\n",
      "Test Loss - 0.25710374116897583;\t Test AUC - 0.8932968974113464;\t Test F1 Score - 0.7244898543156821;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9594594836235046\n",
      "Test Loss - 0.29667091369628906;\t Test AUC - 0.9079184532165527;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 36\n",
      "Train Loss - 0.21329668164253235;\t Train AUC - 0.9441720247268677;\t Train F1 Score - 0.8112450102645985;\t Train Recall - 0.6917808055877686;\t Train Precision - 0.9805825352668762\n",
      "Train Loss - 0.2455938756465912;\t Train AUC - 0.9002186059951782;\t Train F1 Score - 0.7411167592677216;\t Train Recall - 0.5887096524238586;\t Train Precision - 1.0\n",
      "Train Loss - 0.23512811958789825;\t Train AUC - 0.9227399230003357;\t Train F1 Score - 0.7601810528243206;\t Train Recall - 0.6222222447395325;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2051793336868286;\t Train AUC - 0.9309819936752319;\t Train F1 Score - 0.819819791208595;\t Train Recall - 0.699999988079071;\t Train Precision - 0.989130437374115\n",
      "Train Loss - 0.2101934552192688;\t Train AUC - 0.9335988163948059;\t Train F1 Score - 0.8071749211664926;\t Train Recall - 0.6818181872367859;\t Train Precision - 0.9890109896659851\n",
      "Train Loss - 0.24102865159511566;\t Train AUC - 0.9312518835067749;\t Train F1 Score - 0.8057554023955975;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9739130139350891\n",
      "Train Loss - 0.2872498631477356;\t Train AUC - 0.8971322178840637;\t Train F1 Score - 0.6968325999237617;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.19181552529335022;\t Train AUC - 0.936001181602478;\t Train F1 Score - 0.8370043868148584;\t Train Recall - 0.7364341020584106;\t Train Precision - 0.9693877696990967\n",
      "Train Loss - 0.21747741103172302;\t Train AUC - 0.9358958005905151;\t Train F1 Score - 0.7747747627043958;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9450549483299255\n",
      "Train Loss - 0.20713168382644653;\t Train AUC - 0.937618613243103;\t Train F1 Score - 0.7945205499285002;\t Train Recall - 0.6692307591438293;\t Train Precision - 0.9775280952453613\n",
      "Train Loss - 0.2187374383211136;\t Train AUC - 0.9213203191757202;\t Train F1 Score - 0.818565387019053;\t Train Recall - 0.7132353186607361;\t Train Precision - 0.9603960514068604\n",
      "Train Loss - 0.23241978883743286;\t Train AUC - 0.922768771648407;\t Train F1 Score - 0.7677725248425533;\t Train Recall - 0.6328125;\t Train Precision - 0.9759036302566528\n",
      "Train Loss - 0.19544313848018646;\t Train AUC - 0.9356866478919983;\t Train F1 Score - 0.8301886607122686;\t Train Recall - 0.7213114500045776;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.22456207871437073;\t Train AUC - 0.9220413565635681;\t Train F1 Score - 0.7932489628251728;\t Train Recall - 0.6911764740943909;\t Train Precision - 0.9306930899620056\n",
      "Train Loss - 0.20079109072685242;\t Train AUC - 0.9365978837013245;\t Train F1 Score - 0.8148148333100294;\t Train Recall - 0.7039999961853027;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.26491618156433105;\t Train AUC - 0.8791317939758301;\t Train F1 Score - 0.7052631260706325;\t Train Recall - 0.5677965879440308;\t Train Precision - 0.9305555820465088\n",
      "Train Loss - 0.20455269515514374;\t Train AUC - 0.9295116066932678;\t Train F1 Score - 0.7941176362288684;\t Train Recall - 0.6982758641242981;\t Train Precision - 0.9204545617103577\n",
      "Train Loss - 0.19438879191875458;\t Train AUC - 0.9455746412277222;\t Train F1 Score - 0.8018017511754478;\t Train Recall - 0.7063491940498352;\t Train Precision - 0.9270833134651184\n",
      "Train Loss - 0.2333524525165558;\t Train AUC - 0.9278187155723572;\t Train F1 Score - 0.7863247763949385;\t Train Recall - 0.652482271194458;\t Train Precision - 0.9892473220825195\n",
      "Train Loss - 0.19585347175598145;\t Train AUC - 0.9416932463645935;\t Train F1 Score - 0.8018433458242041;\t Train Recall - 0.7016128897666931;\t Train Precision - 0.9354838728904724\n",
      "Train Loss - 0.2479332536458969;\t Train AUC - 0.9129064083099365;\t Train F1 Score - 0.7868852435063809;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9696969985961914\n",
      "Train Loss - 0.21571753919124603;\t Train AUC - 0.9352610111236572;\t Train F1 Score - 0.7720930017157879;\t Train Recall - 0.6335877776145935;\t Train Precision - 0.988095223903656\n",
      "Train Loss - 0.24316337704658508;\t Train AUC - 0.9165188074111938;\t Train F1 Score - 0.7767857227831861;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.1833309680223465;\t Train AUC - 0.9473437666893005;\t Train F1 Score - 0.8235293746407067;\t Train Recall - 0.699999988079071;\t Train Precision - 1.0\n",
      "Train Loss - 0.24040059745311737;\t Train AUC - 0.9187192916870117;\t Train F1 Score - 0.7950820015863111;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9797979593276978\n",
      "Train Loss - 0.1927323192358017;\t Train AUC - 0.9430983662605286;\t Train F1 Score - 0.8260869839015675;\t Train Recall - 0.7037037014961243;\t Train Precision - 1.0\n",
      "Train Loss - 0.2204313427209854;\t Train AUC - 0.9294497966766357;\t Train F1 Score - 0.799999985694886;\t Train Recall - 0.6666666865348816;\t Train Precision - 1.0\n",
      "Train Loss - 0.2173486351966858;\t Train AUC - 0.9099907875061035;\t Train F1 Score - 0.7593582680294142;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9220778942108154\n",
      "Train Loss - 0.22486478090286255;\t Train AUC - 0.9220120906829834;\t Train F1 Score - 0.8017621433115643;\t Train Recall - 0.694656491279602;\t Train Precision - 0.9479166865348816\n",
      "Train Loss - 0.22469370067119598;\t Train AUC - 0.9414496421813965;\t Train F1 Score - 0.8214286068137397;\t Train Recall - 0.709876537322998;\t Train Precision - 0.9745762944221497\n",
      "Train Loss - 0.2121153324842453;\t Train AUC - 0.9346833229064941;\t Train F1 Score - 0.7892376835405335;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.2271726280450821;\t Train AUC - 0.9078572988510132;\t Train F1 Score - 0.8000000144157433;\t Train Recall - 0.6776859760284424;\t Train Precision - 0.976190447807312\n",
      "Train Loss - 0.2505529224872589;\t Train AUC - 0.8833572268486023;\t Train F1 Score - 0.7562188889365629;\t Train Recall - 0.6280992031097412;\t Train Precision - 0.949999988079071\n",
      "Train Loss - 0.21092325448989868;\t Train AUC - 0.9309803247451782;\t Train F1 Score - 0.8036529436160376;\t Train Recall - 0.6717557311058044;\t Train Precision - 1.0\n",
      "Train Loss - 0.20837606489658356;\t Train AUC - 0.9282748699188232;\t Train F1 Score - 0.8018867979009142;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.21104182302951813;\t Train AUC - 0.9360741376876831;\t Train F1 Score - 0.7894736958003183;\t Train Recall - 0.6766917109489441;\t Train Precision - 0.9473684430122375\n",
      "Train Loss - 0.2431451380252838;\t Train AUC - 0.9223045706748962;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.22967422008514404;\t Train AUC - 0.9199997186660767;\t Train F1 Score - 0.7932489884522943;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9399999976158142\n",
      "Train Loss - 0.03970899060368538;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.23206980526447296;\t Test AUC - 0.8973292112350464;\t Test F1 Score - 0.7961165112575973;\t Test Recall - 0.694915235042572;\t Test Precision - 0.9318181872367859\n",
      "Test Loss - 0.2603811025619507;\t Test AUC - 0.8921030759811401;\t Test F1 Score - 0.7476635705889523;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9523809552192688\n",
      "Test Loss - 0.2247239649295807;\t Test AUC - 0.9197366237640381;\t Test F1 Score - 0.7818181736998986;\t Test Recall - 0.6771653294563293;\t Test Precision - 0.9247311949729919\n",
      "Test Loss - 0.21729840338230133;\t Test AUC - 0.9138369560241699;\t Test F1 Score - 0.8165137301035095;\t Test Recall - 0.7063491940498352;\t Test Precision - 0.967391312122345\n",
      "Test Loss - 0.23308385908603668;\t Test AUC - 0.9184582233428955;\t Test F1 Score - 0.772946818732236;\t Test Recall - 0.6349206566810608;\t Test Precision - 0.9876543283462524\n",
      "Test Loss - 0.2183115929365158;\t Test AUC - 0.9062522649765015;\t Test F1 Score - 0.7692308097591083;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.9259259104728699\n",
      "Test Loss - 0.23348286747932434;\t Test AUC - 0.8996509313583374;\t Test F1 Score - 0.7578947431412284;\t Test Recall - 0.6206896305084229;\t Test Precision - 0.9729729890823364\n",
      "Test Loss - 0.2593287229537964;\t Test AUC - 0.8836767673492432;\t Test F1 Score - 0.7216495592019361;\t Test Recall - 0.5932203531265259;\t Test Precision - 0.9210526347160339\n",
      "Test Loss - 0.23351722955703735;\t Test AUC - 0.9158691763877869;\t Test F1 Score - 0.8051947773532095;\t Test Recall - 0.6788321137428284;\t Test Precision - 0.9893617033958435\n",
      "Test Loss - 0.2499845325946808;\t Test AUC - 0.8934397101402283;\t Test F1 Score - 0.7512195593834244;\t Test Recall - 0.6260162591934204;\t Test Precision - 0.9390243887901306\n",
      "Test Loss - 0.2874012291431427;\t Test AUC - 0.8833988308906555;\t Test F1 Score - 0.7359307160863721;\t Test Recall - 0.5944055914878845;\t Test Precision - 0.9659090638160706\n",
      "Test Loss - 0.23602887988090515;\t Test AUC - 0.9178045988082886;\t Test F1 Score - 0.7914893428088506;\t Test Recall - 0.6690647602081299;\t Test Precision - 0.96875\n",
      "Test Loss - 0.28467386960983276;\t Test AUC - 0.8777494430541992;\t Test F1 Score - 0.7354259657316944;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.9425287246704102\n",
      "Test Loss - 0.2536395192146301;\t Test AUC - 0.9019362330436707;\t Test F1 Score - 0.7475728132992798;\t Test Recall - 0.6260162591934204;\t Test Precision - 0.9277108311653137\n",
      "Test Loss - 0.2605081796646118;\t Test AUC - 0.8985382914543152;\t Test F1 Score - 0.7705627336126593;\t Test Recall - 0.631205677986145;\t Test Precision - 0.9888888597488403\n",
      "Test Loss - 0.2589073181152344;\t Test AUC - 0.8920621871948242;\t Test F1 Score - 0.7208121898665768;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9466666579246521\n",
      "Test Loss - 0.29466965794563293;\t Test AUC - 0.9128787517547607;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 37\n",
      "Train Loss - 0.21195688843727112;\t Train AUC - 0.9422410130500793;\t Train F1 Score - 0.8160000306647806;\t Train Recall - 0.698630154132843;\t Train Precision - 0.9807692170143127\n",
      "Train Loss - 0.24636045098304749;\t Train AUC - 0.9031071662902832;\t Train F1 Score - 0.7299999930747565;\t Train Recall - 0.5887096524238586;\t Train Precision - 0.9605262875556946\n",
      "Train Loss - 0.2355768382549286;\t Train AUC - 0.9246196746826172;\t Train F1 Score - 0.7601810528243206;\t Train Recall - 0.6222222447395325;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2069089114665985;\t Train AUC - 0.9307610392570496;\t Train F1 Score - 0.8054298733374188;\t Train Recall - 0.6846153736114502;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.21711492538452148;\t Train AUC - 0.9288315773010254;\t Train F1 Score - 0.7963800771382238;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9887640476226807\n",
      "Train Loss - 0.2390981763601303;\t Train AUC - 0.9345228672027588;\t Train F1 Score - 0.8086642493594074;\t Train Recall - 0.6871165633201599;\t Train Precision - 0.9824561476707458\n",
      "Train Loss - 0.28918692469596863;\t Train AUC - 0.89431232213974;\t Train F1 Score - 0.7000000235160381;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9746835231781006\n",
      "Train Loss - 0.19612941145896912;\t Train AUC - 0.9345364570617676;\t Train F1 Score - 0.8318583555051624;\t Train Recall - 0.7286821603775024;\t Train Precision - 0.969072163105011\n",
      "Train Loss - 0.21364453434944153;\t Train AUC - 0.9364979863166809;\t Train F1 Score - 0.7802690745677909;\t Train Recall - 0.6641221642494202;\t Train Precision - 0.945652186870575\n",
      "Train Loss - 0.20805196464061737;\t Train AUC - 0.9406219720840454;\t Train F1 Score - 0.7777777288080614;\t Train Recall - 0.6461538672447205;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.2234535664319992;\t Train AUC - 0.9200130105018616;\t Train F1 Score - 0.8101266086978051;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.9504950642585754\n",
      "Train Loss - 0.23900769650936127;\t Train AUC - 0.9177783727645874;\t Train F1 Score - 0.7403845809400649;\t Train Recall - 0.6015625;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.19713805615901947;\t Train AUC - 0.9356865882873535;\t Train F1 Score - 0.8019323751443799;\t Train Recall - 0.6803278923034668;\t Train Precision - 0.9764705896377563\n",
      "Train Loss - 0.22585256397724152;\t Train AUC - 0.9209479689598083;\t Train F1 Score - 0.7931034658771513;\t Train Recall - 0.6764705777168274;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.2013123333454132;\t Train AUC - 0.9365642070770264;\t Train F1 Score - 0.8093023115753423;\t Train Recall - 0.6959999799728394;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.26107969880104065;\t Train AUC - 0.881347119808197;\t Train F1 Score - 0.7157894522300343;\t Train Recall - 0.5762711763381958;\t Train Precision - 0.9444444179534912\n",
      "Train Loss - 0.20185379683971405;\t Train AUC - 0.9311769604682922;\t Train F1 Score - 0.7999999707146532;\t Train Recall - 0.7068965435028076;\t Train Precision - 0.9213483333587646\n",
      "Train Loss - 0.19028957188129425;\t Train AUC - 0.9446370005607605;\t Train F1 Score - 0.8148148358871637;\t Train Recall - 0.6984127163887024;\t Train Precision - 0.9777777791023254\n",
      "Train Loss - 0.24624526500701904;\t Train AUC - 0.9271311163902283;\t Train F1 Score - 0.7736625393940322;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9215686321258545\n",
      "Train Loss - 0.1910254955291748;\t Train AUC - 0.9419388771057129;\t Train F1 Score - 0.8056872418529097;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.24565142393112183;\t Train AUC - 0.9126032590866089;\t Train F1 Score - 0.7886178713082953;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9603960514068604\n",
      "Train Loss - 0.21286608278751373;\t Train AUC - 0.9354318976402283;\t Train F1 Score - 0.7798165756466352;\t Train Recall - 0.6488549709320068;\t Train Precision - 0.977011501789093\n",
      "Train Loss - 0.23856548964977264;\t Train AUC - 0.9180163145065308;\t Train F1 Score - 0.7767857227831861;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.1805870682001114;\t Train AUC - 0.9506596922874451;\t Train F1 Score - 0.8118811621758051;\t Train Recall - 0.6833333373069763;\t Train Precision - 1.0\n",
      "Train Loss - 0.2453821748495102;\t Train AUC - 0.9122925400733948;\t Train F1 Score - 0.7782426695659618;\t Train Recall - 0.6413792967796326;\t Train Precision - 0.9893617033958435\n",
      "Train Loss - 0.1928536295890808;\t Train AUC - 0.944460391998291;\t Train F1 Score - 0.8209607124996943;\t Train Recall - 0.6962962746620178;\t Train Precision - 1.0\n",
      "Train Loss - 0.2228488177061081;\t Train AUC - 0.9317632913589478;\t Train F1 Score - 0.7787610535726582;\t Train Recall - 0.6376811861991882;\t Train Precision - 1.0\n",
      "Train Loss - 0.21574419736862183;\t Train AUC - 0.9102504849433899;\t Train F1 Score - 0.7675675817330154;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9466666579246521\n",
      "Train Loss - 0.2266014665365219;\t Train AUC - 0.9238594770431519;\t Train F1 Score - 0.7857143120276042;\t Train Recall - 0.6717557311058044;\t Train Precision - 0.9462365508079529\n",
      "Train Loss - 0.22911132872104645;\t Train AUC - 0.939624547958374;\t Train F1 Score - 0.8214286068137397;\t Train Recall - 0.709876537322998;\t Train Precision - 0.9745762944221497\n",
      "Train Loss - 0.2089899182319641;\t Train AUC - 0.9360107779502869;\t Train F1 Score - 0.7911111146838775;\t Train Recall - 0.6742424368858337;\t Train Precision - 0.9569892287254333\n",
      "Train Loss - 0.22575755417346954;\t Train AUC - 0.9087285399436951;\t Train F1 Score - 0.782178246817952;\t Train Recall - 0.6528925895690918;\t Train Precision - 0.9753086566925049\n",
      "Train Loss - 0.2506576478481293;\t Train AUC - 0.8857295513153076;\t Train F1 Score - 0.753768793081613;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9615384340286255\n",
      "Train Loss - 0.2130352258682251;\t Train AUC - 0.9300118684768677;\t Train F1 Score - 0.8018017784747788;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9780219793319702\n",
      "Train Loss - 0.2092103362083435;\t Train AUC - 0.9281902313232422;\t Train F1 Score - 0.8018867979009142;\t Train Recall - 0.6854838728904724;\t Train Precision - 0.9659090638160706\n",
      "Train Loss - 0.20557555556297302;\t Train AUC - 0.9375795125961304;\t Train F1 Score - 0.8034934655557456;\t Train Recall - 0.6917293071746826;\t Train Precision - 0.9583333134651184\n",
      "Train Loss - 0.24442410469055176;\t Train AUC - 0.9194369316101074;\t Train F1 Score - 0.7598253207322118;\t Train Recall - 0.6126760840415955;\t Train Precision - 1.0\n",
      "Train Loss - 0.23259282112121582;\t Train AUC - 0.920811653137207;\t Train F1 Score - 0.7899159663865546;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9306930899620056\n",
      "Train Loss - 0.03683556243777275;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.224696546792984;\t Test AUC - 0.9029203653335571;\t Test F1 Score - 0.8078817627838591;\t Test Recall - 0.694915235042572;\t Test Precision - 0.9647058844566345\n",
      "Test Loss - 0.26471155881881714;\t Test AUC - 0.8877168893814087;\t Test F1 Score - 0.7511737574717161;\t Test Recall - 0.6153846383094788;\t Test Precision - 0.9638554453849792\n",
      "Test Loss - 0.22449608147144318;\t Test AUC - 0.9202194213867188;\t Test F1 Score - 0.7834101450572933;\t Test Recall - 0.6692913174629211;\t Test Precision - 0.9444444179534912\n",
      "Test Loss - 0.21724924445152283;\t Test AUC - 0.9130332469940186;\t Test F1 Score - 0.812785393691177;\t Test Recall - 0.7063491940498352;\t Test Precision - 0.9569892287254333\n",
      "Test Loss - 0.2348010241985321;\t Test AUC - 0.9163234233856201;\t Test F1 Score - 0.7677725348607995;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9529411792755127\n",
      "Test Loss - 0.214298814535141;\t Test AUC - 0.9068840146064758;\t Test F1 Score - 0.7772020271919031;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.949367105960846\n",
      "Test Loss - 0.23484331369400024;\t Test AUC - 0.8990452885627747;\t Test F1 Score - 0.7684210735998931;\t Test Recall - 0.6293103694915771;\t Test Precision - 0.9864864945411682\n",
      "Test Loss - 0.2615266740322113;\t Test AUC - 0.8839141726493835;\t Test F1 Score - 0.7253886172208227;\t Test Recall - 0.5932203531265259;\t Test Precision - 0.9333333373069763\n",
      "Test Loss - 0.23221980035305023;\t Test AUC - 0.9166811108589172;\t Test F1 Score - 0.8068669730668143;\t Test Recall - 0.6861313581466675;\t Test Precision - 0.9791666865348816\n",
      "Test Loss - 0.2575070858001709;\t Test AUC - 0.883528470993042;\t Test F1 Score - 0.7669902847277571;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9518072009086609\n",
      "Test Loss - 0.28598499298095703;\t Test AUC - 0.8833529949188232;\t Test F1 Score - 0.7445887612603174;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9772727489471436\n",
      "Test Loss - 0.23895253241062164;\t Test AUC - 0.9154013395309448;\t Test F1 Score - 0.8000000288045044;\t Test Recall - 0.6762589812278748;\t Test Precision - 0.9791666865348816\n",
      "Test Loss - 0.2844051122665405;\t Test AUC - 0.8795639276504517;\t Test F1 Score - 0.7397260440235404;\t Test Recall - 0.595588207244873;\t Test Precision - 0.9759036302566528\n",
      "Test Loss - 0.23902598023414612;\t Test AUC - 0.9015612602233887;\t Test F1 Score - 0.7783250860399504;\t Test Recall - 0.642276406288147;\t Test Precision - 0.987500011920929\n",
      "Test Loss - 0.2572207748889923;\t Test AUC - 0.9034131765365601;\t Test F1 Score - 0.7725321698516844;\t Test Recall - 0.6382978558540344;\t Test Precision - 0.97826087474823\n",
      "Test Loss - 0.2605648934841156;\t Test AUC - 0.8902530670166016;\t Test F1 Score - 0.7244898543156821;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9594594836235046\n",
      "Test Loss - 0.28898048400878906;\t Test AUC - 0.9161255359649658;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n",
      "Epoch - 38\n",
      "Train Loss - 0.21203510463237762;\t Train AUC - 0.9460201859474182;\t Train F1 Score - 0.8016194340715057;\t Train Recall - 0.6780821681022644;\t Train Precision - 0.9801980257034302\n",
      "Train Loss - 0.24304883182048798;\t Train AUC - 0.9022008180618286;\t Train F1 Score - 0.7474747685896667;\t Train Recall - 0.5967742204666138;\t Train Precision - 1.0\n",
      "Train Loss - 0.23604345321655273;\t Train AUC - 0.9229151606559753;\t Train F1 Score - 0.7601810528243206;\t Train Recall - 0.6222222447395325;\t Train Precision - 0.9767441749572754\n",
      "Train Loss - 0.20059002935886383;\t Train AUC - 0.9349426627159119;\t Train F1 Score - 0.8181818309894276;\t Train Recall - 0.692307710647583;\t Train Precision - 1.0\n",
      "Train Loss - 0.20950016379356384;\t Train AUC - 0.9343434572219849;\t Train F1 Score - 0.8124999689286226;\t Train Recall - 0.689393937587738;\t Train Precision - 0.989130437374115\n",
      "Train Loss - 0.23988337814807892;\t Train AUC - 0.9325995445251465;\t Train F1 Score - 0.8072727054952957;\t Train Recall - 0.6809815764427185;\t Train Precision - 0.9910714030265808\n",
      "Train Loss - 0.2870487570762634;\t Train AUC - 0.8977580666542053;\t Train F1 Score - 0.6968325999237617;\t Train Recall - 0.5460993051528931;\t Train Precision - 0.9624999761581421\n",
      "Train Loss - 0.19696994125843048;\t Train AUC - 0.9341332912445068;\t Train F1 Score - 0.8266666619632406;\t Train Recall - 0.7209302186965942;\t Train Precision - 0.96875\n",
      "Train Loss - 0.20946399867534637;\t Train AUC - 0.938980221748352;\t Train F1 Score - 0.7853881321852059;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9772727489471436\n",
      "Train Loss - 0.21125000715255737;\t Train AUC - 0.9365139007568359;\t Train F1 Score - 0.781818183158513;\t Train Recall - 0.6615384817123413;\t Train Precision - 0.9555555582046509\n",
      "Train Loss - 0.21884706616401672;\t Train AUC - 0.9209875464439392;\t Train F1 Score - 0.8135593183952924;\t Train Recall - 0.7058823704719543;\t Train Precision - 0.9599999785423279\n",
      "Train Loss - 0.23877842724323273;\t Train AUC - 0.9188045859336853;\t Train F1 Score - 0.7488151590351446;\t Train Recall - 0.6171875;\t Train Precision - 0.9518072009086609\n",
      "Train Loss - 0.19161342084407806;\t Train AUC - 0.9393133521080017;\t Train F1 Score - 0.8285714445830753;\t Train Recall - 0.7131147384643555;\t Train Precision - 0.9886363744735718\n",
      "Train Loss - 0.22925427556037903;\t Train AUC - 0.921526312828064;\t Train F1 Score - 0.801724140418467;\t Train Recall - 0.6838235259056091;\t Train Precision - 0.96875\n",
      "Train Loss - 0.20132946968078613;\t Train AUC - 0.9366989731788635;\t Train F1 Score - 0.8148148333100294;\t Train Recall - 0.7039999961853027;\t Train Precision - 0.9670329689979553\n",
      "Train Loss - 0.2575315833091736;\t Train AUC - 0.8906393051147461;\t Train F1 Score - 0.7120418868864631;\t Train Recall - 0.5762711763381958;\t Train Precision - 0.931506872177124\n",
      "Train Loss - 0.19787637889385223;\t Train AUC - 0.9329848289489746;\t Train F1 Score - 0.8078817858599163;\t Train Recall - 0.7068965435028076;\t Train Precision - 0.9425287246704102\n",
      "Train Loss - 0.18955059349536896;\t Train AUC - 0.9481363892555237;\t Train F1 Score - 0.8108108127613499;\t Train Recall - 0.7142857313156128;\t Train Precision - 0.9375\n",
      "Train Loss - 0.22814545035362244;\t Train AUC - 0.929951012134552;\t Train F1 Score - 0.7932489420915207;\t Train Recall - 0.6666666865348816;\t Train Precision - 0.9791666865348816\n",
      "Train Loss - 0.19182129204273224;\t Train AUC - 0.9417778849601746;\t Train F1 Score - 0.8037383528872927;\t Train Recall - 0.6935483813285828;\t Train Precision - 0.9555555582046509\n",
      "Train Loss - 0.2452428638935089;\t Train AUC - 0.9141644239425659;\t Train F1 Score - 0.7918367198501088;\t Train Recall - 0.6689655184745789;\t Train Precision - 0.9700000286102295\n",
      "Train Loss - 0.2129996418952942;\t Train AUC - 0.9355865716934204;\t Train F1 Score - 0.7889907771545216;\t Train Recall - 0.6564885377883911;\t Train Precision - 0.9885057210922241\n",
      "Train Loss - 0.23956294357776642;\t Train AUC - 0.918586790561676;\t Train F1 Score - 0.7699114597672916;\t Train Recall - 0.6397058963775635;\t Train Precision - 0.9666666388511658\n",
      "Train Loss - 0.18357917666435242;\t Train AUC - 0.9450260400772095;\t Train F1 Score - 0.8235293746407067;\t Train Recall - 0.699999988079071;\t Train Precision - 1.0\n",
      "Train Loss - 0.2524060308933258;\t Train AUC - 0.9083137512207031;\t Train F1 Score - 0.7901234666514272;\t Train Recall - 0.6620689630508423;\t Train Precision - 0.9795918464660645\n",
      "Train Loss - 0.1949167102575302;\t Train AUC - 0.9399123191833496;\t Train F1 Score - 0.8260869839015675;\t Train Recall - 0.7037037014961243;\t Train Precision - 1.0\n",
      "Train Loss - 0.22047629952430725;\t Train AUC - 0.933661162853241;\t Train F1 Score - 0.7913043314773847;\t Train Recall - 0.6594203114509583;\t Train Precision - 0.989130437374115\n",
      "Train Loss - 0.21634460985660553;\t Train AUC - 0.9108442068099976;\t Train F1 Score - 0.7717391837209465;\t Train Recall - 0.6454545259475708;\t Train Precision - 0.9594594836235046\n",
      "Train Loss - 0.21992053091526031;\t Train AUC - 0.9258695244789124;\t Train F1 Score - 0.7946428402313757;\t Train Recall - 0.6793892979621887;\t Train Precision - 0.9569892287254333\n",
      "Train Loss - 0.2228410392999649;\t Train AUC - 0.9439089298248291;\t Train F1 Score - 0.8214286068137397;\t Train Recall - 0.709876537322998;\t Train Precision - 0.9745762944221497\n",
      "Train Loss - 0.20829784870147705;\t Train AUC - 0.9368120431900024;\t Train F1 Score - 0.7999999710930714;\t Train Recall - 0.6818181872367859;\t Train Precision - 0.9677419066429138\n",
      "Train Loss - 0.2285008281469345;\t Train AUC - 0.9058213233947754;\t Train F1 Score - 0.7920791871613462;\t Train Recall - 0.6611570119857788;\t Train Precision - 0.9876543283462524\n",
      "Train Loss - 0.25176021456718445;\t Train AUC - 0.8843665719032288;\t Train F1 Score - 0.753768793081613;\t Train Recall - 0.6198347210884094;\t Train Precision - 0.9615384340286255\n",
      "Train Loss - 0.2132822871208191;\t Train AUC - 0.9319813251495361;\t Train F1 Score - 0.7926267194880579;\t Train Recall - 0.6564885377883911;\t Train Precision - 1.0\n",
      "Train Loss - 0.2093019187450409;\t Train AUC - 0.9279699325561523;\t Train F1 Score - 0.7962085339006066;\t Train Recall - 0.6774193644523621;\t Train Precision - 0.9655172228813171\n",
      "Train Loss - 0.20735172927379608;\t Train AUC - 0.936082124710083;\t Train F1 Score - 0.80701756023653;\t Train Recall - 0.6917293071746826;\t Train Precision - 0.9684210419654846\n",
      "Train Loss - 0.24212893843650818;\t Train AUC - 0.921159029006958;\t Train F1 Score - 0.7652173938643053;\t Train Recall - 0.6197183132171631;\t Train Precision - 1.0\n",
      "Train Loss - 0.2327975183725357;\t Train AUC - 0.9203465580940247;\t Train F1 Score - 0.7932489884522943;\t Train Recall - 0.6861313581466675;\t Train Precision - 0.9399999976158142\n",
      "Train Loss - 0.038080085068941116;\t Train AUC - 0.0;\t Train F1 Score - nan;\t Train Recall - 0.0;\t Train Precision - 0.0\n",
      "Test Loss - 0.22323842346668243;\t Test AUC - 0.9047049880027771;\t Test F1 Score - 0.8078817627838591;\t Test Recall - 0.694915235042572;\t Test Precision - 0.9647058844566345\n",
      "Test Loss - 0.25962957739830017;\t Test AUC - 0.8901882171630859;\t Test F1 Score - 0.7570093429869547;\t Test Recall - 0.6230769157409668;\t Test Precision - 0.9642857313156128\n",
      "Test Loss - 0.2274642437696457;\t Test AUC - 0.9173893928527832;\t Test F1 Score - 0.779816498755087;\t Test Recall - 0.6692913174629211;\t Test Precision - 0.9340659379959106\n",
      "Test Loss - 0.21799568831920624;\t Test AUC - 0.9152100086212158;\t Test F1 Score - 0.812785393691177;\t Test Recall - 0.7063491940498352;\t Test Precision - 0.9569892287254333\n",
      "Test Loss - 0.23574833571910858;\t Test AUC - 0.9160053133964539;\t Test F1 Score - 0.7677725348607995;\t Test Recall - 0.6428571343421936;\t Test Precision - 0.9529411792755127\n",
      "Test Loss - 0.21625295281410217;\t Test AUC - 0.9077593684196472;\t Test F1 Score - 0.7772020271919031;\t Test Recall - 0.6578947305679321;\t Test Precision - 0.949367105960846\n",
      "Test Loss - 0.23800422251224518;\t Test AUC - 0.8949576616287231;\t Test F1 Score - 0.7578947431412284;\t Test Recall - 0.6206896305084229;\t Test Precision - 0.9729729890823364\n",
      "Test Loss - 0.2596774995326996;\t Test AUC - 0.8839844465255737;\t Test F1 Score - 0.7319588028943251;\t Test Recall - 0.6016949415206909;\t Test Precision - 0.9342105388641357\n",
      "Test Loss - 0.23655980825424194;\t Test AUC - 0.9132049083709717;\t Test F1 Score - 0.7999999856441822;\t Test Recall - 0.6715328693389893;\t Test Precision - 0.9892473220825195\n",
      "Test Loss - 0.24283656477928162;\t Test AUC - 0.8954082727432251;\t Test F1 Score - 0.7669902847277571;\t Test Recall - 0.642276406288147;\t Test Precision - 0.9518072009086609\n",
      "Test Loss - 0.2808152437210083;\t Test AUC - 0.8920215368270874;\t Test F1 Score - 0.7381974350795572;\t Test Recall - 0.6013985872268677;\t Test Precision - 0.9555555582046509\n",
      "Test Loss - 0.2386036217212677;\t Test AUC - 0.9183663725852966;\t Test F1 Score - 0.7948717670505641;\t Test Recall - 0.6690647602081299;\t Test Precision - 0.9789473414421082\n",
      "Test Loss - 0.28430113196372986;\t Test AUC - 0.8792548775672913;\t Test F1 Score - 0.7454544960426418;\t Test Recall - 0.6029411554336548;\t Test Precision - 0.976190447807312\n",
      "Test Loss - 0.2426862269639969;\t Test AUC - 0.8994648456573486;\t Test F1 Score - 0.7609756273623935;\t Test Recall - 0.6341463327407837;\t Test Precision - 0.9512194991111755\n",
      "Test Loss - 0.2650144398212433;\t Test AUC - 0.8972944021224976;\t Test F1 Score - 0.7652174112281647;\t Test Recall - 0.6241135001182556;\t Test Precision - 0.9887640476226807\n",
      "Test Loss - 0.2590312659740448;\t Test AUC - 0.8896186351776123;\t Test F1 Score - 0.7244898543156821;\t Test Recall - 0.5819672346115112;\t Test Precision - 0.9594594836235046\n",
      "Test Loss - 0.29759883880615234;\t Test AUC - 0.9054833650588989;\t Test F1 Score - 0.6875000244472171;\t Test Recall - 0.523809552192688;\t Test Precision - 1.0\n"
     ]
    }
   ],
   "source": [
    "mean_train_loss, mean_train_auc, mean_train_f1, mean_train_recall, mean_train_precision, mean_test_loss, mean_test_auc, mean_test_f1, mean_test_recall, mean_test_precision = train_model(fm, num_epochs, train_dataset, test_dataset, optimizer, loss, grad_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPqYQq8VmaOz"
   },
   "source": [
    "The method `train_model` trains the `fm` model and outputs the following lists:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Og0zPzVIhcdr"
   },
   "source": [
    "| Element               | Description                                                                 |\n",
    "|-----------------------|-----------------------------------------------------------------------------|\n",
    "| mean_train_loss       | This is the average training loss per epoch.                                |\n",
    "| mean_train_auc        | This is the average Area Under the ROC Curve (AUC) for the training set.    |\n",
    "| mean_train_f1         | This is the average F1 score for the training set.                          |\n",
    "| mean_train_recall     | This is the average recall score for the training set.                      |\n",
    "| mean_train_precision  | This is the average precision score for the training set.                   |\n",
    "| mean_test_loss        | This is the average loss on the test set per epoch.                         |\n",
    "| mean_test_auc         | This is the average Area Under the ROC Curve (AUC) for the test set.        |\n",
    "| mean_test_f1          | This is the average F1 score for the test set.                              |\n",
    "| mean_test_recall      | This is the average recall score for the test set.                          |\n",
    "| mean_test_precision   | This is the average precision score for the test set.                       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cS2ErYyh5_R"
   },
   "source": [
    "\n",
    "---\n",
    "<font color='green'>\n",
    "Using the data provided in the variables `mean_train_loss`, `mean_train_auc`, `mean_train_f1`, `mean_train_recall`, `mean_train_precision`, `mean_test_loss`, `mean_test_auc`, `mean_test_f1`, `mean_test_recall`, and `mean_test_precision`, let's create the following plots:\n",
    "  * A plot showing the training and testing loss over each epoch. The x-axis should represent the epoch number and the y-axis should represent the loss. \n",
    "\n",
    "  * A plot showing the training and testing AUC over each epoch. The x-axis should represent the epoch number and the y-axis should represent the AUC. \n",
    "\n",
    "  * A plot showing the training and testing F1 score over each epoch. The x-axis should represent the epoch number and the y-axis should represent the F1 score.\n",
    "\n",
    "  * A plot showing the training and testing recall over each epoch. The x-axis should represent the epoch number and the y-axis should represent the recall. \n",
    "\n",
    "  * A plot showing the training and testing precision over each epoch. The x-axis should represent the epoch number and the y-axis should represent the precision. \n",
    "\n",
    "For each plot, we include a legend to distinguish between the training and testing data.\n",
    "\n",
    "We discuss any trends or patterns you observe in these plots and what they may indicate about the performance and generalization of your model.\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_train_loss: [0.42763314, 0.31542063, 0.2765871, 0.2653923, 0.2543688, 0.24872315, 0.25096276, 0.2430352, 0.24023049, 0.23718552, 0.23557618, 0.23425877, 0.23365852, 0.23407078, 0.23216179, 0.23070022, 0.22939824, 0.22835335, 0.22780223, 0.2284042, 0.23082425, 0.22561985, 0.2245121, 0.2238672, 0.2243016, 0.2246404, 0.2234401, 0.22394131, 0.22275844, 0.22576152, 0.2214812, 0.22129457, 0.22029962, 0.2291805, 0.21824455, 0.21721625, 0.21698563, 0.2173994, 0.21616341]\n",
      "\n",
      "mean_train_auc: [0.80307484, 0.8610489, 0.8738505, 0.87688816, 0.8805492, 0.88295215, 0.88239974, 0.8846698, 0.886268, 0.88799137, 0.8892388, 0.890233, 0.8906426, 0.89059585, 0.8912057, 0.89262575, 0.8936976, 0.89415485, 0.8945305, 0.89433914, 0.8938984, 0.89558095, 0.896554, 0.8970943, 0.8970053, 0.8965276, 0.8973676, 0.89783555, 0.8978115, 0.89761156, 0.8988173, 0.8989737, 0.8996205, 0.89617825, 0.9011845, 0.9014166, 0.9018472, 0.90186495, 0.90260607]\n",
      "\n",
      "mean_train_f1: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "\n",
      "mean_train_recall: [0.37862816, 0.5484645, 0.6204647, 0.6202682, 0.62424594, 0.6265915, 0.62194836, 0.62850624, 0.6302004, 0.6319099, 0.63321805, 0.63380134, 0.63361716, 0.63311845, 0.63632905, 0.6365264, 0.6360445, 0.6362755, 0.63855886, 0.63696676, 0.63171184, 0.6404015, 0.64260113, 0.64441955, 0.6427606, 0.6393774, 0.6425942, 0.64294976, 0.64451146, 0.6391026, 0.6454949, 0.6446912, 0.64507014, 0.63244045, 0.6494299, 0.649008, 0.6514326, 0.6454532, 0.64989394]\n",
      "\n",
      "mean_train_precision: [0.6576409, 0.83760005, 0.86124265, 0.8947064, 0.9166313, 0.92498153, 0.92193997, 0.9400775, 0.9404663, 0.9458348, 0.9464123, 0.9461443, 0.9443199, 0.94105846, 0.9430181, 0.943161, 0.9433987, 0.94562775, 0.94611037, 0.94447035, 0.94158924, 0.9452391, 0.946989, 0.9460625, 0.94659364, 0.9482291, 0.9469655, 0.9453941, 0.9472083, 0.9422119, 0.94803363, 0.94683605, 0.9474608, 0.9423776, 0.94289416, 0.9459148, 0.94348145, 0.9435828, 0.9476796]\n",
      "\n",
      "mean_test_loss: [0.3450402, 0.29933837, 0.29300168, 0.2751348, 0.26664218, 0.2643623, 0.2590403, 0.25584427, 0.2552683, 0.25279722, 0.2525056, 0.2518198, 0.25197196, 0.2510559, 0.24990368, 0.24974254, 0.24978621, 0.24942563, 0.24926138, 0.25038788, 0.24964961, 0.24979432, 0.2491642, 0.24930716, 0.25039122, 0.25289893, 0.24699834, 0.24999492, 0.24775517, 0.24868567, 0.25093415, 0.24773093, 0.26734984, 0.24923725, 0.24689674, 0.24739091, 0.24929476, 0.24832265, 0.24855636]\n",
      "\n",
      "mean_test_auc: [0.86293423, 0.88095564, 0.88319635, 0.8904841, 0.8917818, 0.89316976, 0.8924884, 0.8947816, 0.8961944, 0.8977771, 0.8982539, 0.8984951, 0.89798176, 0.89874154, 0.90064764, 0.90118194, 0.90105706, 0.90135795, 0.9011252, 0.90314406, 0.9011247, 0.9007383, 0.9024195, 0.90113723, 0.9014696, 0.9001217, 0.9018355, 0.9021969, 0.9016627, 0.9014307, 0.90024346, 0.9000536, 0.8932934, 0.9019877, 0.9012529, 0.90159553, 0.9014542, 0.9011728, 0.90119505]\n",
      "\n",
      "mean_test_f1: [0.5559318451426174, 0.7117152536948484, 0.7045644222934841, 0.7335023903479407, 0.7407903393980337, 0.7371633956128869, 0.7592799375646253, 0.7596005814327125, 0.7601462537706403, 0.7608921742788648, 0.7608685196363074, 0.7601898554170149, 0.7583583267492497, 0.760440965539072, 0.7615619532288871, 0.761212239306102, 0.7623746688142016, 0.7618467551554877, 0.7626667062743162, 0.7603612993350599, 0.7624622988821823, 0.7628077240342359, 0.7614212262980256, 0.7629318878858196, 0.7635394843675194, 0.7609756498980699, 0.7643301049419342, 0.7626086035596695, 0.7630141717084606, 0.7604740427613343, 0.7574250658543945, 0.7649335217048318, 0.7255710967004084, 0.7597619807379011, 0.7654783331692455, 0.7653884053728405, 0.7593848258278676, 0.7655914434361726, 0.7632951760119703]\n",
      "\n",
      "mean_test_recall: [0.4046225, 0.6068474, 0.5556152, 0.5895977, 0.5992285, 0.6028914, 0.6211207, 0.6199522, 0.61886984, 0.61983025, 0.6212738, 0.62496173, 0.6235269, 0.62443876, 0.6231112, 0.6226533, 0.6244273, 0.62394387, 0.62853396, 0.621141, 0.6272097, 0.6248215, 0.6249244, 0.6254978, 0.62946707, 0.6313361, 0.6285932, 0.62946165, 0.62910396, 0.62436336, 0.6189288, 0.6327168, 0.5810009, 0.64156884, 0.6328769, 0.63334376, 0.63145876, 0.635131, 0.6334129]\n",
      "\n",
      "mean_test_precision: [0.89300567, 0.86400366, 0.9696864, 0.972927, 0.9727586, 0.9511914, 0.9798868, 0.9834716, 0.9880333, 0.9880049, 0.9846647, 0.97349346, 0.9702951, 0.9753255, 0.98243344, 0.98232347, 0.9815622, 0.9809099, 0.97266096, 0.98279685, 0.9751798, 0.9822674, 0.9771992, 0.98067904, 0.97352487, 0.96063817, 0.97806597, 0.970474, 0.97228736, 0.97552264, 0.9789209, 0.9702934, 0.9695114, 0.9347197, 0.9716942, 0.97043073, 0.95604515, 0.9670977, 0.9635723]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_eval_vars = {\n",
    "    \"mean_train_loss\": mean_train_loss, \n",
    "    \"mean_train_auc\": mean_train_auc, \n",
    "    \"mean_train_f1\": mean_train_f1, \n",
    "    \"mean_train_recall\": mean_train_recall, \n",
    "    \"mean_train_precision\": mean_train_precision, \n",
    "    \"mean_test_loss\": mean_test_loss, \n",
    "    \"mean_test_auc\": mean_test_auc, \n",
    "    \"mean_test_f1\": mean_test_f1, \n",
    "    \"mean_test_recall\": mean_test_recall, \n",
    "    \"mean_test_precision\": mean_test_precision\n",
    "}\n",
    "\n",
    "# Print the dictionary\n",
    "for key, value in model_eval_vars.items():\n",
    "    print(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and testing loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), mean_train_loss, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), mean_test_loss, label='Testing Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and testing AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), mean_train_auc, label='Training AUC')\n",
    "plt.plot(range(1, num_epochs + 1), mean_test_auc, label='Testing AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Training and Testing AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and testing F1 score\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), mean_train_f1, label='Training F1 Score')\n",
    "plt.plot(range(1, num_epochs + 1), mean_test_f1, label='Testing F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Training and Testing F1 Score')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and testing recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), mean_train_recall, label='Training Recall')\n",
    "plt.plot(range(1, num_epochs + 1), mean_test_recall, label='Testing Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Training and Testing Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and testing precision\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs + 1), mean_train_precision, label='Training Precision')\n",
    "plt.plot(range(1, num_epochs + 1), mean_test_precision, label='Testing Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Training and Testing Precision')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqvO9pdnkJy3"
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiuT6DSPk_IS"
   },
   "source": [
    "Using the trained model `fm` and the feature data `X_num_train`, `X_cat_train`, `X_num_test` and `X_cat_test`, We would like to create a bar plot visualizing the feature importance for both training and testing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DCU4Gl5kmwP"
   },
   "source": [
    "---\n",
    "<font color='green'>\n",
    "Now, let's make predictions using the model `fm` on both the training and testing data. The model returns two outputs: the predicted values and the importance weights (alpha) for each feature.\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array(X_num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on training data\n",
    "train_predictions, train_alpha = fm((np.array(X_num_train), np.array(X_cat_train)))\n",
    "\n",
    "# Make predictions on testing data\n",
    "test_predictions, test_alpha = fm((np.array(X_num_test), np.array(X_cat_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jR_n9--mDpA"
   },
   "source": [
    "---\n",
    "<font color='green'>\n",
    "We can hence compute the mean feature importance for both training and testing data by averaging the importance weight associated with each feature (numerical or categorical).\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean feature importance for training data\n",
    "train_mean_importance = np.mean(train_alpha, axis=0)\n",
    "\n",
    "# Compute mean feature importance for testing data\n",
    "test_mean_importance = np.mean(test_alpha, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bGjn6gCmG88"
   },
   "source": [
    "---\n",
    "<font color='green'>\n",
    "Finally we can create a horizontal bar plot showing the feature importance of each feature for both the training and testing data. We use different colors to distinguish between the training and testing data. The y-axis should represent the features. The x-axis should represent the feature importance. Additionally, we include a legend to distinguish between the training and testing data.\n",
    "\n",
    "</font>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the features\n",
    "features = numvars + catvars\n",
    "\n",
    "# Compute the mean feature importance for training and testing data\n",
    "train_mean_importance = np.mean(train_alpha, axis=0)\n",
    "test_mean_importance = np.mean(test_alpha, axis=0)\n",
    "\n",
    "# Set the bar width\n",
    "bar_width = 0.4\n",
    "\n",
    "# Set the positions of the bars on the y-axis\n",
    "train_positions = np.arange(len(features))\n",
    "test_positions = train_positions + bar_width\n",
    "\n",
    "# Create the bar plot\n",
    "plt.barh(train_positions, train_mean_importance, height=bar_width, color='blue', label='Training')\n",
    "plt.barh(test_positions, test_mean_importance, height=bar_width, color='orange', label='Testing')\n",
    "\n",
    "# Set the y-axis labels\n",
    "plt.yticks(train_positions + bar_width / 2, features)\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Feature Importance')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Accroding to the plot, we can see the feature of highest importance is `loan_grade`. While the features of lowest importance are `cb_person_credit_length` and `person_emp_length`. The importance ranking is consistent with the expectations (and intuition) based on exsiting knowledge.\n",
    "    \n",
    "<font color='blue'>Also, the feature imporatance of training data and testing data are very close.</font>\n",
    "    \n",
    "<font color='blue'>Generally speaking, the model treats the features similarly between the training and testing data. This indicates that the model is performing consistently and has successfully captured the underlying relationships in the data, which makes it be able to make accurate predictions.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVMTSOpUmxuh"
   },
   "source": [
    "# Using the `FinalModel` for a sequential problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMz53NBtoG7W"
   },
   "source": [
    "---\n",
    "<font color='green'>\n",
    "Given a time series forecasting task, where the objective is to predict an asset's future direction (either upwards or downwards) $T_y$ steps ahead using $T_x$ previous feature vectors, how would we adjust the `FinalModel` to accommodate this? Each feature vector encompasses both numerical and categorical variables at each time step. The `FinalModel`, as we have discussed before, is a non-sequential model and doesn't account for the temporal relationships between time steps. Let's laborate in detail how we would modify the `FinalModel` to handle this time-dependent problem.\n",
    "\n",
    "</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "We can adjust the `FinalModel` to sequence-to-sequence model which is adept at dealing with variable-length sequences.\n",
    "\n",
    "In a Seq2Seq model, there are two main components: an Encoder and a Decoder. The Encoder processes the input sequence and compresses the information into a context vector, also known as the hidden state. Input sequence is going to be mapped to a feature vector which is going to be the initialisation of our decoder LSTM. The last hidden state of encoder is the first hidden state of decoder. The Decoder then uses this context vector to generate the output sequence.\n",
    "\n",
    "Given that the FinalModel is currently a non-sequential model, it's essential to modify it to incorporate temporal relationships. We can do this with the following steps:\n",
    "\n",
    "**Encoder**: Convert the `FinalModel` into an Encoder. We can do this by replacing the standard layers with their gated counterparts suitable for sequence data. Since the gating mechanism is GRU, this transition would be straightforward. This Encoder will process the past $T_x$ feature vectors and create a context vector encapsulating the temporal information.\n",
    "\n",
    "**Embedding Layer**: Since we are also dealing with categorical variables in feature vectors, an embedding layer can be used to transform these into dense vectors of fixed size. This can capture the complex relationships within the categorical data and can be fed into the Encoder.\n",
    "\n",
    "**Decoder**: Build a Decoder, which could also use a similar gated mechanism to handle sequence data. The Decoder should be designed to generate the output sequence of length $T_y$ using the context vector from the Encoder. Each prediction of the Decoder should feed into the next time step of the Decoder along with the context vector, continuing this process until $T_y$ steps.\n",
    "\n",
    "**Training**: During training, the model uses a technique called teacher forcing where the actual output (instead of the model's prediction) is fed into the next time step of the Decoder. Tuning the hyperparameters will be an important step to get good performance.\n",
    "\n",
    "**Prediction**: When predicting, the model uses its own predictions from the previous time step as input to the next time step, along with the context vector.\n",
    "\n",
    "**Loss Function**: A suitable loss function for this problem could be Binary Cross-Entropy given that the prediction task is binary (upwards or downwards).\n",
    "\n",
    "**Seq2Seq** models can be complex to train due to issues like vanishing gradients, so techniques such as gradient clipping, learning rate schedules, or advanced optimization algorithms might be beneficial. Moreover, nuances of the financial time series data. It's often non-stationary and noisy, so feature engineering, data cleaning, and anomaly detection might be crucial steps in preprocessing. Also, we should consider the risk of overfitting due to the model's complexity and apply appropriate regularization techniques if necessary.\n",
    "\n",
    "According to the [Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting](https://arxiv.org/pdf/1912.09363.pdf) paper, one can develop the Transformer-based Time Series Forecasting model to effectively construct feature representations for different types of inputs (such as static, known, and observed) in order to achieve accurate forecasting performance. However, to apply this method one may need information on `Static Metadata` and `Known Future Inputs` in addition to $T_x$ previous feature vectors.\n",
    "\n",
    "The `FinalModel` is more like a Variable Selection Network which is used for judicious selection of the most salient features based on the input. TFT takes our `FinalModel` as the first layer and performs a more complex forecasting system as follows:\n",
    "\n",
    "1. **Gating mechanisms**: These mechanisms allow the model to adapt its depth and network complexity by skipping unused components of the architecture. This flexibility enables TFT to handle diverse datasets and scenarios.\n",
    "\n",
    "2. **Variable selection networks**: At each time step, these networks determine the relevant input variables to consider, enhancing the model's ability to focus on the most informative features.\n",
    "\n",
    "3. **Static covariate encoders**: These encoders integrate static features into the network by encoding context vectors. This integration enables the model to incorporate contextual information and capture the impact of static features on temporal dynamics.\n",
    "\n",
    "4. **Temporal processing**: TFT employs temporal processing to learn both short-term and long-term relationships from observed and known time-varying inputs. For local processing, a sequence-to-sequence layer is utilized, while long-term dependencies are captured using a novel interpretable multi-head attention block.\n",
    "\n",
    "5. **Prediction intervals**: TFT provides prediction intervals through quantile forecasts, which estimate the range of likely target values at each prediction horizon. This feature allows for a more comprehensive understanding of the uncertainty associated with the predictions.\n",
    "   \n",
    "\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "81kUcaVEcLV9",
    "Cq5p0Tdc5zGG",
    "p5Bsa6SAjCmn",
    "1flTS8wbirS-",
    "Kd0J0i2xwit0",
    "_eU3BnDwXXop",
    "pD7g96wTS7DT",
    "qK2VtRwxBnM1",
    "3ew1h6pDTtES",
    "QZXQDBv1wtFW",
    "HoyNde0dLpZF",
    "XpRI3XiRXtVG",
    "kmNIAQZZbstb",
    "3xtl5FGVck7s",
    "VdwSUfSnbupF",
    "lqvO9pdnkJy3",
    "JVMTSOpUmxuh"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
